# ğŸ† Tips-of-Feature-engineering

A feature engineering kit for each issue, to give you a deeper and deeper understanding of the work of feature engineering!


ä¸“é¡¹çªç ´ï¼Œæ¯ä¸€æœŸéƒ½ä¼šåˆ†äº«ä¸€äº›å¾ˆå®ç”¨çš„**ç‰¹å¾å·¥ç¨‹**æŠ€å·§ï¼Œä»ç†è®ºåˆ°å®è·µï¼Œå¾ªåºæ¸è¿›ï¼Œç›®å‰æœ¬é¡¹ç›®å·²ç´¯è®¡æ’°å†™äº†28æœŸå†…å®¹ï¼Œä¸ºäº†æ–¹ä¾¿ç»Ÿä¸€é˜…è¯»ï¼ŒğŸ“¦æ‰“åŒ…æˆäº†ä¸€ä»½PDFä¾›æœ‹å‹ä»¬ä¸‹è½½ã€‚
æ¬¢è¿å…³æ³¨å¾®ä¿¡å…¬ä¼—å·ã€ŠSAMshareã€‹ï¼Œä¸ä½œè€…é˜¿Samå–å¾—äº¤æµï¼

![image](./arrests/å…¬ä¼—å·äºŒç»´ç .jpg)

éšç€æˆ‘ä»¬åœ¨æœºå™¨å­¦ä¹ ã€æ•°æ®å»ºæ¨¡ã€æ•°æ®æŒ–æ˜åˆ†æè¿™æ¡å‘å±•è·¯ä¸Šè¶Šèµ°è¶Šè¿œï¼Œå…¶å®è¶Šä¼šæ„Ÿè§‰åˆ°ç‰¹å¾å·¥ç¨‹çš„é‡è¦æ€§ï¼Œå¹³æ—¶æˆ‘ä»¬åœ¨å¾ˆå¤šåœ°æ–¹éƒ½ä¼šçœ‹åˆ°ä¸€äº›å¾ˆå¥½çš„ç‰¹å¾å·¥ç¨‹æŠ€å·§ï¼Œæœ¬é¡¹ç›®çš„ç›®çš„å°±æ˜¯æŠŠè¿™äº›å°æŠ€å·§æ‰“åŒ…æˆä¸€ä¸ªåˆä¸€ä¸ªçš„å°é”¦å›Šï¼Œä¾›å¤§å®¶å»é˜…è¯»ã€‚

é¦–å…ˆæ˜¯å½“å‰æ›´æ–°åˆ°çš„ç›®å½•ï¼Œæ–¹ä¾¿å¤§å®¶å»æŸ¥æ‰¾å†…å®¹ï¼

#### æ•°æ®é›†å¤§å®¶å¯ä»¥[ç‚¹å‡»è¿™é‡Œ](https://github.com/Pysamlam/Tips-of-Feature-engineering/tree/master/data)å»è¿›è¡Œä¸‹è½½å“ˆğŸ˜†

## ç›®å½•ï¼šKeep updating

* [Tip1ï¼šç‰¹å¾æ— é‡çº²åŒ–çš„å¸¸è§æ“ä½œæ–¹æ³•](#tip1ç‰¹å¾æ— é‡çº²åŒ–çš„å¸¸è§æ“ä½œæ–¹æ³•)
* [Tip2ï¼šæ€ä¹ˆè¿›è¡Œå¤šé¡¹å¼orå¯¹æ•°çš„æ•°æ®å˜æ¢](#tip2æ€ä¹ˆè¿›è¡Œå¤šé¡¹å¼orå¯¹æ•°çš„æ•°æ®å˜æ¢)
* [Tip3ï¼šå¸¸ç”¨çš„ç»Ÿè®¡å›¾åœ¨Pythoné‡Œæ€ä¹ˆç”»?](#tip3å¸¸ç”¨çš„ç»Ÿè®¡å›¾åœ¨Pythoné‡Œæ€ä¹ˆç”»)
* [Tip4ï¼šæ€ä¹ˆå»é™¤DataFrameé‡Œçš„ç¼ºå¤±å€¼ï¼Ÿ](#tip4æ€ä¹ˆå»é™¤DataFrameé‡Œçš„ç¼ºå¤±å€¼)
* [Tip5ï¼šæ€ä¹ˆæŠŠè¢«é”™è¯¯å¡«å……çš„ç¼ºå¤±å€¼è¿˜åŸï¼Ÿ](#tip5æ€ä¹ˆæŠŠè¢«é”™è¯¯å¡«å……çš„ç¼ºå¤±å€¼è¿˜åŸ)
* [Tip6ï¼šæ€ä¹ˆå®šä¹‰ä¸€ä¸ªæ–¹æ³•å»å¡«å……åˆ†ç±»å˜é‡çš„ç©ºå€¼ï¼Ÿ](#tip6æ€ä¹ˆå®šä¹‰ä¸€ä¸ªæ–¹æ³•å»å¡«å……åˆ†ç±»å˜é‡çš„ç©ºå€¼)
* [Tip7ï¼šæ€ä¹ˆå®šä¹‰ä¸€ä¸ªæ–¹æ³•å»å¡«å……æ•°å€¼å˜é‡çš„ç©ºå€¼ï¼Ÿ](#tip7æ€ä¹ˆå®šä¹‰ä¸€ä¸ªæ–¹æ³•å»å¡«å……æ•°å€¼å˜é‡çš„ç©ºå€¼)
* [Tip8ï¼šæ€ä¹ˆæŠŠå‡ ä¸ªå›¾è¡¨ä¸€èµ·åœ¨åŒä¸€å¼ å›¾ä¸Šæ˜¾ç¤ºï¼Ÿ](#tip8æ€ä¹ˆæŠŠå‡ ä¸ªå›¾è¡¨ä¸€èµ·åœ¨åŒä¸€å¼ å›¾ä¸Šæ˜¾ç¤º)
* [Tip9ï¼šæ€ä¹ˆæŠŠç”»å‡ºå †ç§¯å›¾æ¥çœ‹å æ¯”å…³ç³»ï¼Ÿ](#tip9æ€ä¹ˆæŠŠç”»å‡ºå †ç§¯å›¾æ¥çœ‹å æ¯”å…³ç³»)
* [Tip10ï¼šæ€ä¹ˆå¯¹æ»¡è¶³æŸç§æ¡ä»¶çš„å˜é‡ä¿®æ”¹å…¶å˜é‡å€¼ï¼Ÿ](#tip10æ€ä¹ˆå¯¹æ»¡è¶³æŸç§æ¡ä»¶çš„å˜é‡ä¿®æ”¹å…¶å˜é‡å€¼ï¼Ÿ)
* [Tip11ï¼šæ€ä¹ˆé€šè¿‡æ­£åˆ™æå–å­—ç¬¦ä¸²é‡Œçš„æŒ‡å®šå†…å®¹?](#tip11æ€ä¹ˆé€šè¿‡æ­£åˆ™æå–å­—ç¬¦ä¸²é‡Œçš„æŒ‡å®šå†…å®¹)
* [Tip12ï¼šå¦‚ä½•åˆ©ç”¨å­—å…¸æ‰¹é‡ä¿®æ”¹å˜é‡å€¼ï¼Ÿ](#tip12å¦‚ä½•åˆ©ç”¨å­—å…¸æ‰¹é‡ä¿®æ”¹å˜é‡å€¼)
* [Tip13ï¼šå¦‚ä½•å¯¹ç±»åˆ«å˜é‡è¿›è¡Œç‹¬çƒ­ç¼–ç ï¼Ÿ](#tip13å¦‚ä½•å¯¹ç±»åˆ«å˜é‡è¿›è¡Œç‹¬çƒ­ç¼–ç )
* [Tip14ï¼šå¦‚ä½•æŠŠâ€œå¹´é¾„â€å­—æ®µæŒ‰ç…§æˆ‘ä»¬çš„é˜ˆå€¼åˆ†æ®µï¼Ÿ](#tip14å¦‚ä½•æŠŠ"å¹´é¾„"å­—æ®µæŒ‰ç…§æˆ‘ä»¬çš„é˜ˆå€¼åˆ†æ®µ)
* [Tip15ï¼šå¦‚ä½•ä½¿ç”¨sklearnçš„å¤šé¡¹å¼æ¥è¡ç”Ÿæ›´å¤šçš„å˜é‡ï¼Ÿ](#tip15å¦‚ä½•ä½¿ç”¨sklearnçš„å¤šé¡¹å¼æ¥è¡ç”Ÿæ›´å¤šçš„å˜é‡)
* [Tip16ï¼šå¦‚ä½•æ ¹æ®å˜é‡ç›¸å…³æ€§ç”»å‡ºçƒ­åŠ›å›¾ï¼Ÿ](#tip16å¦‚ä½•æ ¹æ®å˜é‡ç›¸å…³æ€§ç”»å‡ºçƒ­åŠ›å›¾)
* [Tip17ï¼šå¦‚ä½•æŠŠåˆ†å¸ƒä¿®æ­£ä¸ºç±»æ­£æ€åˆ†å¸ƒï¼Ÿ](#tip17å¦‚ä½•æŠŠåˆ†å¸ƒä¿®æ­£ä¸ºç±»æ­£æ€åˆ†å¸ƒ)
* [Tip18ï¼šæ€ä¹ˆæ‰¾å‡ºæ•°æ®é›†ä¸­æœ‰æ•°æ®å€¾æ–œçš„ç‰¹å¾ï¼Ÿ](#tip18æ€ä¹ˆæ‰¾å‡ºæ•°æ®é›†ä¸­æœ‰æ•°æ®å€¾æ–œçš„ç‰¹å¾)
* [Tip19ï¼šæ€ä¹ˆå°½å¯èƒ½åœ°ä¿®æ­£æ•°æ®å€¾æ–œçš„ç‰¹å¾ï¼Ÿ](#tip19æ€ä¹ˆå°½å¯èƒ½åœ°ä¿®æ­£æ•°æ®å€¾æ–œçš„ç‰¹å¾)
* [Tip20ï¼šæ€ä¹ˆç®€å•ä½¿ç”¨PCAæ¥åˆ’åˆ†æ•°æ®ä¸”å¯è§†åŒ–å‘¢ï¼Ÿ](#Tip20æ€ä¹ˆç®€å•ä½¿ç”¨PCAæ¥åˆ’åˆ†æ•°æ®ä¸”å¯è§†åŒ–å‘¢)
* [Tip21ï¼šæ€ä¹ˆç®€å•ä½¿ç”¨LDAæ¥åˆ’åˆ†æ•°æ®ä¸”å¯è§†åŒ–å‘¢ï¼Ÿ](#Tip21æ€ä¹ˆç®€å•ä½¿ç”¨LDAæ¥åˆ’åˆ†æ•°æ®ä¸”å¯è§†åŒ–å‘¢)
* [Tip22ï¼šæ€ä¹ˆæ¥ç®¡ç†æˆ‘ä»¬çš„å»ºæ¨¡é¡¹ç›®æ–‡ä»¶ï¼Ÿ](#Tip22æ€ä¹ˆæ¥ç®¡ç†æˆ‘ä»¬çš„å»ºæ¨¡é¡¹ç›®æ–‡ä»¶)
* [Tip23ï¼šæ€ä¹ˆæ‰¹é‡æŠŠç‰¹å¾ä¸­çš„ç¦»ç¾¤ç‚¹ç»™å®‰æ’ä¸€ä¸‹ï¼Ÿ](#Tip23æ€ä¹ˆæ‰¹é‡æŠŠç‰¹å¾ä¸­çš„ç¦»ç¾¤ç‚¹ç»™å®‰æ’ä¸€ä¸‹)
* [Tip24ï¼šå½»åº•äº†è§£ä¸€ä¸‹WOEå’ŒIV](#Tip24å½»åº•äº†è§£ä¸€ä¸‹WOEå’ŒIV)
* [Tip25ï¼šä¸€æ–‡ä»‹ç»ç‰¹å¾å·¥ç¨‹é‡Œçš„å¡æ–¹åˆ†ç®±ï¼Œé™„ä»£ç å®ç°](#tip25ä¸€æ–‡ä»‹ç»ç‰¹å¾å·¥ç¨‹é‡Œçš„å¡æ–¹åˆ†ç®±é™„ä»£ç å®ç°)
* [Tip26ï¼šä»Šå¤©ä¸€èµ·ææ‡‚æœºå™¨å­¦ä¹ é‡Œçš„L1ä¸L2æ­£åˆ™åŒ–](#Tip26ä»Šå¤©ä¸€èµ·ææ‡‚æœºå™¨å­¦ä¹ é‡Œçš„L1ä¸L2æ­£åˆ™åŒ–)
* [Tip27ï¼šé‡‘èé£æ§é‡Œçš„WOEå‰çš„åˆ†ç®±ä¸€å®šè¦å•è°ƒå—ï¼Ÿ](#Tip27é‡‘èé£æ§é‡Œçš„WOEå‰çš„åˆ†ç®±ä¸€å®šè¦å•è°ƒå—)
* [Tip28ï¼šå¦‚ä½•åœ¨Pythonä¸­å¤„ç†ä¸å¹³è¡¡æ•°æ®](#Tip28å¦‚ä½•åœ¨Pythonä¸­å¤„ç†ä¸å¹³è¡¡æ•°æ®)





## Tip1ï¼šç‰¹å¾æ— é‡çº²åŒ–çš„å¸¸è§æ“ä½œæ–¹æ³•

ç¬¬ä¸€æ‹›ï¼Œä»ç®€å•çš„ç‰¹å¾é‡çº²å¤„ç†å¼€å§‹ï¼Œè¿™é‡Œä»‹ç»äº†3ç§æ— é‡çº²åŒ–æ“ä½œçš„æ–¹æ³•ï¼ŒåŒæ—¶ä¹Ÿé™„ä¸Šç›¸å…³çš„åŒ…ä»¥åŠè°ƒç”¨æ–¹æ³•ï¼Œæ¬¢è¿è¡¥å……ï¼

> æ— é‡çº²åŒ–ï¼šå³nondimensionalize æˆ–è€…dimensionlessï¼Œæ˜¯æŒ‡é€šè¿‡ä¸€ä¸ªåˆé€‚çš„å˜é‡æ›¿ä»£ï¼Œå°†ä¸€ä¸ªæ¶‰åŠç‰©ç†é‡çš„æ–¹ç¨‹çš„éƒ¨åˆ†æˆ–å…¨éƒ¨çš„å•ä½ç§»é™¤ï¼Œä»¥æ±‚ç®€åŒ–å®éªŒæˆ–è€…è®¡ç®—çš„ç›®çš„ã€‚â€”â€”ç™¾åº¦ç™¾ç§‘



è¿›è¡Œè¿›ä¸€æ­¥è§£é‡Šï¼Œæ¯”å¦‚æœ‰ä¸¤ä¸ªå­—æ®µï¼Œä¸€ä¸ªæ˜¯è½¦è¡Œèµ°çš„å…¬é‡Œæ•°ï¼Œå¦ä¸€ä¸ªæ˜¯äººè·‘æ­¥çš„è·ç¦»ï¼Œä»–ä»¬ä¹‹é—´çš„å•ä½å…¶å®å·®å¼‚è¿˜æ˜¯æŒºå¤§çš„ï¼Œå…¶å®ä¸¤è€…ä¹‹é—´æ— æ³•è¿›è¡Œæ¯”è¾ƒçš„ï¼Œä½†æ˜¯æˆ‘ä»¬å¯ä»¥è¿›è¡Œå»é‡çº²ï¼ŒæŠŠä»–ä»¬çš„å˜é‡å€¼è¿›è¡Œç¼©æ”¾ï¼Œéƒ½ç»Ÿä¸€åˆ°æŸä¸€ä¸ªåŒºé—´å†…ï¼Œæ¯”å¦‚0-1ï¼Œä¾¿äºä¸åŒå•ä½æˆ–è€…é‡çº§ä¹‹é—´çš„æŒ‡æ ‡å¯ä»¥è¿›è¡Œæ¯”è¾ƒoråŠ æƒï¼

ä¸‹é¢çš„æ˜¯sklearné‡Œçš„ä¸€äº›æ— é‡çº²åŒ–çš„å¸¸è§æ“ä½œæ–¹æ³•ã€‚

```python
from sklearn.datasets import load_iris  
#å¯¼å…¥IRISæ•°æ®é›†  
iris = load_iris()

#æ ‡å‡†åŒ–ï¼Œè¿”å›å€¼ä¸ºæ ‡å‡†åŒ–åçš„æ•°æ®  
from sklearn.preprocessing import StandardScaler  
StandardScaler().fit_transform(iris.data)  

#åŒºé—´ç¼©æ”¾ï¼Œè¿”å›å€¼ä¸ºç¼©æ”¾åˆ°[0, 1]åŒºé—´çš„æ•°æ®  
from sklearn.preprocessing import MinMaxScaler  
MinMaxScaler().fit_transform(iris.data)  

#å½’ä¸€åŒ–ï¼Œè¿”å›å€¼ä¸ºå½’ä¸€åŒ–åçš„æ•°æ®
from sklearn.preprocessing import Normalizer  
Normalizer().fit_transform(iris.data)
```
<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 



## Tip2ï¼šæ€ä¹ˆè¿›è¡Œå¤šé¡¹å¼orå¯¹æ•°çš„æ•°æ®å˜æ¢?

æ•°æ®å˜æ¢ï¼Œè¿™ä¸ªæ“ä½œåœ¨ç‰¹å¾å·¥ç¨‹ä¸­ç”¨å¾—è¿˜æ˜¯è›®å¤šçš„ï¼Œä¸€ä¸ªç‰¹å¾åœ¨å½“å‰çš„åˆ†å¸ƒä¸‹æ— æ³•æœ‰æ˜æ˜¾çš„åŒºåˆ†åº¦ï¼Œä½†ä¸€ä¸ªå°å°çš„å˜æ¢åˆ™å¯ä»¥å¸¦æ¥æ„æƒ³ä¸åˆ°çš„æ•ˆæœï¼Œè€Œè¿™ä¸ªå°å°çš„å˜æ¢ï¼Œä¹Ÿå°±æ˜¯ä»Šå¤©ç»™å¤§å®¶åˆ†äº«çš„å°é”¦å›Šã€‚

#### å¤šé¡¹å¼å˜æ¢

æŒ‰ç…§æŒ‡å®šçš„degreeï¼Œè¿›è¡Œå¤šé¡¹å¼æ“ä½œä»è€Œè¡ç”Ÿå‡ºæ–°å˜é‡(å½“ç„¶è¿™æ˜¯é’ˆå¯¹æ¯ä¸€åˆ—ç‰¹å¾å†…çš„æ“ä½œ)ã€‚

ä¸¾ä¸ªæ —å­ï¼š

```python
from sklearn.datasets import load_iris  
#å¯¼å…¥IRISæ•°æ®é›†  
iris = load_iris()
iris.data[0]

# Output: array([ 5.1,  3.5,  1.4,  0.2])
```

```python
tt = PolynomialFeatures().fit_transform(iris.data)  
tt[0]

# Output: array([  1.  ,   5.1 ,   3.5 ,   1.4 ,   0.2 ,  26.01,  17.85,   7.14, 1.02,  12.25,   4.9 ,   0.7 ,   1.96,   0.28,   0.04])
```

å› ä¸ºPolynomialFeatures()æ–¹æ³•é»˜è®¤degreeæ˜¯2ï¼Œæ‰€ä»¥åªä¼šè¿›è¡ŒäºŒé¡¹å¼çš„è¡ç”Ÿã€‚

ä¸€èˆ¬æ¥è¯´ï¼Œå¤šé¡¹å¼å˜æ¢éƒ½æ˜¯æŒ‰ç…§ä¸‹é¢çš„æ–¹å¼æ¥çš„ï¼š

f = kx + b   ä¸€æ¬¡å‡½æ•°ï¼ˆdegreeä¸º1ï¼‰

f = ax^2 + b*x + w  äºŒæ¬¡å‡½æ•°ï¼ˆdegreeä¸º2ï¼‰

f = a*x^3 + b*x^2 + c*x + w  ä¸‰æ¬¡å‡½æ•°ï¼ˆdegreeä¸º3ï¼‰



è¿™ç±»çš„è½¬æ¢å¯ä»¥é€‚å½“åœ°æå‡æ¨¡å‹çš„æ‹Ÿåˆèƒ½åŠ›ï¼Œå¯¹äºåœ¨çº¿æ€§å›å½’æ¨¡å‹ä¸Šçš„åº”ç”¨è¾ƒä¸ºå¹¿æ³›ã€‚



#### å¯¹æ•°å˜æ¢

è¿™ä¸ªæ“ä½œå°±æ˜¯ç›´æ¥è¿›è¡Œä¸€ä¸ªå¯¹æ•°è½¬æ¢ï¼Œæ”¹å˜åŸå…ˆçš„æ•°æ®åˆ†å¸ƒï¼Œè€Œå¯ä»¥è¾¾åˆ°çš„ä½œç”¨ä¸»è¦æœ‰:

1ï¼‰å–å®Œå¯¹æ•°ä¹‹åå¯ä»¥ç¼©å°æ•°æ®çš„ç»å¯¹æ•°å€¼ï¼Œæ–¹ä¾¿è®¡ç®—ï¼›

2ï¼‰å–å®Œå¯¹æ•°ä¹‹åå¯ä»¥æŠŠä¹˜æ³•è®¡ç®—è½¬æ¢ä¸ºåŠ æ³•è®¡ç®—ï¼›

3ï¼‰è¿˜æœ‰å°±æ˜¯åˆ†å¸ƒæ”¹å˜å¸¦æ¥çš„æ„æƒ³ä¸åˆ°çš„æ•ˆæœã€‚



numpyåº“é‡Œå°±æœ‰å¥½å‡ ç±»å¯¹æ•°è½¬æ¢çš„æ–¹æ³•ï¼Œå¯ä»¥é€šè¿‡from numpy import xxx è¿›è¡Œå¯¼å…¥ä½¿ç”¨ã€‚

logï¼šè®¡ç®—è‡ªç„¶å¯¹æ•°

log10ï¼šåº•ä¸º10çš„log

log2ï¼šåº•ä¸º2çš„log

log1pï¼šåº•ä¸ºeçš„log



#### ä»£ç é›†åˆ

```python
from sklearn.datasets import load_iris  
#å¯¼å…¥IRISæ•°æ®é›†  
iris = load_iris()

#å¤šé¡¹å¼è½¬æ¢  
#å‚æ•°degreeä¸ºåº¦ï¼Œé»˜è®¤å€¼ä¸º2 
from sklearn.preprocessing import PolynomialFeatures  
PolynomialFeatures().fit_transform(iris.data)  

#å¯¹æ•°å˜æ¢
from numpy import log1p  
from sklearn.preprocessing import FunctionTransformer  
#è‡ªå®šä¹‰è½¬æ¢å‡½æ•°ä¸ºå¯¹æ•°å‡½æ•°çš„æ•°æ®å˜æ¢  
#ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯å•å˜å…ƒå‡½æ•°  
FunctionTransformer(log1p).fit_transform(iris.data)  
```
<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 



## Tip3ï¼šå¸¸ç”¨çš„ç»Ÿè®¡å›¾åœ¨Pythoné‡Œæ€ä¹ˆç”»?

è¿™é‡Œçš„è¯æˆ‘ä»¬ä»‹ç»å‡ ç§å¾ˆç®€å•ä½†ä¹Ÿå¾ˆå®ç”¨çš„ç»Ÿè®¡å›¾ç»˜åˆ¶æ–¹æ³•ï¼Œåˆ†åˆ«æœ‰æ¡å½¢å›¾ã€é¥¼å›¾ã€ç®±ä½“å›¾ã€ç›´æ–¹å›¾ä»¥åŠæ•£ç‚¹å›¾ï¼Œå…³äºè¿™å‡ ç§å›¾å½¢çš„å«ä¹‰è¿™è¾¹å°±ä¸å¤šåšè§£é‡Šäº†ã€‚

ä»Šå¤©ç”¨åˆ°ä¸¤ä¸ªæ•°æ®é›†ï¼Œæ•°æ®é›†å¤§å®¶å¯ä»¥åœ¨å…¬ä¼—å·å›å¤"ç‰¹å¾å·¥ç¨‹"æ¥è·å–ï¼Œåˆ†åˆ«æ˜¯**Salary_Ranges_by_Job_Classificationå’ŒGlobalLandTemperaturesByCity**ã€‚

#### æ•ˆæœå›¾ï¼š

![image-20191227230928468](./arrests/1.png)

![image-20191227230949512](./arrests/2.png)

![image-20191227231000989](./arrests/3.png)

![image-20191227231016574](./arrests/4.png)

![image-20191227231027274](./arrests/5.png)



#### ä»£ç é›†åˆ

```python
# å¯¼å…¥ä¸€äº›å¸¸ç”¨åŒ…
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

%matplotlib inline
plt.style.use('fivethirtyeight')

#è§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜ï¼ŒMac
%matplotlib inline
from matplotlib.font_manager import FontProperties


# å¼•å…¥ç¬¬ 1 ä¸ªæ•°æ®é›† Salary_Ranges_by_Job_Classification
salary_ranges = pd.read_csv('./data/Salary_Ranges_by_Job_Classification.csv')

# å¼•å…¥ç¬¬ 2 ä¸ªæ•°æ®é›† GlobalLandTemperaturesByCity
climate = pd.read_csv('./data/GlobalLandTemperaturesByCity.csv')
# ç§»é™¤ç¼ºå¤±å€¼
climate.dropna(axis=0, inplace=True)
# åªçœ‹ä¸­å›½
# æ—¥æœŸè½¬æ¢, å°†dt è½¬æ¢ä¸ºæ—¥æœŸï¼Œå–å¹´ä»½, æ³¨æ„mapçš„ç”¨æ³•
climate['dt'] = pd.to_datetime(climate['dt'])
climate['year'] = climate['dt'].map(lambda value: value.year)
climate_sub_china = climate.loc[climate['Country'] == 'China']
climate_sub_china['Century'] = climate_sub_china['year'].map(lambda x:int(x/100 +1))

# è®¾ç½®æ˜¾ç¤ºçš„å°ºå¯¸
plt.rcParams['figure.figsize'] = (4.0, 4.0) # è®¾ç½®figure_sizeå°ºå¯¸
plt.rcParams['image.interpolation'] = 'nearest' # è®¾ç½® interpolation style
plt.rcParams['image.cmap'] = 'gray' # è®¾ç½® é¢œè‰² style
plt.rcParams['savefig.dpi'] = 100 #å›¾ç‰‡åƒç´ 
plt.rcParams['figure.dpi'] = 100 #åˆ†è¾¨ç‡
plt.rcParams['font.family'] = ['Arial Unicode MS'] #æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡

# ç»˜åˆ¶æ¡å½¢å›¾
salary_ranges['Grade'].value_counts().sort_values(ascending=False).head(10).plot(kind='bar')
# ç»˜åˆ¶é¥¼å›¾
salary_ranges['Grade'].value_counts().sort_values(ascending=False).head(5).plot(kind='pie')
# ç»˜åˆ¶ç®±ä½“å›¾
salary_ranges['Union Code'].value_counts().sort_values(ascending=False).head(5).plot(kind='box')
# ç»˜åˆ¶ç›´æ–¹å›¾
climate['AverageTemperature'].hist()
# ç»˜åˆ¶æ•£ç‚¹å›¾
x = climate_sub_china['year']
y = climate_sub_china['AverageTemperature']
fig, ax = plt.subplots(figsize=(10,5))
ax.scatter(x, y)
plt.show()
```
<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 


## Tip4ï¼šæ€ä¹ˆå»é™¤DataFrameé‡Œçš„ç¼ºå¤±å€¼ï¼Ÿ

è¿™ä¸ªæˆ‘ä»¬ç»å¸¸ä¼šç”¨ï¼Œå½“æˆ‘ä»¬å‘ç°æŸä¸ªå˜é‡çš„ç¼ºå¤±ç‡å¤ªé«˜çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¼šç›´æ¥å¯¹å…¶è¿›è¡Œåˆ é™¤æ“ä½œï¼Œåˆæˆ–è€…è¯´æŸä¸€è¡Œæˆ‘ä¸æƒ³è¦äº†ï¼Œæƒ³å•ç‹¬åˆ é™¤è¿™ä¸€è¡Œæ•°æ®ï¼Œè¿™ä¸ªæˆ‘ä»¬è¯¥æ€ä¹ˆå¤„ç†å‘¢ï¼Ÿè¿™é‡Œä»‹ç»ä¸€ä¸ªæ–¹æ³•ï¼ŒDataFrame.dropna()ï¼Œå…·ä½“å¯ä»¥çœ‹ä¸‹å›¾ï¼š

![image-20191228074829720](./arrests/6.png)

ä»æ–¹æ³•ä»‹ç»å¯ä»¥çœ‹å‡ºï¼Œæˆ‘ä»¬å¯ä»¥æŒ‡å®š `axis` çš„å€¼ï¼Œå¦‚æœæ˜¯0ï¼Œé‚£å°±æ˜¯æŒ‰ç…§è¡Œå»è¿›è¡Œç©ºå€¼åˆ é™¤ï¼Œå¦‚æœæ˜¯1åˆ™æ˜¯æŒ‰ç…§åˆ—å»è¿›è¡Œæ“ä½œï¼Œé»˜è®¤æ˜¯0ã€‚

åŒæ—¶ï¼Œè¿˜æœ‰ä¸€ä¸ªå‚æ•°æ˜¯`how` ,å°±æ˜¯é€‰æ‹©åˆ é™¤çš„æ¡ä»¶ï¼Œå¦‚æœæ˜¯ `any`åˆ™æ˜¯å¦‚æœå­˜åœ¨ä¸€ä¸ªç©ºå€¼ï¼Œåˆ™è¿™è¡Œ(åˆ—)çš„æ•°æ®éƒ½ä¼šè¢«åˆ é™¤ï¼Œå¦‚æœæ˜¯ `all`çš„è¯ï¼Œåªæœ‰å½“è¿™è¡Œ(åˆ—)å…¨éƒ¨çš„å˜é‡å€¼ä¸ºç©ºæ‰ä¼šè¢«åˆ é™¤ï¼Œé»˜è®¤çš„è¯éƒ½æ˜¯`any` ã€‚

å¥½äº†ï¼Œä¸¾å‡ ä¸ªæ —å­ï¼Œæˆ‘ä»¬è¿˜æ˜¯ç”¨climateæ•°æ®é›†ï¼š

```python
# å¼•å…¥æ•°æ®é›†
import pandas as pd
climate = pd.read_csv('./data/GlobalLandTemperaturesByCity.csv')
# ä¿ç•™ä¸€éƒ¨åˆ†åˆ—
data = climate.loc[:,['dt','AverageTemperature','AverageTemperatureUncertainty','City']]
data.head()
```

#### ç»Ÿè®¡æœ‰å¤šå°‘ç¼ºå¤±å€¼

```python
# æŸ¥çœ‹æœ‰å¤šå°‘ç¼ºå¤±å€¼
print(data.isnull().sum())
print('\n')
# æŸ¥çœ‹ç¼ºå¤±å€¼å æ¯”
print(data.isnull().sum()/len(data))
```

![image-20191228081417965](./arrests/7.png)

#### åˆ é™¤æ“ä½œ

```python
# åŸå§‹æ¨¡æ ·
print(data.head())
print('\n')

# é»˜è®¤å‚æ•°axis=0ï¼Œæ ¹æ®ç´¢å¼•(index)åˆ é™¤æŒ‡å®šçš„è¡Œï¼Œåˆ é™¤ç¬¬0è¡Œæ•°æ®
print(data.drop(0).head())
print('\n')

# axis=1,æ ¹æ®åˆ—å(columns)åˆ é™¤æŒ‡å®šçš„åˆ—ï¼Œåˆ é™¤'dt'åˆ—
print(data.drop('dt',axis=1).head())
print('\n')

# ç§»é™¤å«æœ‰ç¼ºå¤±å€¼çš„è¡Œï¼Œç›´æ¥ç»“æœä½œä¸ºæ–°df
data.dropna(axis=0, inplace=True)
```

![image-20191228081435160](./arrests/8.png)

<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 



## Tip5ï¼šæ€ä¹ˆæŠŠè¢«é”™è¯¯å¡«å……çš„ç¼ºå¤±å€¼è¿˜åŸï¼Ÿ

ä¸Šä¸ªå°é”¦å›Šè®²åˆ°æˆ‘ä»¬å¯ä»¥å¯¹ç¼ºå¤±å€¼è¿›è¡Œä¸¢å¼ƒå¤„ç†ï¼Œä½†æ˜¯è¿™ç§æ“ä½œå¾€å¾€ä¼šä¸¢å¤±äº†å¾ˆå¤šä¿¡æ¯çš„ï¼Œå¾ˆå¤šæ—¶å€™æˆ‘ä»¬éƒ½éœ€è¦å…ˆçœ‹çœ‹ç¼ºå¤±çš„åŸå› ï¼Œå¦‚æœæœ‰äº›ç¼ºå¤±æ˜¯æ­£å¸¸å­˜åœ¨çš„ï¼Œæˆ‘ä»¬å°±ä¸éœ€è¦è¿›è¡Œä¸¢å¼ƒï¼Œä¿ç•™ç€å¯¹æˆ‘ä»¬çš„æ¨¡å‹å…¶å®å¸®åŠ©ä¼šæ›´å¤§çš„ã€‚

æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€ç§æƒ…å†µå°±æ˜¯æˆ‘ä»¬ç›´æ¥è¿›è¡Œç»Ÿè®¡ï¼Œå®ƒæ˜¯æ²¡æœ‰ç¼ºå¤±çš„ï¼Œä½†æ˜¯å®é™…ä¸Šæ˜¯ç¼ºå¤±çš„ï¼Œä»€ä¹ˆæ„æ€ï¼Ÿå°±æ˜¯è¯´ç¼ºå¤±è¢«äººä¸ºï¼ˆç³»ç»Ÿï¼‰åœ°è¿›è¡Œäº†å¡«å……ï¼Œæ¯”å¦‚æˆ‘ä»¬å¸¸è§çš„ç”¨0ã€-9ã€-999ã€blankç­‰æ¥è¿›è¡Œå¡«å……ç¼ºå¤±ï¼Œè‹¥çœŸé‡è§è¿™ç§æƒ…å†µï¼Œæˆ‘ä»¬å¯ä»¥è¿™ä¹ˆå¤„ç†å‘¢ï¼Ÿ

å¾ˆç®€å•ï¼Œé‚£å°±æ˜¯**è¿˜åŸç¼ºå¤±ï¼**

#### å•ä¸ªæ“ä½œ

```python
# å¼•å…¥æ•°æ®é›†(çš®é©¬å°ç¬¬å®‰äººç³–å°¿ç—…é¢„æµ‹æ•°æ®é›†)
pima_columns = ['times_pregment','plasma_glucose_concentration','diastolic_blood_pressure','triceps_thickness',
                'serum_insulin','bmi','pedigree_function','age','onset_disbetes']

pima = pd.read_csv('./data/pima.data', names=pima_columns)


# å¤„ç†è¢«é”™è¯¯å¡«å……çš„ç¼ºå¤±å€¼0ï¼Œè¿˜åŸä¸º ç©º(å•ç‹¬å¤„ç†)
pima['serum_insulin'] = pima['serum_insulin'].map(lambda x:x if x !=0 else None)
# æ£€æŸ¥å˜é‡ç¼ºå¤±æƒ…å†µ
pima['serum_insulin'].isnull().sum()

# Outputï¼š374
```



#### æ‰¹é‡æ“ä½œ

```python
# æ‰¹é‡æ“ä½œ è¿˜åŸç¼ºå¤±å€¼
columns = ['serum_insulin','bmi','plasma_glucose_concentration','diastolic_blood_pressure','triceps_thickness']

for col in columns:
    pima[col].replace([0], [None], inplace=True)

# æ£€æŸ¥å˜é‡ç¼ºå¤±æƒ…å†µ
pima.isnull().sum()
```

![image-20191228083228056](./arrests/9.png)

<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 



## Tip6ï¼šæ€ä¹ˆå®šä¹‰ä¸€ä¸ªæ–¹æ³•å»å¡«å……åˆ†ç±»å˜é‡çš„ç©ºå€¼ï¼Ÿ

ä¹‹å‰æˆ‘ä»¬è¯´è¿‡å¦‚ä½•åˆ é™¤æ‰ç¼ºå¤±çš„è¡Œï¼Œä½†æ˜¯å¦‚ä½•æˆ‘ä»¬éœ€è¦çš„æ˜¯å¡«å……å‘¢ï¼Ÿæ¯”å¦‚è¯´ç”¨ä¼—æ•°æ¥å¡«å……ç¼ºå¤±ï¼Œæˆ–è€…ç”¨æŸä¸ªç‰¹å®šå€¼æ¥å¡«å……ç¼ºå¤±å€¼ï¼Ÿè¿™ä¸ªä¹Ÿæ˜¯æˆ‘ä»¬éœ€è¦æŒæ¡çš„ç‰¹å¾å·¥ç¨‹çš„æ–¹æ³•ä¹‹ä¸€ï¼Œå¯¹äºç”¨ç‰¹å®šå€¼å¡«å……ç¼ºå¤±ï¼Œå…¶å®æ¯”è¾ƒç®€å•äº†ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥ç”¨`fillna()` æ–¹æ³•å°±å¯ä»¥ï¼Œä¸‹é¢æˆ‘æ¥è®²ä¸€ä¸ªé€šç”¨çš„åŠæ³•ï¼Œé™¤äº†ç”¨ç‰¹å®šå€¼å¡«å……ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥è‡ªå®šä¹‰ï¼Œæ¯”å¦‚è¯´ç”¨â€ä¼—æ•°â€œæ¥å¡«å……ç­‰ç­‰ã€‚

è¿™é‡Œæˆ‘ä»¬ç”¨åˆ°äº†`TransformerMixin`æ–¹æ³•ï¼Œç„¶åè‡ªå®šä¹‰ä¸€ä¸ªå¡«å……å™¨æ¥è¿›è¡Œç¼ºå¤±å€¼çš„å¡«å……ã€‚

è¿™é‡Œæˆ‘ä»¬é€ ä¸€ä¸ªæ•°æ®é›†æ¥æµ‹è¯•æˆ‘ä»¬çš„ä»£ç ï¼š

```python
# æœ¬æ¬¡æ¡ˆä¾‹ä½¿ç”¨çš„æ•°æ®é›†
import pandas as pd
X = pd.DataFrame({'city':['tokyo',None,'london','seattle','san fancisco','tokyo'],
                  'boolean':['y','n',None,'n','n','y'],
                  'ordinal_column':['somewhat like','like','somewhat like','like','somewhat like','dislike'],
                  'quantitative_column':[1,11,-.5,10,None,20]})
X
```

![image-20191231230535024](./arrests/10.png)



å¯ä»¥çœ‹å‡ºï¼Œè¿™ä¸ªæ•°æ®é›†æœ‰ä¸‰ä¸ªåˆ†ç±»å˜é‡ï¼Œåˆ†åˆ«æ˜¯booleanã€cityå’Œordinal_columnï¼Œè€Œè¿™é‡Œé¢æœ‰ä¸¤ä¸ªå­—æ®µå­˜åœ¨ç©ºå€¼ã€‚



```python
# å¡«å……åˆ†ç±»å˜é‡ï¼ˆåŸºäºTransformerMixinçš„è‡ªå®šä¹‰å¡«å……å™¨ï¼Œç”¨ä¼—æ•°å¡«å……ï¼‰
from sklearn.base import TransformerMixin
class CustomCategoryzImputer(TransformerMixin):
    def __init__(self, cols=None):
        self.cols = cols
        
    def transform(self, df):
        X = df.copy()
        for col in self.cols:
            X[col].fillna(X[col].value_counts().index[0], inplace=True)
        return X
    
    def fit(self, *_):
        return self   
    
# è°ƒç”¨è‡ªå®šä¹‰çš„å¡«å……å™¨
cci = CustomCategoryzImputer(cols=['city','boolean'])
cci.fit_transform(X)
```

![image-20191231230946764](./arrests/11.png)

<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 


## Tip7ï¼šæ€ä¹ˆå®šä¹‰ä¸€ä¸ªæ–¹æ³•å»å¡«å……æ•°å€¼å˜é‡çš„ç©ºå€¼ï¼Ÿ

è¿™ä¸ªé”¦å›Šå’Œä¸Šä¸€ä¸ªå·®ä¸å¤šäº†ï¼Œä¸è¿‡è¿™ä¸ªæ¢ä¸€ä¸ªæ–¹æ³• `Imputer` ã€‚

åŒæ ·çš„ï¼Œæˆ‘ä»¬è¿˜æ˜¯é€ ä¸€ä¸ªæ•°æ®é›†ï¼š

```python
# æœ¬æ¬¡æ¡ˆä¾‹ä½¿ç”¨çš„æ•°æ®é›†
import pandas as pd
X = pd.DataFrame({'city':['tokyo',None,'london','seattle','san fancisco','tokyo'],
                  'boolean':['y','n',None,'n','n','y'],
                  'ordinal_column':['somewhat like','like','somewhat like','like','somewhat like','dislike'],
                  'quantitative_column':[1,11,-.5,10,None,20]})
X
```

![image-20191231230535024](./arrests/10.png)



å¯ä»¥çœ‹å‡ºï¼Œè¿™ä¸ªæ•°æ®é›†æœ‰ä¸€ä¸ªæ•°å€¼å˜é‡`quantitative_columns`ï¼Œå­˜åœ¨ä¸€è¡Œç¼ºå¤±å€¼ï¼Œæˆ‘ä»¬ç›´æ¥è°ƒç”¨`sklearn`çš„`preprocessing`æ–¹æ³•é‡Œçš„`Imputer`ã€‚

```python
# å¡«å……æ•°å€¼å˜é‡ï¼ˆåŸºäºImputerçš„è‡ªå®šä¹‰å¡«å……å™¨ï¼Œç”¨ä¼—æ•°å¡«å……ï¼‰
from sklearn.preprocessing import Imputer
class CustomQuantitativeImputer(TransformerMixin):
    def __init__(self, cols=None, strategy='mean'):
        self.cols = cols
        self.strategy = strategy
        
    def transform(self, df):
        X = df.copy()
        impute = Imputer(strategy=self.strategy)
        for col in self.cols:
            X[col] = impute.fit_transform(X[[col]])
        return X
    
    def fit(self, *_):
        return self
    
# è°ƒç”¨è‡ªå®šä¹‰çš„å¡«å……å™¨
cqi = CustomQuantitativeImputer(cols = ['quantitative_column'], strategy='mean')
cqi.fit_transform(X)
```

![image-20191231231355341](./arrests/12.png)


<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 

## Tip8ï¼šæ€ä¹ˆæŠŠå‡ ä¸ªå›¾è¡¨ä¸€èµ·åœ¨åŒä¸€å¼ å›¾ä¸Šæ˜¾ç¤ºï¼Ÿ

æœªæ¥å‡ ä¸ªç‰¹å¾é”¦å›Šçš„å†…å®¹ä¼šä½¿ç”¨æ³°å¦å°¼å…‹å·çš„æ•°æ®é›†ï¼Œå¤§å®¶å¯ä»¥åœ¨ä¸‹é¢çš„é“¾æ¥å»ä¸‹è½½æ•°æ®å“ˆã€‚

Titanicæ•°æ®é›†ä¸‹è½½ï¼šhttps://www.kaggle.com/c/titanic/data



é¦–å…ˆæˆ‘ä»¬è¦çŸ¥é“ï¼Œåšç‰¹å¾å·¥ç¨‹ä¹‹å‰çŸ¥é“æ•°æ®çš„åˆ†å¸ƒå’Œå…³è”æƒ…å†µæ˜¯æä¸ºé‡è¦çš„ï¼Œå› æ­¤æŠŠè¿™äº›ä¿¡æ¯åšä¸€äº›å¯è§†åŒ–çš„æ“ä½œæ˜¯å¾ˆé‡è¦çš„æ“ä½œå’ŒæŠ€èƒ½ï¼Œä»Šå¤©æˆ‘ä»¬å°±æ¥å­¦ä¹ ä¸‹æ€ä¹ˆç”»å¾ˆå¤šå¼ å›¾ï¼Œç„¶åå¯ä»¥ä¸€å¹¶æ˜¾ç¤ºåœ¨åŒä¸€å¼ ä¸Šå§ï¼Œä¸“ä¸šæ¥è¯´å°±æ˜¯ç”»å­å›¾ã€‚

#### å¯¼å…¥æ•°æ®é›†

```python
# å¯¼å…¥ç›¸å…³åº“
import pandas as pd 
import numpy as np 
from pandas import Series,DataFrame

# å¯¼å…¥æ³°å¦å°¼çš„æ•°æ®é›†
data_train = pd.read_csv("./data/titanic/Train.csv")
data_train.head()
```

![image-20200104150617226](./arrests/13.png)



#### ä»£ç æ±‡é›†

```python
import matplotlib.pyplot as plt

# è®¾ç½®figure_sizeå°ºå¯¸
plt.rcParams['figure.figsize'] = (8.0, 6.0) 

fig = plt.figure()

# è®¾å®šå›¾è¡¨é¢œè‰²
fig.set(alpha=0.2)  

# ç¬¬ä¸€å¼ å°å›¾
plt.subplot2grid((2,3),(0,0))           
data_train['Survived'].value_counts().plot(kind='bar')
plt.ylabel(u"äººæ•°")  
plt.title(u"èˆ¹å‘˜è·æ•‘æƒ…å†µ (1ä¸ºè·æ•‘)")

# ç¬¬äºŒå¼ å°å›¾
plt.subplot2grid((2,3),(0,1))
data_train['Pclass'].value_counts().plot(kind="bar")
plt.ylabel(u"äººæ•°")
plt.title(u"ä¹˜å®¢ç­‰çº§åˆ†å¸ƒ")

# ç¬¬ä¸‰å¼ å°å›¾
plt.subplot2grid((2,3),(0,2))
plt.scatter(data_train['Survived'], data_train['Age'])
plt.ylabel(u"å¹´é¾„") 
plt.grid(b=True, which='major', axis='y') 
plt.title(u"æŒ‰å¹´é¾„çœ‹è·æ•‘åˆ†å¸ƒ (1ä¸ºè·æ•‘)")

# ç¬¬å››å¼ å°å›¾ï¼Œåˆ†å¸ƒå›¾
plt.subplot2grid((2,3),(1,0), colspan=2)
data_train.Age[data_train.Pclass == 1].plot(kind='kde')   
data_train.Age[data_train.Pclass == 2].plot(kind='kde')
data_train.Age[data_train.Pclass == 3].plot(kind='kde')
plt.xlabel(u"å¹´é¾„")
plt.ylabel(u"å¯†åº¦") 
plt.title(u"å„ç­‰çº§çš„ä¹˜å®¢å¹´é¾„åˆ†å¸ƒ")
plt.legend((u'å¤´ç­‰èˆ±', u'2ç­‰èˆ±',u'3ç­‰èˆ±'),loc='best')

# ç¬¬äº”å¼ å°å›¾
plt.subplot2grid((2,3),(1,2))
data_train.Embarked.value_counts().plot(kind='bar')
plt.title(u"å„ç™»èˆ¹å£å²¸ä¸Šèˆ¹äººæ•°")
plt.ylabel(u"äººæ•°")  
plt.show()
```

![image-20200104150744024](./arrests/14.png)

æˆ‘ä»¬ä»ä¸Šé¢çš„å¯è§†åŒ–æ“ä½œç»“æœå¯ä»¥çœ‹å‡ºï¼Œå…¶å®å¯ä»¥çœ‹å‡ºä¸€äº›è§„å¾‹ï¼Œæ¯”å¦‚è¯´ç”Ÿè¿˜çš„å‡ ç‡æ¯”æ­»äº¡çš„è¦å¤§ï¼Œç„¶åè·æ•‘çš„äººåœ¨å¹´é¾„ä¸ŠåŒºåˆ«ä¸å¤§ï¼Œç„¶åå°±æ˜¯æœ‰é’±äººï¼ˆåå¤´ç­‰èˆ±çš„ï¼‰çš„å¹´é¾„ä¼šåå¤§ç­‰ã€‚

<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 



## Tip9ï¼šæ€ä¹ˆæŠŠç”»å‡ºå †ç§¯å›¾æ¥çœ‹å æ¯”å…³ç³»ï¼Ÿ

æœªæ¥å‡ ä¸ªç‰¹å¾é”¦å›Šçš„å†…å®¹ä¼šä½¿ç”¨æ³°å¦å°¼å…‹å·çš„æ•°æ®é›†ï¼Œå¤§å®¶å¯ä»¥åœ¨ä¸‹é¢çš„é“¾æ¥å»ä¸‹è½½æ•°æ®å“ˆã€‚

Titanicæ•°æ®é›†ä¸‹è½½ï¼šhttps://www.kaggle.com/c/titanic/data



ä¸Šæ¬¡çš„é”¦å›Šæˆ‘çŸ¥é“äº†æ€ä¹ˆæŠŠå‡ å¼ å›¾æ”¾åœ¨ä¸€å¼ å›¾ä¸Šå»æ˜¾ç¤ºï¼Œä½†æ˜¯è¿™ä¸ªåªæ˜¯ä¸€ç§æ’ç‰ˆæ–¹å¼çš„æ“ä½œï¼Œä»Šå¤©åˆ†äº«ä¸€ä¸ªç”»å †ç§¯å›¾çš„æ–¹æ³•ï¼Œå¯ä»¥ç”¨æ¥çœ‹ç±»åˆ«å æ¯”å…³ç³»ï¼Œæœ‰åŠ©äºæˆ‘ä»¬å»äº†è§£æ•°æ®ï¼Œå‘ç°æ•°æ®é‡Œçš„è§„å¾‹ã€‚

#### å¯¼å…¥æ•°æ®é›†

```python
# å¯¼å…¥ç›¸å…³åº“
import pandas as pd 
import numpy as np 
from pandas import Series,DataFrame

# å¯¼å…¥æ³°å¦å°¼çš„æ•°æ®é›†
data_train = pd.read_csv("./data/titanic/Train.csv")
data_train.head()
```

![image-20200104150617226](./arrests/13.png)



#### ä»£ç æ±‡é›†

```python
# è®¾ç½®figure_sizeå°ºå¯¸
plt.rcParams['figure.figsize'] = (5.0, 4.0) 

#çœ‹çœ‹å„ä¹˜å®¢ç­‰çº§çš„è·æ•‘æƒ…å†µ
fig = plt.figure()
fig.set(alpha=0.8)

Survived_0 = data_train.Pclass[data_train.Survived == 0].value_counts()
Survived_1 = data_train.Pclass[data_train.Survived == 1].value_counts()
df=pd.DataFrame({u'è·æ•‘':Survived_1, u'æœªè·æ•‘':Survived_0})
df.plot(kind='bar', stacked=True)
plt.title(u"å„ä¹˜å®¢ç­‰çº§çš„è·æ•‘æƒ…å†µ")
plt.xlabel(u"ä¹˜å®¢ç­‰çº§") 
plt.ylabel(u"äººæ•°") 
plt.show()
```

![image-20200105094525846](./arrests/15.png)

<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 



## Tip10ï¼šæ€ä¹ˆå¯¹æ»¡è¶³æŸç§æ¡ä»¶çš„å˜é‡ä¿®æ”¹å…¶å˜é‡å€¼ï¼Ÿ

æœªæ¥å‡ ä¸ªç‰¹å¾é”¦å›Šçš„å†…å®¹ä¼šä½¿ç”¨æ³°å¦å°¼å…‹å·çš„æ•°æ®é›†ï¼Œå¤§å®¶å¯ä»¥åœ¨ä¸‹é¢çš„é“¾æ¥å»ä¸‹è½½æ•°æ®å“ˆã€‚

Titanicæ•°æ®é›†ä¸‹è½½ï¼š

https://www.kaggle.com/c/titanic/data



è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨`loc`å‡½æ•°ï¼Œè¿™ä¸ªæ–¹å¼å®åœ¨æ˜¯å¤ªå¥½ç”¨äº†ï¼

é¦–å…ˆæˆ‘ä»¬å…ˆç†è§£ä¸€ä¸‹è¿™ä¸ª`loc`åº”è¯¥æ€ä¹ˆç”¨å§ï¼Œç„¶åå†ä¸¾å‡ ä¸ªå®æˆ˜ä¾‹å­æ¥ç†è§£ä¸€ä¸‹ã€‚

æˆ‘ä»¬è¦çŸ¥é“locå‡½æ•°çš„æ„æ€å°±æ˜¯é€šè¿‡è¡Œæ ‡ç­¾ç´¢å¼•è¡Œæ•°æ®ï¼Œæœ€ç›´æ¥çš„å°±æ˜¯çœ‹çœ‹æ–‡æ¡£ï¼Œå¼•ç”¨æ–‡æ¡£é‡Œçš„æ•°æ®é›†ï¼š

```python
df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],index=['cobra', 'viper', 'sidewinder'],columns=['max_speed', 'shield'])
df
```

![image-20200105200816439](./arrests/16.png)

ä¸‹é¢çš„å°ä¾‹å­å°±æ˜¯ä»æ–‡æ¡£é‡Œæ‹¿è¿‡æ¥çš„ï¼Œå¾ˆå…¨é¢çš„ç¤ºä¾‹äº†ä¸€äº›åº”ç”¨æ“ä½œã€‚

![image-20200105200936822](./arrests/17.png)

![image-20200105201004990](./arrests/18.png)

é‚£ä¹ˆé€šè¿‡ä¸Šé¢çš„å­¦ä¹ ï¼Œä½ å¤§æ¦‚ä¹ŸçŸ¥é“äº†`loc`çš„ç®€å•ç”¨æ³•äº†ï¼Œä¸‹é¢å°±ä»‹ç»ä¸‹åœ¨ç‰¹å¾å·¥ç¨‹é‡Œæˆ‘ä»¬æ¸…æ´—æŸäº›æ•°æ®æ—¶å€™ï¼Œå¯ä»¥é€šè¿‡è¿™å‡½æ•°æ¥ä¿®æ”¹å˜é‡å€¼ï¼Œä»è€Œè¾¾åˆ°æˆ‘ä»¬çš„æŸäº›ç›®çš„ã€‚



ä¸‹é¢æˆ‘ä»¬è¿˜æ˜¯ç”¨æ³°å¦å°¼å·çš„æ•°æ®é›†ï¼š

```python
# å¯¼å…¥ç›¸å…³åº“
import pandas as pd 
import numpy as np 
from pandas import Series,DataFrame

# å¯¼å…¥æ³°å¦å°¼çš„æ•°æ®é›†
data_train = pd.read_csv("./data/titanic/Train.csv")
data_train['Age'].value_counts().sort_index()
```

![image-20200105201448795](./arrests/19.png)

æˆ‘ä»¬å¯ä»¥çœ‹å‡ºæœ‰äº›å¹´é¾„æœ‰å°äº1å²çš„ï¼Œæ¯”å¦‚0.42ã€0.67ä¹‹ç±»çš„ï¼Œæˆ‘ä»¬è¿™é‡Œå°±ä½¿ç”¨ä¸€ä¸‹`loc`æ¥æŠŠè¿™äº›å°äº1å²çš„ä¿®æ”¹ä¸º1å²å§ï¼Œå¦‚æœæ²¡æœ‰æ„å¤–ï¼Œåº”è¯¥å²æ•°ä¸º1çš„ç»Ÿè®¡æ•°ä¼šå˜ä¸º14ä¸ªã€‚

```python
data_train.loc[(data_train.Age<=1),'Age'] = 1
data_train['Age'].value_counts().sort_index()
```

![image-20200105201854156](./arrests/20.png)

<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 

## Tip11ï¼šæ€ä¹ˆé€šè¿‡æ­£åˆ™æå–å­—ç¬¦ä¸²é‡Œçš„æŒ‡å®šå†…å®¹?

è¿™ä¸ªæ­£åˆ™è¡¨è¾¾å¼åœ¨æˆ‘ä»¬åšå­—ç¬¦æå–ä¸­æ˜¯ååˆ†å¸¸ç”¨çš„ï¼Œå…ˆå‰æœ‰ä¸€ç¯‡æ–‡ç« æœ‰ä»‹ç»åˆ°æ€ä¹ˆå»ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¥å®ç°æˆ‘ä»¬çš„ç›®çš„ï¼Œå¤§å®¶å¯ä»¥å…ˆå›é¡¾ä¸‹è¿™ç¯‡æ–‡ç« ã€‚

[å›¾æ–‡å¹¶èŒ‚åœ°å¸¦ä½ å…¥é—¨æ­£åˆ™è¡¨è¾¾å¼](https://mp.weixin.qq.com/s/F63qWLEWZY6vHGUK3pjnfA)



æˆ‘ä»¬è¿˜æ˜¯ç”¨ä¸€ä¸‹æ³°å¦å°¼å…‹å·çš„æ•°æ®é›†ï¼Œå¤§å®¶å¯ä»¥åœ¨ä¸‹é¢çš„é“¾æ¥å»ä¸‹è½½æ•°æ®å“ˆã€‚

Titanicæ•°æ®é›†ä¸‹è½½ï¼š

https://www.kaggle.com/c/titanic/data

```python
# å¯¼å…¥ç›¸å…³åº“
import pandas as pd 
import numpy as np 
from pandas import Series,DataFrame
import re

# å¯¼å…¥æ³°å¦å°¼çš„æ•°æ®é›†
data_train = pd.read_csv("./data/titanic/Train.csv")
data_train.head()
```

![image-20200106224916692](./arrests/21.png)

æˆ‘ä»¬ç°åœ¨å¯ä»¥æå–ä¸‹è¿™`name`é‡Œçš„ç§°è°“ï¼Œæ¯”å¦‚Mrã€Missä¹‹ç±»çš„ï¼Œä½œä¸ºä¸€ä¸ªæ–°åˆ—ï¼Œä»£ç å¦‚ä¸‹:

```python
data['Title'] = data['Name'].map(lambda x: re.compile(", (.*?)\.").findall(x)[0])
data.head()
```

![image-20200106225032595](./arrests/22.png)



æˆ‘ä»¬ä¹‹å‰çœ‹è¿™ä»£ç å…¶å®æœ‰ç‚¹æ‡µçš„ï¼Œä¸è¿‡è¿™æ˜¯å› ä¸ºå¤§å®¶å¯èƒ½å¯¹æ­£åˆ™è¡¨è¾¾å¼çš„è§„åˆ™ä¸å¤ªç†Ÿæ‚‰ï¼Œæ‰€ä»¥ä¸‹é¢æœ‰å‡ ä¸ªç›¸å…³çš„å¯ä»¥å‚è€ƒä¸‹ã€‚

```python
import re
str = 'xxdaxxabxxacabxxcdabddbxxssbdffbggxx'
# ä¸€ä¸ª'.'å°±æ˜¯åŒ¹é…\n(æ¢è¡Œç¬¦)ä»¥å¤–çš„ä»»ä½•å­—ç¬¦
print(re.findall(r'a.b',str))

# ä¸€ä¸ª'*'å‰é¢çš„å­—ç¬¦å‡ºç°0æ¬¡æˆ–ä»¥ä¸Š
print(re.findall(r'a*b',str))

# åŒ¹é…ä».*å‰é¢çš„å­—ç¬¦ä¸ºèµ·ç‚¹ï¼Œåˆ°åé¢å­—ç¬¦ä¸ºç»ˆç‚¹çš„æ‰€æœ‰å†…å®¹ï¼Œç›´åˆ°è¿”å›æ‰€æœ‰
print(re.findall(r'xx.*xx',str))

# éè´ªå©ªï¼Œå’Œä¸Šé¢çš„ä¸€æ ·ï¼Œä¸è¿‡æ˜¯ç”¨è¿‡ä¸€æ¬¡å°±ä¸ä¼šå†ç”¨,ï¼Œä»¥åˆ—è¡¨çš„å½¢å¼è¿”å›
print(re.findall(r'xx.*?xx',str))

# éè´ªå©ªï¼Œä¸ä¸Šé¢æ˜¯ä¸€æ ·çš„ï¼Œåªæ˜¯ä¸ä¸Šé¢ç›¸æ¯”ï¼Œå¤šäº†ä¸€ä¸ªæ‹¬å·ï¼Œåªä¿ç•™æ‹¬å·ä¸­çš„å†…å®¹
print(re.findall(r'xx(.*?)xx',str))

# ä¿ç•™a,bä¸­é—´çš„å†…å®¹
print(re.findall(r'xx(.+?)xx',str))
print(re.findall(r'xx(.+?)xx',str)[0])
```

![image-20200106225154826](./arrests/23.png)



æ‰€ä»¥ï¼Œçœ‹äº†è¿™äº›åï¼Œåº”è¯¥å°±å¯ä»¥ç†è§£ä¸Šé¢çš„patternçš„å«ä¹‰äº†ï¼


<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 


## Tip12ï¼šå¦‚ä½•åˆ©ç”¨å­—å…¸æ‰¹é‡ä¿®æ”¹å˜é‡å€¼ï¼Ÿ

è¿™é‡Œæˆ‘ä»¬å‡è®¾æœ‰è¿™ä¹ˆä¸€ç§æƒ…å†µï¼Œä¸€ä¸ªå­—æ®µé‡Œçš„å˜é‡å€¼ï¼Œéœ€è¦æŠŠæŸå‡ ä¸ªå˜é‡å€¼ä¿®æ”¹ä¸ºåŒä¸€ä¸ªå€¼ï¼Œç„¶åå…¶ä»–å‡ ä¸ªå˜é‡å€¼ä¿®æ”¹ä¸ºå¦å¤–ä¸€ä¸ªï¼Œé‚£ä¹ˆæˆ‘ä»¬æœ‰ä»€ä¹ˆç®€å•çš„åŠæ³•å¯ä»¥å®Œæˆå‘¢ï¼Ÿè¿™è¾¹ï¼Œæˆ‘æ¨èä¸€ä¸ª**å­—å…¸æ˜ å°„**çš„åŠæ³•ï¼

æˆ‘ä»¬è¿˜æ˜¯ç”¨ä¸€ä¸‹æ³°å¦å°¼å…‹å·çš„æ•°æ®é›†ï¼Œå¤§å®¶å¯ä»¥åœ¨ä¸‹é¢çš„é“¾æ¥å»ä¸‹è½½æ•°æ®å“ˆã€‚

Titanicæ•°æ®é›†ä¸‹è½½ï¼š

https://www.kaggle.com/c/titanic/data

```python
# å¯¼å…¥ç›¸å…³åº“
import pandas as pd 
import numpy as np 
from pandas import Series,DataFrame
import re

# å¯¼å…¥æ³°å¦å°¼çš„æ•°æ®é›†
data_train = pd.read_csv("./data/titanic/Train.csv")
# æå–å…¶ä¸­å‡ åˆ—
data = data_train.loc[:,['PassengerId','Name']]

# æå–ç§°è°“
data['Title'] = data['Name'].map(lambda x: re.compile(", (.*?)\.").findall(x)[0])
data.Title.value_counts()
```

![image-20200108082956766](./arrests/24.png)

å°±å¥½åƒæˆ‘åˆšåˆšæ‰€è¯´çš„ï¼Œéœ€è¦æŠŠé»„è‰²æ¡†æ¡†é‡Œçš„å˜é‡å€¼ä¿®æ”¹æ‰ï¼Œè€Œä¸”æ˜¯æŒ‰ç…§æˆ‘ä»¬çš„æƒ³æ³•ï¼Œæ¯”å¦‚`capt`å’Œ`Dr`åˆä¸ºä¸€ä½“ï¼Œç»Ÿä¸€å«`officer`ã€‚

```python
# å®šä¹‰ä¸€ä¸ªç©ºå­—å…¸æ¥æ”¶é›†æ˜ å°„å…³ç³»
title_Dict = {}
title_Dict.update(dict.fromkeys(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer'))
title_Dict.update(dict.fromkeys(['Don', 'Sir', 'the Countess', 'Dona', 'Lady'], 'Royalty'))
title_Dict.update(dict.fromkeys(['Mme', 'Ms', 'Mrs'], 'Mrs'))
title_Dict.update(dict.fromkeys(['Mlle', 'Miss'], 'Miss'))
title_Dict.update(dict.fromkeys(['Mr'], 'Mr'))
title_Dict.update(dict.fromkeys(['Master','Jonkheer'], 'Master'))
title_Dict
```

![image-20200108083243631](./arrests/25.png)

æˆ‘ä»¬æŠŠæ˜ å°„å…³ç³»ç”¨å­—å…¸æ¥å­˜å‚¨ï¼Œåˆ°æ—¶å€™ç›´æ¥å¯ä»¥æ‹¿æ¥ç”¨ã€‚

```python
data['Title'] = data['Title'].map(title_Dict)
data.Title.value_counts()
```

![image-20200108083335530](./arrests/26.png)


<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 


## Tip13ï¼šå¦‚ä½•å¯¹ç±»åˆ«å˜é‡è¿›è¡Œç‹¬çƒ­ç¼–ç ï¼Ÿ

å¾ˆå¤šæ—¶å€™æˆ‘ä»¬éœ€è¦å¯¹ç±»åˆ«å˜é‡è¿›è¡Œç‹¬çƒ­ç¼–ç ï¼Œç„¶åæ‰å¯ä»¥ä½œä¸ºå…¥å‚ç»™æ¨¡å‹ä½¿ç”¨ï¼Œç‹¬çƒ­çš„æ–¹å¼æœ‰å¾ˆå¤šç§ï¼Œè¿™é‡Œä»‹ç»ä¸€ä¸ªå¸¸ç”¨çš„æ–¹æ³• `get_dummies`å§ï¼Œè¿™ä¸ªæ–¹æ³•å¯ä»¥è®©ç±»åˆ«å˜é‡æŒ‰ç…§æšä¸¾å€¼ç”ŸæˆNä¸ªï¼ˆNä¸ºæšä¸¾å€¼æ•°é‡ï¼‰æ–°å­—æ®µï¼Œéƒ½æ˜¯0-1çš„å˜é‡å€¼ã€‚

æˆ‘ä»¬è¿˜æ˜¯ç”¨åˆ°æˆ‘ä»¬çš„æ³°å¦å°¼å…‹å·çš„æ•°æ®é›†ï¼ŒåŒæ—¶ä½¿ç”¨æˆ‘ä»¬ä¸Šæ¬¡é”¦å›Šåˆ†äº«çš„çŸ¥è¯†ï¼Œå¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†æ“ä½œï¼Œè§ä¸‹ï¼š

```python
# å¯¼å…¥ç›¸å…³åº“
import pandas as pd 
import numpy as np 
from pandas import Series,DataFrame
import re

# å¯¼å…¥æ³°å¦å°¼çš„æ•°æ®é›†
data_train = pd.read_csv("./data/titanic/Train.csv")
# æå–å…¶ä¸­å‡ åˆ—
data = data_train.loc[:,['PassengerId','Name']]

# æå–ç§°è°“
data['Title'] = data['Name'].map(lambda x: re.compile(", (.*?)\.").findall(x)[0])

# å®šä¹‰ä¸€ä¸ªç©ºå­—å…¸æ¥æ”¶é›†æ˜ å°„å…³ç³»
title_Dict = {}
title_Dict.update(dict.fromkeys(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer'))
title_Dict.update(dict.fromkeys(['Don', 'Sir', 'the Countess', 'Dona', 'Lady'], 'Royalty'))
title_Dict.update(dict.fromkeys(['Mme', 'Ms', 'Mrs'], 'Mrs'))
title_Dict.update(dict.fromkeys(['Mlle', 'Miss'], 'Miss'))
title_Dict.update(dict.fromkeys(['Mr'], 'Mr'))
title_Dict.update(dict.fromkeys(['Master','Jonkheer'], 'Master'))
data['Title'] = data['Title'].map(title_Dict)
data.Title.value_counts()
```

![image-20200109203916978](./arrests/27.png)

é‚£ä¹ˆæ¥ä¸‹æ¥æˆ‘ä»¬å¯¹å­—æ®µTitleè¿›è¡Œç‹¬çƒ­ç¼–ç ï¼Œè¿™é‡Œä½¿ç”¨get_dummiesï¼Œç”ŸæˆNä¸ª0-1æ–°å­—æ®µï¼š

```python
# æˆ‘ä»¬å¯¹å­—æ®µTitleè¿›è¡Œç‹¬çƒ­ç¼–ç ï¼Œè¿™é‡Œä½¿ç”¨get_dummiesï¼Œç”ŸæˆNä¸ª0-1æ–°å­—æ®µ
dummies_title = pd.get_dummies(data['Title'], prefix="Title")
data = pd.concat([data,dummies_title], axis=1)
data.head()
```

![image-20200109204023084](./arrests/28.png)

å¯¹äº†ï¼Œè¿™é‡Œæœ‰äº›åŒå­¦å¯èƒ½ä¼šé—®ï¼Œè¿˜æœ‰ä¸€ç§ç‹¬çƒ­ç¼–ç å‡ºæ¥çš„æ˜¯N-1ä¸ªå­—æ®µçš„åˆæ˜¯ä»€ä¹ˆï¼Ÿå¦å¤–è¿™ç§çš„è¯ï¼Œæˆ‘ä»¬æ˜¯ç§°ä¸º`dummy encoding`çš„ï¼Œä¹Ÿå°±æ˜¯å“‘å˜é‡ç¼–ç ï¼Œå®ƒæŠŠä»»æ„ä¸€ä¸ªçŠ¶æ€ä½å»é™¤ï¼Œä¹Ÿå°±æ˜¯è¯´å…¶ä¸­æœ‰ä¸€ç±»å˜é‡å€¼çš„å“‘å˜é‡è¡¨ç¤ºä¸ºå…¨0ã€‚æ›´å¤šçš„å†…å®¹å»ºè®®å¯ä»¥ç™¾åº¦æ·±å…¥äº†è§£å“ˆã€‚

<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 


## Tip14ï¼šå¦‚ä½•æŠŠâ€œå¹´é¾„â€å­—æ®µæŒ‰ç…§æˆ‘ä»¬çš„é˜ˆå€¼åˆ†æ®µï¼Ÿ

æˆ‘ä»¬åœ¨è¿›è¡Œç‰¹å¾å¤„ç†çš„æ—¶å€™ï¼Œä¹Ÿæœ‰çš„æ—¶å€™ä¼šé‡åˆ°ä¸€äº›å˜é‡ï¼Œæ¯”å¦‚è¯´å¹´é¾„ï¼Œç„¶åæˆ‘ä»¬æƒ³è¦æŒ‰ç…§æˆ‘ä»¬æƒ³è¦çš„é˜ˆå€¼è¿›è¡Œåˆ†ç±»ï¼Œæ¯”å¦‚è¯´ä½äº18å²çš„ä½œä¸ºä¸€ç±»ï¼Œ18-30å²çš„ä½œä¸ºä¸€ç±»ï¼Œé‚£ä¹ˆæ€ä¹ˆç”¨Pythonå®ç°çš„å‘¢ï¼Ÿ

æ˜¯çš„ï¼Œæˆ‘ä»¬è¿˜æ˜¯ç”¨åˆ°æˆ‘ä»¬çš„æ³°å¦å°¼å…‹å·çš„æ•°æ®é›†ï¼Œå¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†æ“ä½œï¼Œè§ä¸‹ï¼š

```python
# å¯¼å…¥ç›¸å…³åº“
import pandas as pd 
import numpy as np 
from pandas import Series,DataFrame

# å¯¼å…¥æ³°å¦å°¼çš„æ•°æ®é›†
data_train = pd.read_csv("./data/titanic/Train.csv")
# ä¿®å¤éƒ¨åˆ†ageçš„å€¼
data_train.loc[(data_train.Age<=1),'Age'] = 1
# åªä¿ç•™éƒ¨åˆ†å€¼
data = data_train.loc[:,['PassengerId','Age']]
data.head()
```

![image-20200109204627086](./arrests/29.png)

ç„¶åï¼Œæˆ‘ä»¬ç¼–è¾‘ä»£ç ï¼ŒæŒ‰ç…§æˆ‘ä»¬çš„é¢„æœŸè¿›è¡Œåˆ†ç»„:

```python
# ç¡®å®šé˜ˆå€¼ï¼Œå†™å…¥åˆ—è¡¨
bins = [0, 12, 18, 30, 50, 70, 100]
data['Age_group'] = pd.cut(data['Age'], bins)

dummies_Age = pd.get_dummies(data['Age_group'], prefix= 'Age')
data = pd.concat([data, dummies_Age], axis=1)

data.head()
```

![image-20200109204718102](./arrests/30.png)



è¿™æ ·å­å°±å¾ˆç¥å¥‡äº†å§ï¼ŒæŠŠå¹´é¾„æŒ‰ç…§æˆ‘ä»¬çš„éœ€æ±‚è¿›è¡Œåˆ†ç»„ï¼Œé¡ºä¾¿ä½¿ç”¨ç‹¬çƒ­ç¼–ç ç”Ÿæˆäº†æ–°çš„å­—æ®µã€‚


<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 



## Tip15ï¼šå¦‚ä½•ä½¿ç”¨sklearnçš„å¤šé¡¹å¼æ¥è¡ç”Ÿæ›´å¤šçš„å˜é‡ï¼Ÿ

å…³äºè¿™ç§è¡ç”Ÿå˜é‡çš„æ–¹å¼ï¼Œç†è®ºå…¶å®å¤§å®¶åº”è¯¥å¾ˆæ—©ä¹Ÿéƒ½å¬è¯´è¿‡äº†ï¼Œä½†æ˜¯å¦‚ä½•åœ¨Pythoné‡Œå®ç°ï¼Œä¹Ÿå°±æ˜¯ä»Šå¤©åœ¨è¿™é‡Œåˆ†äº«ç»™å¤§å®¶ï¼Œå…¶å®ä¹Ÿå¾ˆç®€å•ï¼Œå°±æ˜¯è°ƒç”¨`sklearn`çš„`PolynomialFeatures`æ–¹æ³•ï¼Œå…·ä½“å¤§å®¶å¯ä»¥çœ‹çœ‹ä¸‹é¢çš„demoã€‚



è¿™é‡Œä½¿ç”¨ä¸€ä¸ªäººä½“åŠ é€Ÿåº¦æ•°æ®é›†ï¼Œä¹Ÿå°±æ˜¯è®°å½•ä¸€ä¸ªäººåœ¨åšä¸åŒåŠ¨ä½œæ—¶å€™ï¼Œåœ¨ä¸åŒæ–¹å‘ä¸Šçš„åŠ é€Ÿåº¦ï¼Œåˆ†åˆ«æœ‰3ä¸ªæ–¹å‘ï¼Œå‘½åä¸ºxã€yã€zã€‚

```python
# äººä½“èƒ¸éƒ¨åŠ é€Ÿåº¦æ•°æ®é›†,æ ‡ç­¾activityçš„æ•°å€¼ä¸º1-7
'''
1-åœ¨ç”µè„‘å‰å·¥ä½œ
2-ç«™ç«‹ã€èµ°è·¯å’Œä¸Šä¸‹æ¥¼æ¢¯
3-ç«™ç«‹
4-èµ°è·¯
5-ä¸Šä¸‹æ¥¼æ¢¯
6-ä¸äººè¾¹èµ°è¾¹èŠ
7-ç«™ç«‹ç€è¯´è¯

'''
import pandas as pd
df = pd.read_csv('./data/activity_recognizer/1.csv', header=None)
df.columns = ['index','x','y','z','activity']
df.head()

```

![image-20200111200231817](./arrests/31.png)

é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥ç›´æ¥è°ƒç”¨åˆšåˆšè¯´çš„åŠæ³•ï¼Œç„¶åå¯¹äºæ•°å€¼å‹å˜é‡å¤šé¡¹å¼çš„å˜é‡æ‰©å±•ï¼Œä»£ç å¦‚ä¸‹:

```python
# æ‰©å±•æ•°å€¼ç‰¹å¾
from sklearn.preprocessing import PolynomialFeatures

x = df[['x','y','z']]
y = df['activity']

poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)

x_poly = poly.fit_transform(x)
pd.DataFrame(x_poly, columns=poly.get_feature_names()).head()
```

![image-20200111200347306](./arrests/32.png)

<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 


## Tip16ï¼šå¦‚ä½•æ ¹æ®å˜é‡ç›¸å…³æ€§ç”»å‡ºçƒ­åŠ›å›¾ï¼Ÿ

ä¸Šæ¬¡çš„é”¦å›Šæœ‰æåŠåˆ°å¦‚ä½•ä½¿ç”¨`sklearn`æ¥å®ç°å¤šé¡¹å¼çš„æ‰©å±•æ¥è¡ç”Ÿæ›´å¤šçš„å˜é‡ï¼Œä½†æ˜¯æˆ‘ä»¬ä¹ŸçŸ¥é“å…¶å®è¿™æ ·å­å‡ºæ¥çš„å˜é‡ä¹‹é—´çš„ç›¸å…³æ€§æ˜¯å¾ˆå¼ºçš„ï¼Œæˆ‘ä»¬æ€ä¹ˆå¯ä»¥å¯è§†åŒ–ä¸€ä¸‹å‘¢ï¼Ÿè¿™é‡Œä»‹ç»ä¸€ä¸ªçƒ­åŠ›å›¾çš„æ–¹å¼ï¼Œè°ƒç”¨`corr`æ¥å®ç°å˜é‡ç›¸å…³æ€§çš„è®¡ç®—ï¼ŒåŒæ—¶çƒ­åŠ›å›¾ï¼Œé¢œè‰²è¶Šæ·±çš„è¯ï¼Œä»£è¡¨ç›¸å…³æ€§è¶Šå¼ºï¼

```python
# äººä½“èƒ¸éƒ¨åŠ é€Ÿåº¦æ•°æ®é›†,æ ‡ç­¾activityçš„æ•°å€¼ä¸º1-7
'''
1-åœ¨ç”µè„‘å‰å·¥ä½œ
2-ç«™ç«‹ã€èµ°è·¯å’Œä¸Šä¸‹æ¥¼æ¢¯
3-ç«™ç«‹
4-èµ°è·¯
5-ä¸Šä¸‹æ¥¼æ¢¯
6-ä¸äººè¾¹èµ°è¾¹èŠ
7-ç«™ç«‹ç€è¯´è¯

'''
import pandas as pd
from sklearn.preprocessing import PolynomialFeatures

df = pd.read_csv('./data/activity_recognizer/1.csv', header=None)
df.columns = ['index','x','y','z','activity']

x = df[['x','y','z']]
y = df['activity']

# å¤šé¡¹å¼æ‰©å……æ•°å€¼å˜é‡
poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)

x_poly = poly.fit_transform(x)
pd.DataFrame(x_poly, columns=poly.get_feature_names()).head()

# æŸ¥çœ‹çƒ­åŠ›å›¾(é¢œè‰²è¶Šæ·±ä»£è¡¨ç›¸å…³æ€§è¶Šå¼º)
%matplotlib inline
import seaborn as sns

sns.heatmap(pd.DataFrame(x_poly, columns=poly.get_feature_names()).corr())
```

![image-20200111201003846](./arrests/33.png)

<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 


## Tip17ï¼šå¦‚ä½•æŠŠåˆ†å¸ƒä¿®æ­£ä¸ºç±»æ­£æ€åˆ†å¸ƒï¼Ÿ

ä»Šå¤©æˆ‘ä»¬ç”¨çš„æ˜¯ä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼Œä¹Ÿæ˜¯åœ¨kaggleä¸Šçš„ä¸€ä¸ªæ¯”èµ›ï¼Œå¤§å®¶å¯ä»¥å…ˆå»ä¸‹è½½ä¸€ä¸‹ï¼š

![image-20200113205105743](./arrests/34.png)

ä¸‹è½½åœ°å€ï¼šhttps://www.kaggle.com/c/house-prices-advanced-regression-techniques/data

```python
import pandas as pd
import numpy as np
# Plots
import seaborn as sns
import matplotlib.pyplot as plt

# è¯»å–æ•°æ®é›†
train = pd.read_csv('./data/house-prices-advanced-regression-techniques/train.csv')
train.head()

```

![image-20200113210816071](./arrests/35.png)



é¦–å…ˆè¿™ä¸ªæ˜¯ä¸€ä¸ªä»·æ ¼é¢„æµ‹çš„é¢˜ç›®ï¼Œåœ¨å¼€å§‹å‰æˆ‘ä»¬éœ€è¦çœ‹çœ‹åˆ†å¸ƒæƒ…å†µï¼Œå¯ä»¥è°ƒç”¨ä»¥ä¸‹çš„æ–¹æ³•æ¥è¿›è¡Œç»˜åˆ¶ï¼š

```python
sns.set_style("white")
sns.set_color_codes(palette='deep')
f, ax = plt.subplots(figsize=(8, 7))
#Check the new distribution 
sns.distplot(train['SalePrice'], color="b");
ax.xaxis.grid(False)
ax.set(ylabel="Frequency")
ax.set(xlabel="SalePrice")
ax.set(title="SalePrice distribution")
sns.despine(trim=True, left=True)
plt.show()

```

![image-20200113210907623](./arrests/36.png)



æˆ‘ä»¬ä»ç»“æœå¯ä»¥çœ‹å‡ºï¼Œé”€å”®ä»·æ ¼æ˜¯å³åï¼Œè€Œå¤§å¤šæ•°æœºå™¨å­¦ä¹ æ¨¡å‹éƒ½ä¸èƒ½å¾ˆå¥½åœ°å¤„ç†éæ­£æ€åˆ†å¸ƒæ•°æ®ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥åº”ç”¨log(1+x)è½¬æ¢æ¥è¿›è¡Œä¿®æ­£ã€‚é‚£ä¹ˆå…·ä½“æˆ‘ä»¬å¯ä»¥æ€ä¹ˆç”¨Pythonä»£ç å®ç°å‘¢ï¼Ÿ

```python
# log(1+x) è½¬æ¢
train["SalePrice_log"] = np.log1p(train["SalePrice"])

sns.set_style("white")
sns.set_color_codes(palette='deep')
f, ax = plt.subplots(figsize=(8, 7))

sns.distplot(train['SalePrice_log'] , fit=norm, color="b");

# å¾—åˆ°æ­£æ€åˆ†å¸ƒçš„å‚æ•°
(mu, sigma) = norm.fit(train['SalePrice_log'])

plt.legend(['Normal dist. ($\mu=$ {:.2f} and $\sigma=$ {:.2f} )'.format(mu, sigma)],
            loc='best')
ax.xaxis.grid(False)
ax.set(ylabel="Frequency")
ax.set(xlabel="SalePrice")
ax.set(title="SalePrice distribution")
sns.despine(trim=True, left=True)

plt.show()
```

![image-20200113211509700](./arrests/37.png)


<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 

## Tip18ï¼šæ€ä¹ˆæ‰¾å‡ºæ•°æ®é›†ä¸­æœ‰æ•°æ®å€¾æ–œçš„ç‰¹å¾ï¼Ÿ

ä»Šå¤©æˆ‘ä»¬ç”¨çš„æ˜¯ä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼Œä¹Ÿæ˜¯åœ¨kaggleä¸Šçš„ä¸€ä¸ªæ¯”èµ›ï¼Œå¤§å®¶å¯ä»¥å…ˆå»ä¸‹è½½ä¸€ä¸‹ï¼š

![image-20200113205105743](./arrests/34.png)

ä¸‹è½½åœ°å€ï¼šhttps://www.kaggle.com/c/house-prices-advanced-regression-techniques/data

```python
import pandas as pd
import numpy as np
# Plots
import seaborn as sns
import matplotlib.pyplot as plt

# è¯»å–æ•°æ®é›†
train = pd.read_csv('./data/house-prices-advanced-regression-techniques/train.csv')
train.head()
```

![image-20200113210816071](./arrests/35.png)



æˆ‘ä»¬å¯¹æ•°æ®é›†è¿›è¡Œåˆ†æï¼Œé¦–å…ˆæˆ‘ä»¬å¯ä»¥å…ˆçœ‹çœ‹ç‰¹å¾çš„åˆ†å¸ƒæƒ…å†µï¼Œçœ‹ä¸‹å“ªäº›ç‰¹å¾æ˜æ˜¾å°±æ˜¯æœ‰æ•°æ®å€¾æ–œçš„ï¼Œç„¶åå¯ä»¥æ‰¾åŠæ³•è§£å†³ï¼Œå› æ­¤ï¼Œç¬¬ä¸€æ­¥å°±æ˜¯è¦æœ‰åŠæ³•æ‰¾åˆ°è¿™äº›ç‰¹å¾ã€‚

é¦–å…ˆå¯ä»¥é€šè¿‡å¯è§†åŒ–çš„æ–¹å¼ï¼Œç”»ç®±ä½“å›¾ï¼Œç„¶åè§‚å¯Ÿç®±ä½“æƒ…å†µï¼Œç†è®ºçŸ¥è¯†æ˜¯ï¼š

> åœ¨ç®±çº¿å›¾ä¸­ï¼Œç®±å­çš„ä¸­é—´æœ‰ä¸€æ¡çº¿ï¼Œä»£è¡¨äº†æ•°æ®çš„ä¸­ä½æ•°ã€‚ç®±å­çš„ä¸Šä¸‹åº•ï¼Œåˆ†åˆ«æ˜¯æ•°æ®çš„ä¸Šå››åˆ†ä½æ•°ï¼ˆQ3ï¼‰å’Œä¸‹å››åˆ†ä½æ•°ï¼ˆQ1ï¼‰ï¼Œè¿™æ„å‘³ç€ç®±ä½“åŒ…å«äº†50%çš„æ•°æ®ã€‚å› æ­¤ï¼Œ**ç®±å­çš„é«˜åº¦åœ¨ä¸€å®šç¨‹åº¦ä¸Šåæ˜ äº†æ•°æ®çš„æ³¢åŠ¨ç¨‹åº¦**ã€‚ä¸Šä¸‹è¾¹ç¼˜åˆ™ä»£è¡¨äº†è¯¥ç»„æ•°æ®çš„æœ€å¤§å€¼å’Œæœ€å°å€¼ã€‚æœ‰æ—¶å€™ç®±å­å¤–éƒ¨ä¼šæœ‰ä¸€äº›ç‚¹ï¼Œå¯ä»¥ç†è§£ä¸ºæ•°æ®ä¸­çš„â€œ**å¼‚å¸¸å€¼**â€ã€‚è€Œå¯¹äºæ•°æ®å€¾æ–œçš„ï¼Œæˆ‘ä»¬å«åšâ€œåæ€â€ï¼Œä¸æ­£æ€åˆ†å¸ƒç›¸å¯¹ï¼ŒæŒ‡çš„æ˜¯éå¯¹ç§°åˆ†å¸ƒçš„åæ–œçŠ¶æ€ã€‚åœ¨ç»Ÿè®¡å­¦ä¸Šï¼Œä¼—æ•°å’Œå¹³å‡æ•°ä¹‹å·®å¯ä½œä¸ºåˆ†é…åæ€çš„æŒ‡æ ‡ä¹‹ä¸€ï¼šå¦‚å¹³å‡æ•°å¤§äºä¼—æ•°ï¼Œç§°ä¸ºæ­£åæ€ï¼ˆæˆ–å³åæ€ï¼‰ï¼›ç›¸åï¼Œåˆ™ç§°ä¸ºè´Ÿåæ€ï¼ˆæˆ–å·¦åæ€ï¼‰ã€‚



```python
# ä¸¢å¼ƒyå€¼
all_features = train.drop(['SalePrice'], axis=1)

# æ‰¾å‡ºæ‰€æœ‰çš„æ•°å€¼å‹å˜é‡
numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
numeric = []
for i in all_features.columns:
    if all_features[i].dtype in numeric_dtypes:
        numeric.append(i)
        
# å¯¹æ‰€æœ‰çš„æ•°å€¼å‹å˜é‡ç»˜åˆ¶ç®±ä½“å›¾
sns.set_style("white")
f, ax = plt.subplots(figsize=(8, 7))
ax.set_xscale("log")
ax = sns.boxplot(data=all_features[numeric] , orient="h", palette="Set1")
ax.xaxis.grid(False)
ax.set(ylabel="Feature names")
ax.set(xlabel="Numeric values")
ax.set(title="Numeric Distribution of Features")
sns.despine(trim=True, left=True)
```

![image-20200114215939603](./arrests/38.png)

å¯ä»¥çœ‹å‡ºæœ‰ä¸€äº›ç‰¹å¾ï¼Œæœ‰ä¸€äº›æ•°æ®ä¼šåç¦»ç®±ä½“å¤–ï¼Œå› æ­¤å±äºæ•°æ®å€¾æ–œã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬ä»ä¸Šé¢çš„å¯è§†åŒ–ä¸­è™½ç„¶çœ‹å‡ºæ¥äº†ï¼Œä½†æ˜¯æƒ³è¦é€‰å‡ºæ¥è¿˜æ˜¯æ¯”è¾ƒéº»çƒ¦ï¼Œæ‰€ä»¥è¿™é‡Œå¼•å…¥ä¸€ä¸ªåæ€çš„æ¦‚å¿µï¼Œç›¸å¯¹åº”çš„æœ‰ä¸€ä¸ªæŒ‡æ ‡`skew`ï¼Œè¿™ä¸ªå°±æ˜¯ä»£è¡¨åæ€çš„ç³»æ•°ã€‚

> Skewnessï¼šæè¿°æ•°æ®åˆ†å¸ƒå½¢æ€çš„ç»Ÿè®¡é‡ï¼Œå…¶æè¿°çš„æ˜¯æŸæ€»ä½“å–å€¼åˆ†å¸ƒçš„**å¯¹ç§°æ€§**ï¼Œç®€å•æ¥è¯´å°±æ˜¯æ•°æ®çš„ä¸å¯¹ç§°ç¨‹åº¦ã€‚
>
> ååº¦æ˜¯ä¸‰é˜¶ä¸­å¿ƒè·è®¡ç®—å‡ºæ¥çš„ã€‚
>
> ï¼ˆ1ï¼‰Skewness = 0 ï¼Œåˆ†å¸ƒå½¢æ€ä¸æ­£æ€åˆ†å¸ƒååº¦ç›¸åŒã€‚
>
> ï¼ˆ2ï¼‰Skewness > 0 ï¼Œæ­£åå·®æ•°å€¼è¾ƒå¤§ï¼Œä¸ºæ­£åæˆ–å³åã€‚é•¿å°¾å·´æ‹–åœ¨å³è¾¹ï¼Œæ•°æ®å³ç«¯æœ‰è¾ƒå¤šçš„æç«¯å€¼ã€‚
>
> ï¼ˆ3ï¼‰Skewness < 0 ï¼Œè´Ÿåå·®æ•°å€¼è¾ƒå¤§ï¼Œä¸ºè´Ÿåæˆ–å·¦åã€‚é•¿å°¾å·´æ‹–åœ¨å·¦è¾¹ï¼Œæ•°æ®å·¦ç«¯æœ‰è¾ƒå¤šçš„æç«¯å€¼ã€‚
>
> ï¼ˆ4ï¼‰æ•°å€¼çš„ç»å¯¹å€¼è¶Šå¤§ï¼Œè¡¨æ˜æ•°æ®åˆ†å¸ƒè¶Šä¸å¯¹ç§°ï¼Œåæ–œç¨‹åº¦å¤§ã€‚

é‚£ä¹ˆåœ¨Pythoné‡Œå¯ä»¥æ€ä¹ˆå®ç°å‘¢ï¼Ÿ

```python
# æ‰¾å‡ºæ˜æ˜¾åæ€çš„æ•°å€¼å‹å˜é‡
skew_features = all_features[numeric].apply(lambda x: skew(x)).sort_values(ascending=False)

high_skew = skew_features[skew_features > 0.5]
skew_index = high_skew.index

print("æœ¬æ•°æ®é›†ä¸­æœ‰ {} ä¸ªæ•°å€¼å‹å˜é‡çš„ Skew > 0.5 :".format(high_skew.shape[0]))
skewness = pd.DataFrame({'Skew' :high_skew})
skew_features.head(10)
```

![image-20200114220316028](./arrests/39.png)


<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 

## Tip19ï¼šæ€ä¹ˆå°½å¯èƒ½åœ°ä¿®æ­£æ•°æ®å€¾æ–œçš„ç‰¹å¾ï¼Ÿ

ä¸Šä¸€ä¸ªé”¦å›Šï¼Œåˆ†äº«äº†ç»™å¤§å®¶é€šè¿‡`skew`çš„æ–¹æ³•æ¥æ‰¾åˆ°æ•°æ®é›†ä¸­æœ‰æ•°æ®å€¾æ–œçš„ç‰¹å¾ï¼ˆç‰¹å¾é”¦å›Šï¼šæ€ä¹ˆæ‰¾å‡ºæ•°æ®é›†ä¸­æœ‰æ•°æ®å€¾æ–œçš„ç‰¹å¾ï¼Ÿï¼‰ï¼Œé‚£ä¹ˆæ€ä¹ˆå»ä¿®æ­£å®ƒå‘¢ï¼Ÿæ­£æ˜¯ä»Šå¤©è¦åˆ†äº«ç»™å¤§å®¶çš„é”¦å›Šï¼



è¿˜æ˜¯ç”¨åˆ°æˆ¿ä»·é¢„æµ‹çš„æ•°æ®é›†ï¼š

![image-20200113205105743](./arrests/34.png)

ä¸‹è½½åœ°å€ï¼šhttps://www.kaggle.com/c/house-prices-advanced-regression-techniques/data

```python
import pandas as pd
import numpy as np
# Plots
import seaborn as sns
import matplotlib.pyplot as plt

# è¯»å–æ•°æ®é›†
train = pd.read_csv('./data/house-prices-advanced-regression-techniques/train.csv')
train.head()
```

![image-20200113210816071](./arrests/35.png)



æˆ‘ä»¬é€šè¿‡ä¸Šæ¬¡çš„çŸ¥è¯†ï¼ŒçŸ¥é“äº†å¯ä»¥é€šè¿‡`skewness`æ¥è¿›è¡Œå€¾æ–œç‰¹å¾çš„è¾¨åˆ«ï¼Œé‚£ä¹ˆå¯¹äºä¿®æ­£å®ƒçš„åŠæ³•ï¼Œè¿™é‡Œä¹Ÿå…ˆåˆ†äº«ä¸€ä¸ªç†è®ºçŸ¥è¯† â€”â€” **box-coxè½¬æ¢**ã€‚

> çº¿æ€§å›å½’æ¨¡å‹æ»¡è¶³çº¿æ€§æ€§ã€ç‹¬ç«‹æ€§ã€æ–¹å·®é½æ€§ä»¥åŠæ­£æ€æ€§çš„åŒæ—¶ï¼Œåˆä¸ä¸¢å¤±ä¿¡æ¯ï¼Œæ­¤ç§å˜æ¢ç§°ä¹‹ä¸ºBoxâ€”Coxå˜æ¢ã€‚
>
> Box-Coxå˜æ¢æ˜¯Boxå’ŒCoxåœ¨1964å¹´æå‡ºçš„ä¸€ç§å¹¿ä¹‰å¹‚å˜æ¢æ–¹æ³•ï¼Œæ˜¯ç»Ÿè®¡å»ºæ¨¡ä¸­å¸¸ç”¨çš„ä¸€ç§[æ•°æ®](https://baike.baidu.com/item/æ•°æ®/33305)å˜æ¢ï¼Œç”¨äºè¿ç»­çš„å“åº”å˜é‡ä¸æ»¡è¶³æ­£æ€åˆ†å¸ƒçš„æƒ…å†µã€‚Box-Coxå˜æ¢ä¹‹åï¼Œå¯ä»¥ä¸€å®šç¨‹åº¦ä¸Šå‡å°ä¸å¯è§‚æµ‹çš„è¯¯å·®å’Œé¢„æµ‹å˜é‡çš„ç›¸å…³æ€§ã€‚Box-Coxå˜æ¢çš„ä¸»è¦ç‰¹ç‚¹æ˜¯å¼•å…¥ä¸€ä¸ªå‚æ•°ï¼Œé€šè¿‡æ•°æ®æœ¬èº«ä¼°è®¡è¯¥å‚æ•°è¿›è€Œç¡®å®šåº”é‡‡å–çš„æ•°æ®å˜æ¢å½¢å¼ï¼ŒBox-Coxå˜æ¢å¯ä»¥æ˜æ˜¾åœ°æ”¹å–„æ•°æ®çš„æ­£æ€æ€§ã€å¯¹ç§°æ€§å’Œæ–¹å·®ç›¸ç­‰æ€§ï¼Œå¯¹è®¸å¤šå®é™…æ•°æ®éƒ½æ˜¯è¡Œä¹‹æœ‰æ•ˆçš„ã€‚â€”â€” ç™¾åº¦ç™¾ç§‘



åœ¨ä½¿ç”¨å‰ï¼Œæˆ‘ä»¬å…ˆçœ‹çœ‹åŸå…ˆå€¾æ–œçš„ç‰¹å¾æœ‰å¤šå°‘ä¸ªã€‚



```python
# ä¸¢å¼ƒyå€¼
all_features = train.drop(['SalePrice'], axis=1)

# æ‰¾å‡ºæ‰€æœ‰çš„æ•°å€¼å‹å˜é‡
numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
numeric = []
for i in all_features.columns:
    if all_features[i].dtype in numeric_dtypes:
        numeric.append(i)
        
# æ‰¾å‡ºæ˜æ˜¾åæ€çš„æ•°å€¼å‹å˜é‡
skew_features = all_features[numeric].apply(lambda x: skew(x)).sort_values(ascending=False)

high_skew = skew_features[skew_features > 0.5]
skew_index = high_skew.index

print("æœ¬æ•°æ®é›†ä¸­æœ‰ {} ä¸ªæ•°å€¼å‹å˜é‡çš„ Skew > 0.5 :".format(high_skew.shape[0]))
skewness = pd.DataFrame({'Skew' :high_skew})
skew_features
```

> æœ¬æ•°æ®é›†ä¸­æœ‰ 24 ä¸ªæ•°å€¼å‹å˜é‡çš„ Skew > 0.5 :



åœ¨Pythonä¸­æ€ä¹ˆä½¿ç”¨Box-Cox è½¬æ¢å‘¢ï¼Ÿå¾ˆç®€å•ã€‚

```python
# é€šè¿‡ Box-Cox è½¬æ¢ï¼Œä»è€ŒæŠŠå€¾æ–œçš„æ•°æ®è¿›è¡Œä¿®æ­£
for i in skew_index:
    all_features[i] = boxcox1p(all_features[i], boxcox_normmax(all_features[i] + 1))
```



ç„¶åæˆ‘ä»¬å†çœ‹çœ‹è¿˜æœ‰å¤šå°‘ä¸ªæ•°æ®å€¾æ–œçš„ç‰¹å¾å§ï¼

```python
# æ‰¾å‡ºæ˜æ˜¾åæ€çš„æ•°å€¼å‹å˜é‡
skew_features = all_features[numeric].apply(lambda x: skew(x)).sort_values(ascending=False)

high_skew = skew_features[skew_features > 0.5]
skew_index = high_skew.index
print("æœ¬æ•°æ®é›†ä¸­æœ‰ {} ä¸ªæ•°å€¼å‹å˜é‡çš„ Skew > 0.5 :".format(high_skew.shape[0]))
skewness = pd.DataFrame({'Skew' :high_skew})
```

> æœ¬æ•°æ®é›†ä¸­æœ‰ 15 ä¸ªæ•°å€¼å‹å˜é‡çš„ Skew > 0.5 :



å˜å°‘äº†å¾ˆå¤šï¼Œè€Œä¸”å¦‚æœçœ‹ä»–ä»¬çš„skewå€¼ï¼Œä¹Ÿä¼šå‘ç°å˜å°äº†å¾ˆå¤šã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥çœ‹çœ‹è½¬æ¢åçš„ç®±ä½“å›¾æƒ…å†µã€‚

```python
# Let's make sure we handled all the skewed values
sns.set_style("white")
f, ax = plt.subplots(figsize=(8, 7))
ax.set_xscale("log")
ax = sns.boxplot(data=all_features[skew_index] , orient="h", palette="Set1")
ax.xaxis.grid(False)
ax.set(ylabel="Feature names")
ax.set(xlabel="Numeric values")
ax.set(title="Numeric Distribution of Features")
sns.despine(trim=True, left=True)
```

![image-20200117212535708](./arrests/40.png)

<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 
 
## Tip20ï¼šæ€ä¹ˆç®€å•ä½¿ç”¨PCAæ¥åˆ’åˆ†æ•°æ®ä¸”å¯è§†åŒ–å‘¢ï¼Ÿ

PCAç®—æ³•åœ¨æ•°æ®æŒ–æ˜ä¸­æ˜¯å¾ˆåŸºç¡€çš„é™ç»´ç®—æ³•ï¼Œç®€å•å›é¡¾ä¸€ä¸‹å®šä¹‰ï¼š

> PCAï¼Œå…¨ç§°ä¸ºPrincipal Component Analysisï¼Œä¹Ÿå°±æ˜¯ä¸»æˆåˆ†åˆ†ææ–¹æ³•ï¼Œæ˜¯ä¸€ç§é™ç»´ç®—æ³•ï¼Œå…¶åŠŸèƒ½å°±æ˜¯æŠŠNç»´çš„ç‰¹å¾ï¼Œé€šè¿‡è½¬æ¢æ˜ å°„åˆ°Kç»´ä¸Šï¼ˆK<Nï¼‰ï¼Œè¿™äº›ç”±åŸå…ˆNç»´çš„æŠ•å°„åçš„Kä¸ªæ­£äº¤ç‰¹å¾ï¼Œå°±è¢«ç§°ä¸ºä¸»æˆåˆ†ã€‚



æˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨çš„æ•°æ®é›†irisï¼Œæ¥å¼„ä¸€ä¸ªdemoï¼š

```python
# å¯¼å…¥ç›¸å…³åº“
from sklearn.datasets import load_iris
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
%matplotlib inline

#è§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜ï¼ŒMac
%matplotlib inline
from matplotlib.font_manager import FontProperties
# è®¾ç½®æ˜¾ç¤ºçš„å°ºå¯¸
plt.rcParams['font.family'] = ['Arial Unicode MS'] #æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡

# å¯¼å…¥æ•°æ®é›†
iris = load_iris()
iris_x, iris_y = iris.data, iris.target

# å®ä¾‹åŒ–
pca = PCA(n_components=2)

# è®­ç»ƒæ•°æ®
pca.fit(iris_x)
pca.transform(iris_x)[:5,]

# è‡ªå®šä¹‰ä¸€ä¸ªå¯è§†åŒ–çš„æ–¹æ³•
label_dict = {i:k for i,k in enumerate(iris.target_names)}
def plot(x,y,title,x_label,y_label):
    ax = plt.subplot(111)
    for label,marker,color in zip(
    range(3),('^','s','o'),('blue','red','green')):
        plt.scatter(x=x[:,0].real[y == label],
                   y = x[:,1].real[y == label],
                   color = color,
                   alpha = 0.5,
                   label = label_dict[label]
                   )
        
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    
    leg = plt.legend(loc='upper right', fancybox=True)
    leg.get_frame().set_alpha(0.5)
    plt.title(title)

# å¯è§†åŒ–
plot(iris_x, iris_y,"åŸå§‹çš„irisæ•°æ®é›†","sepal length(cm)","sepal width(cm)")
plt.show()

plot(pca.transform(iris_x), iris_y,"PCAè½¬æ¢åçš„å¤´ä¸¤ä¸ªæ­£äº¤ç‰¹å¾","PCA1","PCA2")
```

![image-20200129161705398](./arrests/41.png)

æˆ‘ä»¬é€šè¿‡è‡ªå®šä¹‰çš„ç»˜å›¾å‡½æ•°`plot`ï¼ŒæŠŠä¸åŒç±»åˆ«çš„yå€¼è¿›è¡Œä¸åŒé¢œè‰²çš„æ˜¾ç¤ºï¼Œä»è€Œçœ‹å‡ºåœ¨å€¼åŸŸä¸Šåˆ†å¸ƒçš„å·®å¼‚ã€‚ä»åŸå§‹çš„ç‰¹å¾æ¥çœ‹ï¼Œä¸åŒç±»åˆ«ä¹‹é—´å…¶å®ç•Œé™å¹¶ä¸æ˜¯ååˆ†æ˜æ˜¾ï¼Œå¦‚ä¸Šå›¾æ‰€ç¤ºã€‚è€Œè¿›è¡ŒPCAè½¬æ¢åï¼Œå¯ä»¥çœ‹å‡ºä¸åŒç±»åˆ«ä¹‹é—´çš„ç•Œé™æœ‰äº†æ¯”è¾ƒæ˜æ˜¾çš„å·®å¼‚ã€‚

<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 



## Tip21ï¼šæ€ä¹ˆç®€å•ä½¿ç”¨LDAæ¥åˆ’åˆ†æ•°æ®ä¸”å¯è§†åŒ–å‘¢ï¼Ÿ

LDAç®—æ³•åœ¨æ•°æ®æŒ–æ˜ä¸­æ˜¯å¾ˆåŸºç¡€çš„ç®—æ³•ï¼Œç®€å•å›é¡¾ä¸€ä¸‹å®šä¹‰ï¼š

> LDAçš„å…¨ç§°ä¸ºLinear Discriminant Analysis, ä¸­æ–‡ä¸ºçº¿æ€§åˆ¤åˆ«åˆ†æï¼ŒLDAæ˜¯ä¸€ç§æœ‰ç›‘ç£å­¦ä¹ çš„ç®—æ³•ï¼Œå’ŒPCAä¸åŒã€‚PCAæ˜¯æ— ç›‘ç£ç®—æ³•ï¼Œã€‚LDAæ˜¯â€œæŠ•å½±åç±»å†…æ–¹å·®æœ€å°ï¼Œç±»é—´æ–¹å·®æœ€å¤§â€ï¼Œä¹Ÿå°±æ˜¯å°†æ•°æ®æŠ•å½±åˆ°ä½ç»´åº¦ä¸Šï¼ŒæŠ•å½±åå¸Œæœ›æ¯ä¸€ç§ç±»åˆ«æ•°æ®çš„æŠ•å½±ç‚¹å°½å¯èƒ½çš„æ¥è¿‘ï¼Œè€Œä¸åŒç±»åˆ«çš„æ•°æ®çš„ç±»åˆ«ä¸­å¿ƒä¹‹é—´çš„è·ç¦»å°½å¯èƒ½çš„å¤§ã€‚

æˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨çš„æ•°æ®é›†irisï¼Œæ¥å¼„ä¸€ä¸ªdemoï¼š

```python
# å¯¼å…¥ç›¸å…³åº“
from sklearn.datasets import load_iris
import matplotlib.pyplot as plt
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
%matplotlib inline

#è§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜ï¼ŒMac
%matplotlib inline
from matplotlib.font_manager import FontProperties
# è®¾ç½®æ˜¾ç¤ºçš„å°ºå¯¸
plt.rcParams['font.family'] = ['Arial Unicode MS'] #æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡

# å¯¼å…¥æ•°æ®é›†
iris = load_iris()
iris_x, iris_y = iris.data, iris.target

# å®ä¾‹åŒ–
lda = LinearDiscriminantAnalysis(n_components=2)

# è®­ç»ƒæ•°æ®
x_lda_iris = lda.fit_transform(iris_x, iris_y)


# è‡ªå®šä¹‰ä¸€ä¸ªå¯è§†åŒ–çš„æ–¹æ³•
label_dict = {i:k for i,k in enumerate(iris.target_names)}
def plot(x,y,title,x_label,y_label):
    ax = plt.subplot(111)
    for label,marker,color in zip(
    range(3),('^','s','o'),('blue','red','green')):
        plt.scatter(x=x[:,0].real[y == label],
                   y = x[:,1].real[y == label],
                   color = color,
                   alpha = 0.5,
                   label = label_dict[label]
                   )
        
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    
    leg = plt.legend(loc='upper right', fancybox=True)
    leg.get_frame().set_alpha(0.5)
    plt.title(title)

# å¯è§†åŒ–
plot(iris_x, iris_y,"åŸå§‹çš„irisæ•°æ®é›†","sepal length(cm)","sepal width(cm)")
plt.show()

plot(x_lda_iris, iris_y, "LDA Projection", "LDA1", "LDA2")
```

![image-20200129174752001](./arrests/42.png)

<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 
## Tip22ï¼šæ€ä¹ˆæ¥ç®¡ç†æˆ‘ä»¬çš„å»ºæ¨¡é¡¹ç›®æ–‡ä»¶ï¼Ÿ

è¿™ä¸ªä¸“é¢˜å…¶å®å¾ˆä¹…ä¹‹å‰åœ¨æˆ‘çš„ä¸€ç¯‡æ–‡ç« é‡Œæœ‰æ¯”è¾ƒè¯¦ç»†çš„ä»‹ç»ï¼Œå¯ä»¥æˆ³[ã€Šåˆ†äº«8ç‚¹è¶…çº§æœ‰ç”¨çš„Pythonç¼–ç¨‹å»ºè®®ã€‹](https://mp.weixin.qq.com/s/eOeXA0ctErvd2mmEexZcBA)ï¼Œä½†æ˜¯ä»Šå¤©æˆ‘è¿˜æ˜¯æƒ³æŠŠå…¶ä¸­çš„ä¸€ä¸ªå†…å®¹é‡ç‚¹æ¥è¯´ä¸€ä¸‹ï¼Œå¤§å®¶å¯ä»¥å…ˆçœ‹çœ‹è¿™å¼ å›¾ï¼Œè¿™ä¸ªæˆ‘ä»¬åœ¨åšå»ºæ¨¡é¡¹ç›®æ—¶ï¼Œä¸ªäººæ¯”è¾ƒæ¨èçš„ä¸€ä¸ªå»ºé¡¹ç›®æ–‡ä»¶çš„demoã€‚



![image-20200129174752001](./arrests/43.png)



è¿™ä¸ªé¡¹ç›®æ–‡ä»¶ç»“æ„æ˜¯æˆ‘å¹³æ—¶ç»å¸¸ç”¨çš„ï¼Œä¼šæ ¹æ®é¡¹ç›®å¤æ‚åº¦è‡ªè¡Œåˆ å‡ä¸€äº›å†…å®¹ï¼Œä¸è¿‡æ€»ä½“çš„æ¡†æ¶è¿˜æ˜¯å·®ä¸å¤šçš„ï¼Œæ‰€ä»¥åˆ†äº«ç»™å¤§å®¶å‚è€ƒä¸‹å‘—ï¼Œå› ä¸ºä¸ªäººç”¨èµ·æ¥è¿˜æ˜¯è›®ä¸é”™çš„ï¼Œå›¾ç‰‡é‡Œè®²äº†è¿˜æ˜¯æ¯”è¾ƒè¯¦ç»†çš„äº†ï¼Œä¸è¿‡æˆ‘è¿˜æ˜¯æŒ‘ä¸€äº›é‡ç‚¹æ¥ç®€å•è§£é‡Šä¸€ä¸‹ï¼š

* experimentï¼šä¸“é—¨ç”¨æ¥å­˜æ”¾æˆ‘ä»¬çš„å®éªŒæ–‡ä»¶ï¼Œä¹Ÿå°±æ˜¯é‚£äº›ä¸æ–­åœ°æµ‹è¯•ç®—æ³•çš„ä¸­é—´æ–‡ä»¶ã€‚
* modelï¼šå­˜æ”¾ä¸åŒç®—æ³•çš„æœ€ç»ˆç‰ˆæœ¬ä»£ç çš„æ–‡ä»¶å¤¹
* dataï¼šå­˜æ”¾æ•°æ®çš„æ–‡ä»¶å¤¹ï¼Œé‡Œé¢è¿˜ä¼šåˆ†ä¸åŒç±»åˆ«å»å­˜æ”¾æ•°æ®ï¼Œæ¯”å¦‚externalï¼ˆæ¥è‡ªç¬¬ä¸‰æ–¹çš„æ•°æ®ï¼‰ã€interimï¼ˆç»è¿‡éƒ¨åˆ†æ¸…æ´—è½¬æ¢çš„æ•°æ®æºï¼Œå¦‚SQLã€SASï¼‰ã€rawï¼ˆåŸå§‹æ•°æ®é›†ï¼Œä¸æ·»åŠ ä»»ä½•åŠ å·¥ï¼‰ã€processedï¼ˆæœ€ç»ˆç”¨äºå»ºæ¨¡çš„æ•°æ®é›†ï¼‰ã€codeï¼ˆç”¨äºå‚¨å­˜æ•°æ®æ¸…æ´—çš„ä»£ç ï¼‰

<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>
 
## Tip23ï¼šæ€ä¹ˆæ‰¹é‡æŠŠç‰¹å¾ä¸­çš„ç¦»ç¾¤ç‚¹ç»™å®‰æ’ä¸€ä¸‹ï¼Ÿ

è¿™ä¸ªä¸“æ åœäº†ä¹Ÿæœ‰ä¸€æ®µæ—¶é—´äº†ï¼Œè‡ªä»ä¸Šæ¬¡å¯¹ä¹‹å‰çš„å†…å®¹è¿›è¡Œäº†ä¸€æ¬¡æ¢³ç†ä¹‹åï¼Œä¼¼ä¹æ˜¯ç»™è‡ªå·±ä¸€ä¸ªâ€œå€Ÿå£â€ä¼‘æ¯äº†ä¸€é˜µå­ï¼Œç°åœ¨æ„Ÿè§‰è¿˜æ˜¯å¾—é‡æ–°æ‹¿å‡ºæ¥ç»§ç»­æ›´æ–°äº†ã€‚

```python
# å¯¼å…¥æ•°æ®é›†
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

train = pd.read_csv('./data/Group-Image-of-Consumers/train_dataset.csv')
test = pd.read_csv('./data/Group-Image-of-Consumers/test_dataset.csv')
data = pd.concat([train, test], ignore_index=True)
data.head()
```

![image-20200403211901868](./arrests/44.png)

æˆ‘ä»¬ç®€å•ä»é‡Œé¢æŒ‘é€‰å‡ ä¸ªæ•°å€¼å‹å˜é‡æ¥çœ‹çœ‹åˆ†å¸ƒæƒ…å†µå§ï¼Œç”»å›¾çš„æŠ€å·§è¿™é‡Œå°±ä¸è¯´äº†ï¼Œå¯ä»¥å‚è€ƒä¹‹å‰ç”»ç®±ä½“å›¾çš„é‚£ç¯‡é•œå›Šæ–‡ç« ã€‚

```python
# æŒ‘é€‰å…¶ä¸­å‡ ä¸ªå˜é‡
feature_list=['å½“æœˆç½‘è´­ç±»åº”ç”¨ä½¿ç”¨æ¬¡æ•°','å½“æœˆé‡‘èç†è´¢ç±»åº”ç”¨ä½¿ç”¨æ€»æ¬¡æ•°','å½“æœˆè§†é¢‘æ’­æ”¾ç±»åº”ç”¨ä½¿ç”¨æ¬¡æ•°']

# ç»˜åˆ¶ç®±ä½“å›¾
sns.set_style("white")
f, ax = plt.subplots(figsize=(8, 7))
ax.set_xscale("log")
ax = sns.boxplot(data=data[feature_list] , orient="h", palette="Set1")
ax.xaxis.grid(False)
ax.set(ylabel="Feature names")
ax.set(xlabel="Numeric values")
ax.set(title="Numeric Distribution of Features")
sns.despine(trim=True, left=True)
```

![image-20200403212339978](./arrests/45.png)

å¯ä»¥çœ‹åˆ°çº¢è‰²æ¡†æ¡†åœˆèµ·æ¥çš„å°±æ˜¯æˆ‘ä»¬çš„ç¦»ç¾¤ç‚¹ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥æ€ä¹ˆå¤„ç†ä¸€ä¸‹å‘¢ï¼Ÿè¿™é‡Œç»™å¤§å®¶ä»‹ç»ä¸€ä¸ªæ–¹æ³•ï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
def process(all_data,feature_list):
    #å¤„ç†ç¦»ç¾¤ç‚¹
    for col in feature_list:
        ulimit=np.percentile(all_data[col].values, 99.9) #è®¡ç®—ä¸€ä¸ªå¤šç»´æ•°ç»„çš„ä»»æ„ç™¾åˆ†æ¯”åˆ†ä½æ•°
        llimit=np.percentile(all_data[col].values, 0.1)
        all_data.loc[all_data[col]>ulimit,col]=ulimit  # å¤§äº99.9%çš„ç›´æ¥èµ‹å€¼
        all_data.loc[all_data[col]<llimit,col]=llimit
    return all_data
```

ä½¿ç”¨åˆšåˆšæˆ‘ä»¬ç¼–å†™çš„é‚£ä¸ªæ–¹æ³•ï¼š

```python
# ä½¿ç”¨å‡½æ•°è¿›è¡Œæç«¯å€¼çš„è½¬æ¢
data_new = process(data,feature_list)

# ç»˜åˆ¶ç®±ä½“å›¾
sns.set_style("white")
f, ax = plt.subplots(figsize=(8, 7))
ax.set_xscale("log")
ax = sns.boxplot(data=data_new[feature_list] , orient="h", palette="Set1")
ax.xaxis.grid(False)
ax.set(ylabel="Feature names")
ax.set(xlabel="Numeric values")
ax.set(title="Numeric Distribution of Features")
sns.despine(trim=True, left=True)
```

![image-20200403212552077](./arrests/46.png)

see!æˆ‘ä»¬çš„å¼‚å¸¸å€¼å°±ä¼šè¢«ç›´æ¥â€œå®‰æ’â€äº†ï¼Œæ˜¯ä¸æ˜¯å¾ˆç®€å•å‘¢ï¼Ÿå…¶å®å¼‚å¸¸å€¼çš„å¤„ç†è¿˜æ˜¯æœ‰å¾ˆå¤§æ–¹æ³•çš„ï¼Œä»Šå¤©å°±æŠ›ç –å¼•ç‰ä¸€ä¸‹ï¼Œæ›´å¤šçš„æ–¹æ³•ç­‰å¾…å¤§å®¶å»æŒ–æ˜å“¦ï¼

<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>

## Tip24ï¼šå½»åº•äº†è§£ä¸€ä¸‹WOEå’ŒIV

ç¬¬ä¸€æ¬¡æ¥è§¦è¿™ä¸¤ä¸ªåè¯æ˜¯åœ¨åšé£æ§æ¨¡å‹çš„æ—¶å€™ï¼Œè€å¸ˆæ•™æˆ‘ä»¬å¯ä»¥ç”¨IVå»åšå˜é‡ç­›é€‰ï¼ŒIVï¼ˆInformation Valueï¼‰ï¼Œä¸­æ–‡åæ˜¯ä¿¡æ¯å€¼ï¼Œç®€å•æ¥è¯´è¿™ä¸ªæŒ‡æ ‡çš„ä½œç”¨å°±æ˜¯æ¥è¡¡é‡å˜é‡çš„é¢„æµ‹èƒ½åŠ›å¼ºå¼±çš„ï¼Œç„¶åIVåˆæ˜¯WOEç®—å‡ºæ¥çš„ã€‚å§‘ä¸”å…ˆä¸ç®¡åŸç†å“ˆï¼Œæˆ‘ä»¬å…ˆç»™å‡ºæ¥ä¸€ä¸‹ç»“è®ºã€‚

| IVèŒƒå›´    | å˜é‡é¢„æµ‹åŠ› |
| --------- | ---------- |
| <0.02     | æ— é¢„æµ‹åŠ›ğŸ˜¯  |
| 0.02~0.10 | å¼±ğŸ‘        |
| 0.10~0.30 | ä¸­ç­‰ğŸ˜Š      |
| `> 0.30   | å¼ºğŸ‘        |

è™½ç„¶å¯èƒ½è¿™ä¸ªæŒ‡æ ‡è¿˜æ˜¯å¾ˆå®¹æ˜“å°±å¯ä»¥ä½¿ç”¨ï¼Œä½†æ˜¯äº†è§£å®ƒçš„åŸç†æ˜¯ååˆ†é‡è¦çš„ï¼Œè¿™å¯¹äºæˆ‘ä»¬æ·±å…¥ç†è§£å˜é‡æœ‰å¾ˆå¤§çš„å¸®åŠ©ã€‚



åœ¨å¼€å§‹è®²åŸç†å‰ï¼Œå…ˆçº¦å®šä¸€ä¸‹ä»Šå¤©ä¼šç”¨åˆ°çš„ä¸€äº›ä»£å·ã€‚

$y_i$ : ç¬¬iç»„ä¸­å“åº”å®¢æˆ·æ•°é‡

$y_{all}$ : å…¨éƒ¨å“åº”å®¢æˆ·æ•°é‡æ€»å’Œ

$n_i$ ï¼šç¬¬iç»„ä¸­æœªå“åº”å®¢æˆ·æ•°é‡

$n_{all}$ ï¼šå…¨éƒ¨æœªå“åº”å®¢æˆ·æ•°é‡æ€»å’Œ

å“åº”/æœªå“åº”ï¼šæŒ‡çš„æ˜¯è‡ªå˜é‡æ¯ä¸ªè®°å½•å¯¹åº”çš„ç›®æ ‡å˜é‡çš„å€¼ï¼Œç›®æ ‡å˜é‡çš„å€¼ä¸º0æˆ–1ï¼Œä¸€èˆ¬å¦‚æœ1ä¸ºå“åº”çš„è¯ï¼Œ0å°±æ˜¯æœªå“åº”ã€‚

$IV_i$ï¼šç¬¬iç»„çš„IVå€¼

$Py_i$ï¼šç­‰äº $y_i/y_{all}$

$Pn_i$ï¼šç­‰äº $n_i/n_{all}$

å¯ä»¥çœ‹çœ‹ä¸‹é¢çš„è¡¨æ ¼ç†è§£ä¸€æ³¢ï¼Œå˜é‡Aæ˜¯ä¸€ä¸ªè¿ç»­å‹å˜é‡ï¼Œå€¼åŸŸæ˜¯v1-vxï¼Œå½“å‰æ ¹æ®æŸäº›åˆ†ç®±æ–¹å¼åˆ†æˆäº†mç»„ï¼Œå…·ä½“çš„åˆ†ç»„æƒ…å†µå¦‚ä¸‹æ‰€ç¤ºï¼š

![image-20200730223421518](./arrests/48.png)



#### WOEçš„åŸç†

WOEæ˜¯weight of evidenceçš„ç¼©å†™ï¼Œæ˜¯ä¸€ç§ç¼–ç å½¢å¼ï¼Œé¦–å…ˆæˆ‘ä»¬è¦çŸ¥é“WOEæ˜¯é’ˆå¯¹ç±»åˆ«å˜é‡è€Œè¨€çš„ï¼Œæ‰€ä»¥è¿ç»­æ€§å˜é‡éœ€è¦æå‰åšå¥½åˆ†ç»„ï¼ˆè¿™é‡Œä¹Ÿæ˜¯ä¸€ä¸ªå¾ˆå¥½çš„è€ƒç‚¹ï¼Œä¹Ÿæœ‰ä¼šè¯´åˆ†ç®±ã€ç¦»æ•£åŒ–çš„ï¼Œå˜é‡ä¼˜åŒ–ä¹Ÿå¯ä»¥ä»è¿™ä¸ªè§’åº¦å‡ºå‘ï¼‰ã€‚

å…ˆç»™å‡ºæ•°å­¦è®¡ç®—å…¬å¼ï¼Œå¯¹äºç¬¬iç»„çš„WOEå¯ä»¥è¿™ä¹ˆè®¡ç®—ï¼š

$$WOE_i = ln(\frac{y_i/y_{all}}{n_i/n_{all}})$$

ä»å…¬å¼ä¸Šå¯ä»¥çœ‹å‡ºï¼Œç¬¬iç»„çš„WOEå€¼ç­‰äºè¿™ä¸ªç»„çš„å“åº”å®¢æˆ·å æ‰€æœ‰å“åº”å®¢æˆ·çš„æ¯”ä¾‹ä¸æœªå“åº”å®¢æˆ·å æ‰€æœ‰æœªå“åº”å®¢æˆ·çš„æ¯”ä¾‹çš„æ¯”å€¼å–å¯¹æ•°ã€‚å¯¹äºä¸Šé¢çš„å…¬å¼æˆ‘ä»¬è¿˜å¯ä»¥ ç®€å•åšä¸€ä¸‹è½¬åŒ–ï¼š

$$WOE_i = ln(\frac{y_i/y_{all}}{n_i/n_{all}}) = ln(\frac{y_i/n_i}{y_{all}/n_{all}})$$

æ‰€ä»¥ï¼ŒWOEä¸»è¦å°±æ˜¯ä½“ç°ç»„å†…çš„å¥½åå æ¯”ä¸æ•´ä½“çš„å·®å¼‚åŒ–ç¨‹åº¦å¤§å°ï¼ŒWOEè¶Šå¤§ï¼Œå·®å¼‚è¶Šå¤§ã€‚



#### IVçš„åŸç†

ä¸Šé¢æˆ‘ä»¬ä»‹ç»äº†å¦‚ä½•è®¡ç®—ä¸€ä¸ªåˆ†ç»„çš„WOEå€¼ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±å¯ä»¥æŠŠå˜é‡æ‰€æœ‰åˆ†ç»„çš„WOEå€¼ç»™ç®—å‡ºæ¥äº†ï¼Œå¯¹åº”åœ°ï¼Œæ¯ä¸ªåˆ†ç»„ä¹Ÿæœ‰ä¸€ä¸ªIVå€¼ï¼Œæˆ‘ä»¬å«  $IV_i$ ï¼Œå…¶ä¸­ï¼š

$$IV_i = (Py_i-Pn_i)*WOE_i$$

$$IV = \displaystyle\sum^{n}_{i}{IV_i} $$

è®¡ç®—è¿™ä¸ªå˜é‡çš„IVå€¼å°±æ˜¯è¿™æ ·å­å°±å¯ä»¥äº†ï¼ŒæŠŠæ¯ä¸ªåˆ†ç»„çš„IVå€¼ç»™åŠ èµ·æ¥ã€‚



#### å®é™…æ¡ˆä¾‹

å¥½äº†ï¼Œä¸Šé¢çš„ç†è®ºä¹Ÿè®²äº†ä¸€äº›äº†ï¼Œè¿˜æ˜¯æ‹¿ä¸€ä¸ªå®é™…çš„å˜é‡æ¥è®¡ç®—ä¸€ä¸‹ã€‚

æˆ‘ä»¬æ¥å‡è®¾ä¸€ä¸ªåœºæ™¯ï¼Œæˆ‘ä»¬éœ€è¦å–èŒ¶å¶ï¼Œç„¶åæˆ‘ä»¬ä¸çŸ¥é“ä»å“ªé‡Œæ‹¿æ¥äº†ä¸€ä»½1000äººçš„è¥é”€åå•ï¼ˆæ‰‹æœºå·ç ï¼‰ï¼Œç„¶åå°±æ‰¹é‡æ·»åŠ å¾®ä¿¡å¥½å‹ï¼Œæœ€åæœ‰500ä¸ªæ‰‹æœºå·ç å¯ä»¥æˆåŠŸæœç´¢åˆ°å¾®ä¿¡å·çš„ï¼Œè¿›è€Œè¿›è¡Œäº†å¥½å‹æ·»åŠ ï¼Œæœ€ç»ˆæœ‰100äººæˆåŠŸæ·»åŠ åˆ°å¥½å‹äº†ã€‚

æˆ‘ä»¬è¿™ä»½åå•ä¸Šï¼Œæœ‰å®¢æˆ·çš„å¹´é¾„å­—æ®µï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥æ‹¿æ¥è®¡ç®—ä¸€ä¸‹è¿™ä¸ªå­—æ®µå¯¹äºæ˜¯å¦æˆåŠŸæ·»åŠ å¥½å‹ï¼ˆå“åº”ï¼‰æœ‰å¤šå¤§çš„é¢„æµ‹èƒ½åŠ›ï¼Œæˆ‘ä»¬åœ¨Excelä¸­è¿›è¡Œå®ç°ï¼š

![image-20200801081041030](./arrests/49.png)

å¯ä»¥çœ‹å‡ºæ¥ï¼Œè¿™ä¸ªå˜é‡å¯¹äºæˆ‘ä»¬æ˜¯å¦å¯ä»¥æˆåŠŸåŠ åˆ°å®¢æˆ·å¾®ä¿¡å¥½å‹æœ‰ç€å¾ˆå¼ºçš„é¢„æµ‹èƒ½åŠ›ã€‚



#### Pythonå®ç°

æˆ‘ä»¬çŸ¥é“ï¼Œé’ˆå¯¹è¿ç»­å‹å˜é‡ï¼Œæ˜¯éœ€è¦å…ˆè½¬æ¢ä¸ºç±»åˆ«å˜é‡æ‰å¯ä»¥è¿›è¡ŒIVå€¼çš„è®¡ç®—çš„ï¼Œç°åœ¨æˆ‘ä»¬æŠŠæ•°æ®å¯¼å…¥åˆ°Pythonä¸­ï¼ŒåŸå§‹å˜é‡æ˜¯è¿ç»­å‹å˜é‡ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¦‚ä½•åœ¨Pythoné‡Œå®ç°IVå€¼çš„è®¡ç®—å‘¢ï¼Ÿå¦‚ä¸‹å›¾ï¼šï¼ˆå…¶ä¸­target=1ä»£è¡¨å“åº”ï¼Œtarget=0ä»£è¡¨æœªå“åº”ï¼‰

![image-20200801092020512](./arrests/50.png)

æ ¸å¿ƒä»£ç å°±æ˜¯ä¸‹é¢çš„ï¼š

```python
def iv_count(data_bad, data_good):
    '''è®¡ç®—ivå€¼'''
    value_list = set(data_bad.unique()) | set(data_good.unique())
    iv = 0
    len_bad = len(data_bad)
    len_good = len(data_good)
    for value in value_list:
        # åˆ¤æ–­æ˜¯å¦æŸç±»æ˜¯å¦ä¸º0ï¼Œé¿å…å‡ºç°æ— ç©·å°å€¼å’Œæ— ç©·å¤§å€¼
        if sum(data_bad == value) == 0:
            bad_rate = 1 / len_bad
        else:
            bad_rate = sum(data_bad == value) / len_bad
        if sum(data_good == value) == 0:
            good_rate = 1 / len_good
        else:
            good_rate = sum(data_good == value) / len_good
        iv += (good_rate - bad_rate) * math.log(good_rate / bad_rate,2)
        print(value,iv)
    return iv
```



é‚£ä¹ˆæˆ‘ä»¬å¦‚ä½•ä½¿ç”¨å‘¢ï¼Œä¸€æ­¥ä¸€æ­¥æ¥ï¼š

##### Step1ï¼šå¯¼å…¥æ•°æ®

æµ‹è¯•æ•°æ®é›†å¯ä»¥åå°å›å¤ 'age' è¿›è¡Œè·å–ã€‚

```Python
data = pd.read_csv('./data/age.csv')

# å®šä¹‰å¿…è¦çš„å‚æ•°
feature = data.loc[:,['age']]
labels = data['target']
keep_cols = ['age']
cut_bin_dict = {'age':[0,18,25,30,40,50,100]}
```

##### Step2ï¼šæŒ‰ç…§æŒ‡å®šé˜ˆå€¼åˆ†ç®±

æŒ‰ç…§æˆ‘ä»¬ä¹‹å‰Excelç›¸åŒçš„åˆ†ç®±é€»è¾‘è¿›è¡Œåˆ†ç®±:

```python
cut_bin = cut_bin_dict['age']
# æŒ‰ç…§åˆ†ç®±é˜ˆå€¼åˆ†ç®±,å¹¶å°†ç¼ºå¤±å€¼æ›¿æ¢æˆBlank,åŒºåˆ†å¥½åæ ·æœ¬
data_bad = pd.cut(feature['age'], cut_bin, right=False).cat.add_categories(['Blank']).fillna('Blank')[labels == 1]
data_good = pd.cut(feature['age'], cut_bin, right=False
                   ).cat.add_categories(['Blank']).fillna('Blank')[labels == 0]

value_list = set(data_bad.unique()) | set(data_good.unique())
value_list
```

![image-20200801092640472](./arrests/51.png)

##### Step3ï¼šè°ƒç”¨å‡½æ•°è®¡ç®—IV

```python
iv_series['age'] = iv_count(data_bad, data_good)
iv_series

```

![image-20200801092803440](./arrests/52.png)

å¯ä»¥çœ‹å¾—å‡ºï¼Œå’Œæˆ‘ä»¬Excelè®¡ç®—çš„ç»“æœå®Œå…¨ä¸€è‡´ï¼



#### â€œæˆ‘è¦æ‰“10ä¸ªâ€ç‰ˆæœ¬

å—¯ï¼Œä¸Šé¢é’ˆå¯¹å•ä¸ªçš„å˜é‡IVè®¡ç®—æ˜¯ä¼šäº†ï¼Œé‚£ä¹ˆå¦‚æœæœ‰ä¸€å †éœ€è¦ä½ è®¡ç®—IVçš„å˜é‡ï¼Œå¯ä»¥å¦‚ä½•å¤„ç†å‘¢?å…¶å®ï¼ŒåŸç†å¾ˆç®€å•ï¼Œå°±æ˜¯å†™ä¸ªå¾ªç¯ï¼Œè¿™é‡Œå‘¢å·²ç»å†™å¥½äº†ä¸€ä¸ªï¼Œå¤§å®¶å¯ä»¥å‚è€ƒä¸€ä¸‹çš„ã€‚è¿™è¾¹æœ‰ä¸€äº›ç»†èŠ‚çš„ä¸œè¥¿éœ€è¦è¯´æ˜ä¸€ä¸‹çš„ã€‚

1ï¼‰æ³¨æ„åŒºåˆ†å˜é‡ç±»å‹ï¼Œæ•°å€¼å‹å˜é‡å’Œç±»åˆ«å‹å˜é‡è¦åŒºåˆ†å¯¹å¾…ã€‚

2ï¼‰æ³¨æ„åˆ†ç»„åæ˜¯å¦å‡ºç°æŸç»„å†…çš„å“åº”(æœªå“åº”)æ•°é‡ä¸ºé›¶çš„æƒ…å†µï¼Œå¦‚æœä¸ºé›¶éœ€è¦å¤„ç†ä¸€ä¸‹ã€‚

ä»£ç æ”¾ä¸Šï¼Œå¤§å®¶å¯ä»¥è¯•ç€è¿è¡Œä¸€ä¸‹ï¼š

```python
def get_iv_series(feature, labels, keep_cols=None, cut_bin_dict=None):
    '''
    è®¡ç®—å„å˜é‡æœ€å¤§çš„ivå€¼,get_iv_seriesæ–¹æ³•å‡ºå…¥å‚å¦‚ä¸‹:
    ------------------------------------------------------------
    å…¥å‚ç»“æœå¦‚ä¸‹:
        feature: æ•°æ®é›†çš„ç‰¹å¾ç©ºé—´
        labels: æ•°æ®é›†çš„è¾“å‡ºç©ºé—´
        keep_cols: éœ€è®¡ç®—ivå€¼çš„å˜é‡åˆ—è¡¨
        cut_bin_dict: æ•°å€¼å‹å˜é‡è¦è¿›è¡Œåˆ†ç®±çš„é˜ˆå€¼å­—å…¸,æ ¼å¼ä¸º{'col1':[value1,value2,...], 'col2':[value1,value2,...], ...}
    ------------------------------------------------------------
    å…¥å‚ç»“æœå¦‚ä¸‹:
        iv_series: å„å˜é‡æœ€å¤§çš„IVå€¼
    '''
    def iv_count(data_bad, data_good):
        '''è®¡ç®—ivå€¼'''
        value_list = set(data_bad.unique()) | set(data_good.unique())
        iv = 0
        len_bad = len(data_bad)
        len_good = len(data_good)
        for value in value_list:
            # åˆ¤æ–­æ˜¯å¦æŸç±»æ˜¯å¦ä¸º0ï¼Œé¿å…å‡ºç°æ— ç©·å°å€¼å’Œæ— ç©·å¤§å€¼
            if sum(data_bad == value) == 0:
                bad_rate = 1 / len_bad
            else:
                bad_rate = sum(data_bad == value) / len_bad
            if sum(data_good == value) == 0:
                good_rate = 1 / len_good
            else:
                good_rate = sum(data_good == value) / len_good
            iv += (good_rate - bad_rate) * math.log(good_rate / bad_rate,2)
        return iv

    if keep_cols is None:
        keep_cols = sorted(list(feature.columns))
    col_types = feature[keep_cols].dtypes
    categorical_feature = list(col_types[col_types == 'object'].index)
    numerical_feature = list(col_types[col_types != 'object'].index)

    iv_series = pd.Series()

    # éå†æ•°å€¼å˜é‡è®¡ç®—ivå€¼
    for col in numerical_feature:
        cut_bin = cut_bin_dict[col]
        # æŒ‰ç…§åˆ†ç®±é˜ˆå€¼åˆ†ç®±,å¹¶å°†ç¼ºå¤±å€¼æ›¿æ¢æˆBlank,åŒºåˆ†å¥½åæ ·æœ¬
        data_bad = pd.cut(feature[col], cut_bin, right=False).cat.add_categories(['Blank']).fillna('Blank')[labels == 1]
        data_good = pd.cut(feature[col], cut_bin, right=False
                           ).cat.add_categories(['Blank']).fillna('Blank')[labels == 0]
        iv_series[col] = iv_count(data_bad, data_good)
    # éå†ç±»åˆ«å˜é‡è®¡ç®—ivå€¼
    for col in categorical_feature:
        # å°†ç¼ºå¤±å€¼æ›¿æ¢æˆBlank,åŒºåˆ†å¥½åæ ·æœ¬
        data_bad = feature[col].fillna('Blank')[labels == 1]
        data_good = feature[col].fillna('Blank')[labels == 0]
        iv_series[col] = iv_count(data_bad, data_good)

    return iv_series
```

##### è°ƒç”¨demoï¼š

```python
iv_series = get_iv_series(feature, labels, keep_cols, cut_bin_dict=cut_bin_dict)
iv_series
# age    0.434409
```



#### æ€»ç»“ä¸€ä¸‹

è®°ä½IVå€¼çš„é¢„æµ‹èƒ½åŠ›æ˜ å°„ï¼š

| IVèŒƒå›´    | å˜é‡é¢„æµ‹åŠ› |
| --------- | ---------- |
| <0.02     | æ— é¢„æµ‹åŠ›ğŸ˜¯  |
| 0.02~0.10 | å¼±ğŸ‘        |
| 0.10~0.30 | ä¸­ç­‰ğŸ˜Š      |
| `> 0.30   | å¼ºğŸ‘        |

å¦‚æœæƒ³å¤ç°ä»£ç ï¼Œå¯ä»¥ä»æˆ‘çš„å…¬å·åå°è¾“å‡º  'age' å»è·å–æµ‹è¯•é›†å§ï¼Œæˆ–è€…æ‹¿è‡ªå·±ç›®å‰çš„æ•°æ®é›†æ¥ç©ç©ä¹Ÿå¯ä»¥ï¼Œä¸è¿‡å¾—æ³¨æ„ä¸€äº›ç»†èŠ‚ï¼Œè½¬æ¢æ•°æ®æ ¼å¼ã€‚

<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>

## Tip25ï¼šä¸€æ–‡ä»‹ç»ç‰¹å¾å·¥ç¨‹é‡Œçš„å¡æ–¹åˆ†ç®±ï¼Œé™„ä»£ç å®ç°

ä»Šå¤©è¿˜æ˜¯è®²ä¸€ä¸‹é‡‘èé£æ§çš„ç›¸å…³çŸ¥è¯†ï¼Œä¸Šä¸€æ¬¡æˆ‘ä»¬æœ‰è®²åˆ°ï¼Œå¦‚æœæˆ‘ä»¬éœ€è¦è®¡ç®—å˜é‡çš„IVå€¼ï¼Œä»è€Œåˆ¤æ–­å˜é‡çš„é¢„æµ‹èƒ½åŠ›å¼ºå¼±ï¼Œæ˜¯éœ€è¦å¯¹å˜é‡è¿›è¡Œç¦»æ•£åŒ–çš„ï¼Œä¹Ÿå°±æ˜¯åˆ†ç®±å¤„ç†ã€‚é‚£ä¹ˆï¼Œä»Šå¤©å°±æ¥ç»™å¤§å®¶è§£é‡Šä¸€ä¸‹å…¶ä¸­ä¸€ç§åˆ†ç®±æ–¹å¼ â€”â€” å¡æ–¹åˆ†ç®±å¤„ç†ã€‚



#### âœï¸ äº†è§£å¡æ–¹åˆ†å¸ƒ

äº†è§£å¡æ–¹åˆ†ç®±ï¼Œé¦–å…ˆéœ€è¦äº†è§£ä¸‹å¡æ–¹åˆ†å¸ƒã€‚å¡æ–¹åˆ†å¸ƒ(chi-square distribution, Ï‡2-distribution)æ˜¯æ¦‚ç‡ç»Ÿè®¡é‡Œå¸¸ç”¨çš„ä¸€ç§æ¦‚ç‡åˆ†å¸ƒï¼Œä¹Ÿæ˜¯ç»Ÿè®¡æ¨æ–­é‡Œåº”ç”¨æœ€å¹¿æ³›çš„æ¦‚ç‡åˆ†å¸ƒä¹‹ä¸€ï¼Œåœ¨å‡è®¾æ£€éªŒä¸ç½®ä¿¡åŒºé—´çš„è®¡ç®—ä¸­ç»å¸¸èƒ½è§åˆ°å¡æ–¹åˆ†å¸ƒçš„èº«å½±ï¼Œå…¶å®šä¹‰å¦‚ä¸‹ï¼š

> è‹¥kä¸ªç›¸äº’ç‹¬ç«‹çš„éšæœºå˜é‡$Z_1$, $Z_2$, $Z_3$, ..., $Z_k$ æ»¡è¶³æ ‡å‡†æ­£æ€åˆ†å¸ƒ N(0,1)ï¼Œé‚£ä¹ˆè¿™kä¸ªéšæœºå˜é‡çš„å¹³æ–¹å’Œ $X=\displaystyle\sum^{k}_{i=1}{Z_i^2}$å°±æ˜¯æœä»è‡ªç”±åº¦ä¸ºkçš„å¡æ–¹åˆ†å¸ƒäº†ï¼Œä¸€èˆ¬è®°ä½œï¼š$X ï½  X^2(k)$

å…¶æ¦‚ç‡å¯†åº¦å‡½æ•°å¦‚ä¸‹æ‰€ç¤ºï¼ˆå›¾ç‰‡æ¥è‡ªç™¾åº¦ç™¾ç§‘ï¼‰ï¼š

![image-20200816203804735](./arrests/53.png)



#### âœï¸äº†è§£ä¸‹å¡æ–¹æ£€æµ‹

å¡æ–¹æ£€æµ‹æ˜¯ä»¥å¡æ–¹åˆ†å¸ƒä¸ºåŸºç¡€çš„ä¸€ç§å‡è®¾æ£€éªŒæ–¹æ³•ï¼Œä¸»è¦æ˜¯ç”¨äºæ£€éªŒåˆ†ç±»å˜é‡ä¹‹é—´çš„ç‹¬ç«‹æ€§æƒ…å†µã€‚å®ƒçš„åŸºæœ¬æ€æƒ³å°±æ˜¯æ ¹æ®æ ·æœ¬æ•°æ®æ¨æ–­æ€»ä½“åˆ†å¸ƒä¸æœŸæœ›åˆ†å¸ƒä¹‹é—´æ˜¯å¦å­˜åœ¨æ˜¾è‘—æ€§å·®å¼‚ï¼Œæˆ–è€…è¯´ä¸¤ä¸ªåˆ†ç±»å˜é‡ä¹‹é—´æ˜¯å¦ç›¸äº’ç‹¬ç«‹ï¼ˆoræ˜¯å¦ç›¸å…³ï¼‰ã€‚

**ä¸€èˆ¬çš„æƒ…å†µä¸‹æˆ‘ä»¬ä¼šæŠŠåŸå‡è®¾è®¾ç½®ä¸ºï¼šè§‚å¯Ÿé¢‘æ•°ä¸æœŸæœ›é¢‘æ•°ä¹‹é—´æ²¡æœ‰å·®å¼‚ï¼Œä¹Ÿå°±æ˜¯è¯´ä¸¤ä¸ªåˆ†ç±»å˜é‡ä¹‹é—´æ˜¯ç›¸äº’ç‹¬ç«‹ä¸ç›¸å…³çš„**ã€‚

å®é™…çš„åº”ç”¨ä¸­æˆ‘ä»¬å‡è®¾åŸå‡è®¾æˆç«‹ï¼Œç„¶åè®¡ç®—å‡ºå¡æ–¹å€¼ï¼Œä»è€Œæ¥å†³ç­–æ˜¯å¦éœ€è¦æ‹’ç»åŸå‡è®¾ï¼Œå¡æ–¹å€¼çš„è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š

$X_k^2= \sum{\frac{(A-E)^2}{E}} $

å…¶ä¸­ï¼ŒAä¸ºå®é™…é¢‘æ•°ï¼ŒEä¸ºæœŸæœ›é¢‘æ•°ï¼Œå¡æ–¹å€¼å°±æ˜¯è®¡ç®—å®é™…ä¸æœŸæœ›ä¹‹é—´çš„å·®å¼‚ç¨‹åº¦å¤§å°çš„é‡åŒ–æŒ‡æ ‡ã€‚ä¸Šé¢å…¬å¼ç»“æœæœä»å¡æ–¹åˆ†å¸ƒï¼Œç„¶åæˆ‘ä»¬æ ¹æ®å¡æ–¹åˆ†å¸ƒã€å¡æ–¹ç»Ÿè®¡é‡ä»¥åŠè‡ªç”±åº¦ï¼Œå°±å¯ä»¥æŸ¥å‡ºpå€¼ï¼Œå¦‚æœpå€¼å¾ˆå°ï¼Œä»£è¡¨è§‚å¯Ÿå€¼ä¸æœŸæœ›å€¼åç¦»ç¨‹åº¦å¾ˆå¤§ï¼Œé‚£ä¹ˆå°±éœ€è¦æ‹’ç»åŸå‡è®¾ï¼Œä¹Ÿå°±æ˜¯è¯´ä¸¤ä¸ªåˆ†ç±»å˜é‡ä¹‹é—´æœ‰ç›¸å…³æ€§ã€‚



#### ğŸ” å¡æ–¹åˆ†å¸ƒè¡¨

è¿™ä¸ªæ¦‚å¿µè²Œä¼¼åœ¨å¤§ä¸€çš„æ—¶å€™å°±æœ‰æ¥è§¦è¿‡äº†ï¼Œå¯ä»¥çŸ¥é“æ¨ªè½´æ˜¯åˆ†ä½æ•°ï¼Œçºµè½´æ˜¯è‡ªç”±åº¦ï¼Œç„¶åç±»ä¼¼äºPythonçš„locæ–¹æ³•ï¼Œå®šä½åˆ°çš„å€¼å°±æ˜¯å¡æ–¹å€¼äº†ã€‚ï¼ˆæ¯”å¦‚ï¼Œè¦æ‰¾åˆ†ä½æ•°ä½0.9ï¼Œè‡ªç”±åº¦ä¸º8çš„å€¼ï¼ŒæŸ¥è¡¨å¯çŸ¥ä¸º3.489539

![image-20200826222449796](./arrests/54.png)

å¦‚æœæƒ³è¦åœ¨Pythoné‡Œç”Ÿæˆå¡æ–¹åˆ†å¸ƒè¡¨ï¼Œå¯ä»¥å°è¯•ä¸‹é¢çš„ä»£ç ï¼š

```python
# ç”¨Pythonç”Ÿæˆå¡æ–¹åˆ†å¸ƒä¸´ç•Œå€¼è¡¨
import numpy as np
import pandas as pd
from scipy.stats import chi2
 
# chi square distribution
percents = [0.995, 0.990, 0.975, 0.950, 0.900, 0.100, 0.050, 0.025, 0.010, 0.005]
df = pd.DataFrame(np.array([chi2.isf(percents, df=i) for i in range(1, 10)]), columns=percents, index=list(range(1,10)))
df

```



#### ğŸ¤” ä¸¾ä¸ªæ —å­

æˆ‘ä»¬æœ‰ä¸€ç»„æ•°æ®ï¼Œæ˜¯æŸç§ç—…çš„æ‚£è€…ä½¿ç”¨äº†Aå’ŒBä¸¤ç§ä¸åŒæ–¹æ¡ˆçš„æ²»ç–—ï¼Œæ‰€å¾—åˆ°çš„æ²»ç–—ç»“æœï¼Œå¦‚ä¸‹è¡¨æ‰€ç¤ºï¼Œé—®Aã€Bä¸¤ç§ç–—æ³•æ˜¯å¦æœ‰æ˜æ˜¾å·®å¼‚ï¼Ÿ

| ç»„åˆ« | æœ‰æ•ˆ | æ— æ•ˆ | åˆè®¡ | æœ‰æ•ˆç‡% |
| ---- | ---- | ---- | ---- | ------- |
| Aç»„  | 19   | 24   | 43   | 44.2%   |
| Bç»„  | 34   | 10   | 44   | 77.3%   |
| åˆè®¡ | 53   | 34   | 87   | 60.9%   |

##### è§£ï¼š

è¿™é“é¢˜å…¶å®å°±æ˜¯å¥—å…¬å¼ï¼Œä»ä¸Šé¢æˆ‘äº†è§£åˆ°è¦è®¡ç®—å¡æ–¹å€¼å¯ä»¥æœ‰è¿™ä¸ªå…¬å¼ï¼š

![image-20200826223921485](./arrests/55.png)

æ‰€ä»¥ï¼Œæˆ‘ä»¬å…ˆç®—å‡ºæ¯ä¸ªæ ¼å­çš„æœŸæœ›é¢‘æ•°ï¼š

ç¤ºä¾‹1ï¼šAç»„æœ‰æ•ˆçš„æœŸæœ›é¢‘æ•°ï¼š43*53/87=26.20

| æœŸæœ›é¢‘æ•° | æœ‰æ•ˆ  | æ— æ•ˆ  | åˆè®¡ | æœ‰æ•ˆç‡% |
| -------- | ----- | ----- | ---- | ------- |
| Aç»„      | 26.20 | 16.80 | 43   | 60.9%   |
| Bç»„      | 26.80 | 17.20 | 44   | 60.9%   |
| åˆè®¡     | 53    | 34    | 87   | 60.9%   |

**å…ˆå»ºç«‹åŸå‡è®¾ï¼šAã€Bä¸¤ç§ç–—æ³•æ²¡æœ‰åŒºåˆ«ã€‚**

ç„¶åå°±å¥—å…¥ä¸Šé¢çš„å…¬å¼ï¼šï¼ˆAä¸ºå®é™…é¢‘æ•°ï¼ŒEä¸ºæœŸæœ›é¢‘æ•°ï¼‰

$X_k^2= \sum{\frac{(A-E)^2}{E}} = \frac{(19-26.2)^2}{26.2} +\frac{(24-16.8)^2}{16.8} + \frac{(34-26.8)^2}{26.8} + \frac{(10-17.2)^2}{17.2} = 10.01$

å› ä¸ºæˆ‘ä»¬é€‰æ‹©äº†å…¶ä¸­ä¸€ä¸ªæ–¹æ¡ˆï¼Œå¦å¤–ä¸€ä¸ªæ–¹æ¡ˆå°±æ˜ç¡®äº†ï¼Œæ‰€ä»¥è‡ªç”±åº¦æ˜¯1ï¼Œå› æ­¤å¯ä»¥æŸ¥è¡¨ï¼Œè‡ªç”±åº¦ä¸º1çš„ï¼Œè€Œä¸”å¡æ–¹å€¼ä¸º10.01çš„åˆ†ä½æ•°æ˜¯å¤šå°‘äº†ï½

æŸ¥è¡¨è‡ªç”±åº¦ä¸º1,p=0.05çš„å¡æ–¹å€¼ä¸º3.841ï¼Œè€Œæ­¤ä¾‹å¡æ–¹å€¼10.01>3.841ï¼Œå› æ­¤ p < 0.05ï¼Œè¯´æ˜åŸå‡è®¾åœ¨0.05çš„æ˜¾è‘—æ€§æ°´å¹³ä¸‹æ˜¯å¯ä»¥æ‹’ç»çš„ï¼Œä¹Ÿå°±æ˜¯è¯´åŸå‡è®¾ä¸æˆç«‹ï¼Œä¹Ÿå°±æ˜¯ä¸¤ç§æ²»ç–—æ–¹æ¡ˆæœ‰åŒºåˆ«ã€‚



#### ğŸ˜† è¿›å…¥æ­£é¢˜

ä¸Šé¢è®²äº†è¿™ä¹ˆå¤šåŸºç¡€çš„çŸ¥è¯†ï¼Œå°±æ˜¯ä¸ºäº†å¼•å‡ºè¿™ä¸€èŠ‚çš„å†…å®¹â€”â€” ChiMergeåˆ†ç®±ç®—æ³•ã€‚

ChiMergeå¡æ–¹åˆ†ç®±ç®—æ³•ç”±Kerberäº1992æå‡ºã€‚å®ƒä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼š**åˆå§‹åŒ–é˜¶æ®µå’Œè‡ªåº•å‘ä¸Šçš„åˆå¹¶é˜¶æ®µã€‚**

##### 1ã€åˆå§‹åŒ–é˜¶æ®µï¼š

é¦–å…ˆæŒ‰ç…§å±æ€§å€¼çš„å¤§å°è¿›è¡Œæ’åºï¼ˆå¯¹äºéè¿ç»­ç‰¹å¾ï¼Œéœ€è¦å…ˆåšæ•°å€¼è½¬æ¢ï¼Œæ¯”å¦‚è½¬ä¸ºåäººç‡ï¼Œç„¶åæ’åºï¼‰ï¼Œç„¶åæ¯ä¸ªå±æ€§å€¼å•ç‹¬ä½œä¸ºä¸€ç»„ã€‚

##### 2ã€åˆå¹¶é˜¶æ®µï¼š

ï¼ˆ1ï¼‰å¯¹æ¯ä¸€å¯¹ç›¸é‚»çš„ç»„ï¼Œè®¡ç®—å¡æ–¹å€¼ã€‚

ï¼ˆ2ï¼‰æ ¹æ®è®¡ç®—çš„å¡æ–¹å€¼ï¼Œå¯¹å…¶ä¸­æœ€å°çš„ä¸€å¯¹é‚»ç»„åˆå¹¶ä¸ºä¸€ç»„ã€‚

ï¼ˆ3ï¼‰ä¸æ–­é‡å¤ï¼ˆ1ï¼‰å’Œï¼ˆ2ï¼‰ç›´åˆ°è®¡ç®—å‡ºçš„å¡æ–¹å€¼éƒ½ä¸ä½äºäº‹å…ˆè®¾å®šçš„é˜ˆå€¼ï¼Œæˆ–è€…åˆ†ç»„æ•°è¾¾åˆ°ä¸€å®šçš„æ¡ä»¶ï¼ˆå¦‚æœ€å°åˆ†ç»„æ•°5ï¼Œæœ€å¤§åˆ†ç»„æ•°8ï¼‰ã€‚

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œé˜¿Samä¹‹å‰å‘ç°æœ‰çš„å®ç°æ–¹æ³•åœ¨åˆå¹¶é˜¶æ®µï¼Œè®¡ç®—çš„å¹¶éç›¸é‚»ç»„çš„å¡æ–¹å€¼ï¼ˆåªè€ƒè™‘åœ¨æ­¤ä¸¤ç»„å†…çš„æ ·æœ¬ï¼Œå¹¶è®¡ç®—æœŸæœ›é¢‘æ•°ï¼‰ï¼Œå› ä¸ºä»–ä»¬ç”¨æ•´ä½“æ ·æœ¬æ¥è®¡ç®—æ­¤ç›¸é‚»ä¸¤ç»„çš„æœŸæœ›é¢‘æ•°ã€‚

äº†è§£äº†åŸç†ä¹‹åï¼Œé‚£ä¹ˆPythonå¦‚ä½•å®ç°å‘¢ï¼Ÿè¯·çœ‹ä¸‹é¢çš„ä»£ç ï¼š

##### Step1:å¯¼å…¥ç›¸å…³åº“

```python
import numpy as np
from scipy.stats import chi
import pandas as pd
from pandas import DataFrame,Series
import scipy

```

##### Step2:è®¡ç®—å¡æ–¹å€¼

```python
def chi3(arr):
   '''
  è®¡ç®—å¡æ–¹å€¼
  arr:é¢‘æ•°ç»Ÿè®¡è¡¨,äºŒç»´numpyæ•°ç»„ã€‚
  '''
   assert(arr.ndim==2)
   #è®¡ç®—æ¯è¡Œæ€»é¢‘æ•°
   R_N = arr.sum(axis=1)
   #æ¯åˆ—æ€»é¢‘æ•°
   C_N = arr.sum(axis=0)
   #æ€»é¢‘æ•°
   N = arr.sum()
   # è®¡ç®—æœŸæœ›é¢‘æ•° C_i * R_j / Nã€‚
   E = np.ones(arr.shape)* C_N / N
   E = (E.T * R_N).T
   square = (arr-E)**2 / E
   #æœŸæœ›é¢‘æ•°ä¸º0æ—¶ï¼Œåšé™¤æ•°æ²¡æœ‰æ„ä¹‰ï¼Œä¸è®¡å…¥å¡æ–¹å€¼
   square[E==0] = 0
   #å¡æ–¹å€¼
   v = square.sum()
   return v

```

##### Step3:ç¡®å®šå¡æ–¹åˆ†ç®±ç‚¹

```python
def chiMerge(df,col,target,max_groups=None,threshold=None):

   '''
  å¡æ–¹åˆ†ç®±
  df: pandas dataframeæ•°æ®é›†
  col: éœ€è¦åˆ†ç®±çš„å˜é‡åï¼ˆæ•°å€¼å‹ï¼‰
  target: ç±»æ ‡ç­¾
  max_groups: æœ€å¤§åˆ†ç»„æ•°ã€‚
  threshold: å¡æ–¹é˜ˆå€¼ï¼Œå¦‚æœæœªæŒ‡å®šmax_groupsï¼Œé»˜è®¤ä½¿ç”¨ç½®ä¿¡åº¦95%è®¾ç½®thresholdã€‚
  return: åŒ…æ‹¬å„ç»„çš„èµ·å§‹å€¼çš„åˆ—è¡¨.
  '''

   freq_tab = pd.crosstab(df[col],df[target])

   #è½¬æˆnumpyæ•°ç»„ç”¨äºè®¡ç®—ã€‚
   freq = freq_tab.values

   #åˆå§‹åˆ†ç»„åˆ‡åˆ†ç‚¹ï¼Œæ¯ä¸ªå˜é‡å€¼éƒ½æ˜¯åˆ‡åˆ†ç‚¹ã€‚æ¯ç»„ä¸­åªåŒ…å«ä¸€ä¸ªå˜é‡å€¼.

   #åˆ†ç»„åŒºé—´æ˜¯å·¦é—­å³å¼€çš„ï¼Œå¦‚cutoffs = [1,2,3]ï¼Œåˆ™è¡¨ç¤ºåŒºé—´ [1,2) , [2,3) ,[3,3+)ã€‚
   cutoffs = freq_tab.index.values

   #å¦‚æœæ²¡æœ‰æŒ‡å®šæœ€å¤§åˆ†ç»„
   if max_groups is None:    
       #å¦‚æœæ²¡æœ‰æŒ‡å®šå¡æ–¹é˜ˆå€¼ï¼Œå°±ä»¥95%çš„ç½®ä¿¡åº¦ï¼ˆè‡ªç”±åº¦ä¸ºç±»æ•°ç›®-1ï¼‰è®¾å®šé˜ˆå€¼ã€‚
       if threshold is None:
           #ç±»æ•°ç›®
           cls_num = freq.shape[-1]
           threshold = chi2.isf(0.05,df= cls_num - 1)

   while True:
       minvalue = None
       minidx = None
       #ä»ç¬¬1ç»„å¼€å§‹ï¼Œä¾æ¬¡å–ä¸¤ç»„è®¡ç®—å¡æ–¹å€¼ï¼Œå¹¶åˆ¤æ–­æ˜¯å¦å°äºå½“å‰æœ€å°çš„å¡æ–¹
       for i in range(len(freq) - 1):
           v = chi3(freq[i:i+2])
           if minvalue is None or (minvalue > v): #å°äºå½“å‰æœ€å°å¡æ–¹ï¼Œæ›´æ–°æœ€å°å€¼
               minvalue = v
               minidx = i

       #å¦‚æœæœ€å°å¡æ–¹å€¼å°äºé˜ˆå€¼ï¼Œåˆ™åˆå¹¶æœ€å°å¡æ–¹å€¼çš„ç›¸é‚»ä¸¤ç»„ï¼Œå¹¶ç»§ç»­å¾ªç¯
       if (max_groups is not None and  max_groups< len(freq) ) or (threshold is not None and minvalue < threshold):
           #minidxåä¸€è¡Œåˆå¹¶åˆ°minidx
           tmp = freq[minidx] + freq[minidx+1]
           freq[minidx] = tmp
           #åˆ é™¤minidxåä¸€è¡Œ
           freq = np.delete(freq,minidx+1,0)
           #åˆ é™¤å¯¹åº”çš„åˆ‡åˆ†ç‚¹
           cutoffs = np.delete(cutoffs,minidx+1,0)

       else: #æœ€å°å¡æ–¹å€¼ä¸å°äºé˜ˆå€¼ï¼Œåœæ­¢åˆå¹¶ã€‚
           break
   return cutoffs

```

##### Step4:ç”Ÿæˆåˆ†ç»„åçš„æ–°å˜é‡

```python
def value2group(x,cutoffs):

   '''
  å°†å˜é‡çš„å€¼è½¬æ¢æˆç›¸åº”çš„ç»„ã€‚
  x: éœ€è¦è½¬æ¢åˆ°åˆ†ç»„çš„å€¼
  cutoffs: å„ç»„çš„èµ·å§‹å€¼ã€‚
  return: xå¯¹åº”çš„ç»„ï¼Œå¦‚group1ã€‚ä»group1å¼€å§‹ã€‚
  '''

   #åˆ‡åˆ†ç‚¹ä»å°åˆ°å¤§æ’åºã€‚
   cutoffs = sorted(cutoffs)
   num_groups = len(cutoffs)

   #å¼‚å¸¸æƒ…å†µï¼šå°äºç¬¬ä¸€ç»„çš„èµ·å§‹å€¼ã€‚è¿™é‡Œç›´æ¥æ”¾åˆ°ç¬¬ä¸€ç»„ã€‚
   #å¼‚å¸¸å€¼å»ºè®®åœ¨åˆ†ç»„ä¹‹å‰å…ˆå¤„ç†å¦¥å–„ã€‚
   if x < cutoffs[0]:
       return 'group1'

   for i in range(1,num_groups):
       if cutoffs[i-1] <= x < cutoffs[i]:
           return 'group{}'.format(i)

   #æœ€åä¸€ç»„ï¼Œä¹Ÿå¯èƒ½ä¼šåŒ…æ‹¬ä¸€äº›éå¸¸å¤§çš„å¼‚å¸¸å€¼ã€‚
   return 'group{}'.format(num_groups)

```

##### Step5:å®ç°WOEç¼–ç 

```python
def calWOE(df ,var ,target):

   '''
  è®¡ç®—WOEç¼–ç 
  param dfï¼šæ•°æ®é›†pandas.dataframe
  param varï¼šå·²åˆ†ç»„çš„åˆ—åï¼Œæ— ç¼ºå¤±å€¼
  param targetï¼šå“åº”å˜é‡ï¼ˆ0,1ï¼‰
  returnï¼šç¼–ç å­—å…¸
  '''
   eps = 0.000001  #é¿å…é™¤ä»¥0
   gbi = pd.crosstab(df[var],df[target]) + eps
   gb = df[target].value_counts() + eps
   gbri = gbi/gb
   gbri['woe'] = np.log(gbri[1]/gbri[0])
   return gbri['woe'].to_dict()

```

##### Step6:å®ç°IVå€¼è®¡ç®—

```python
def calIV(df,var,target):

   '''
  è®¡ç®—IVå€¼
  param dfï¼šæ•°æ®é›†pandas.dataframe
  param varï¼šå·²åˆ†ç»„çš„åˆ—åï¼Œæ— ç¼ºå¤±å€¼
  param targetï¼šå“åº”å˜é‡ï¼ˆ0,1ï¼‰
  returnï¼šIVå€¼
  '''
   eps = 0.000001  #é¿å…é™¤ä»¥0
   gbi = pd.crosstab(df[var],df[target]) + eps
   gb = df[target].value_counts() + eps
   gbri = gbi/gb
   gbri['woe'] = np.log(gbri[1]/gbri[0])
   gbri['iv'] = (gbri[1] - gbri[0])*gbri['woe']
   return gbri['iv'].sum()

```

##### Step7:Pythonä»£ç ä½¿ç”¨

```python
cutoffs = chiMerge(data,'MAX_AMOUNT','target',max_groups=8)

'''
PSï¼šç»å¤§æ•°æƒ…å†µä¸‹ï¼Œä¼šå°†ç¼ºå¤±å€¼NaNå½’ç±»åˆ°æœ€åä¸€ç»„ï¼Œå¦‚æœä¸æƒ³è¿™ä¹ˆç®€å•ç²—æš´çš„ï¼Œéœ€è¦åœ¨æœ€å¼€å§‹çš„æ—¶å€™å¯¹ç¼ºå¤±å€¼è¿›è¡Œå¡«å……ã€‚
'''

data['MAX_AMOUNT_chigroup'] = data['MAX_AMOUNT'].apply(value2group,args=(cutoffs,))
r = data.loc[:,['MAX_ã€AMOUNT','MAX_AMOUNT_chigroup','target']]
woe_map = calWOE(data,'MAX_AMOUNT_chigroup','target')
iv = calIV(data,'MAX_AMOUNT_chigroup','target')
iv

```



#### ğŸ“– Reference

[1] Pythonè¯„åˆ†å¡å»ºæ¨¡â€”å¡æ–¹åˆ†ç®±ï¼ˆ1ï¼‰

[2] Pythonè¯„åˆ†å¡å»ºæ¨¡â€”å¡æ–¹åˆ†ç®±ï¼ˆ2ï¼‰ä¹‹ä»£ç å®ç°

[3] pythonè¯„åˆ†å¡å»ºæ¨¡â€”å®ç°WOEç¼–ç åŠIVå€¼è®¡ç®—



<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>

## Tip26ï¼šä»Šå¤©ä¸€èµ·ææ‡‚æœºå™¨å­¦ä¹ é‡Œçš„L1ä¸L2æ­£åˆ™åŒ–

ä»Šå¤©æˆ‘ä»¬æ¥è®²è®²ä¸€ä¸ªç†è®ºçŸ¥è¯†ï¼Œä¹Ÿæ˜¯è€ç”Ÿå¸¸è°ˆçš„å†…å®¹ï¼Œåœ¨æ¨¡å‹å¼€å‘ç›¸å…³å²—ä½ä¸­å‡ºåœºç‡è¾ƒé«˜çš„ï¼Œé‚£å°±æ˜¯L1ä¸L2æ­£åˆ™åŒ–äº†ï¼Œè¿™ä¸ªçœ‹ä¼¼ç®€å•å´ååˆ†é‡è¦çš„æ¦‚å¿µï¼Œè¿˜æ˜¯éœ€è¦æ·±å…¥äº†è§£çš„ã€‚ç½‘ä¸Šæœ‰è›®å¤šçš„å­¦ä¹ èµ„æ–™ï¼Œä»Šå¤©æˆ‘å°±ç€è‡ªå·±çš„ç†è§£ä¹Ÿå†™ä¸€ä¸‹ç¬”è®°ã€‚ğŸ“’

ä»è¥¿ç“œä¹¦ğŸ“–é‡Œæˆ‘ä»¬å¯ä»¥äº†è§£åˆ°æ­£åˆ™é¡¹çš„ä½œç”¨ï¼Œé‚£å°±æ˜¯é™ä½æ¨¡å‹è¿‡æ‹Ÿåˆçš„é£é™©ï¼Œé€šå¸¸å¸¸ç”¨çš„æœ‰L1èŒƒæ•°æ­£åˆ™åŒ–ä¸L2èŒƒæ•°æ­£åˆ™åŒ–ï¼Œä½œä¸ºå•ç‹¬ä¸€é¡¹ï¼ˆæ­£åˆ™é¡¹ï¼‰åŠ å…¥åˆ°æŸå¤±å‡½æ•°ä¸­ï¼Œä¹Ÿå¯ä»¥è‡ªå·±ä½œä¸ºæŸå¤±å‡½æ•°ã€‚ğŸ

#### ğŸ“– L1 and L2 èŒƒæ•°

åœ¨äº†è§£L1å’ŒL2èŒƒæ•°ä¹‹å‰ï¼Œæˆ‘ä»¬å¯ä»¥å…ˆæ¥äº†è§£ä¸€ä¸‹èŒƒæ•°ï¼ˆnormï¼‰çš„å®šä¹‰ï¼Œæ ¹æ®å‚è€ƒæ–‡çŒ®[2]çš„è¯´æ˜ï¼š

> A norm is a mathematical thing that is applied to a vector (like the vector `Î²` above). The norm of a vector maps vector values to values in `[0,âˆ)`. In machine learning, norms are useful because they are used to express distances: this vector and this vector are so-and-so far apart, according to this-or-that norm.

ç®€å•æ¥è¯´ä¹Ÿå°±æ˜¯èŒƒæ•°å…¶å®åœ¨ `[0,âˆ)`èŒƒå›´å†…çš„å€¼ï¼Œæ˜¯å‘é‡çš„æŠ•å½±å¤§å°ï¼Œåœ¨æœºå™¨å­¦ä¹ ä¸­ä¸€èˆ¬ä¼šå‹‡äºè¡¡é‡å‘é‡çš„è·ç¦»ã€‚èŒƒæ•°æœ‰å¾ˆå¤šç§ï¼Œæˆ‘ä»¬å¸¸è§çš„æœ‰L1-normå’ŒL2-normï¼Œå…¶å®è¿˜æœ‰L3-normã€L4-normç­‰ç­‰ï¼Œæ‰€ä»¥æŠ½è±¡æ¥è¡¨ç¤ºï¼Œæˆ‘ä»¬ä¼šå†™ä½œ`Lp-norm`ï¼Œä¸€èˆ¬è¡¨ç¤ºä¸º $||x||_p$ :

$||x||_p = \displaystyle (\sum^{}_{i}{|x_i|^p})^{1/p}$

å¯¹äºä¸Šé¢è¿™ä¸ªæŠ½è±¡çš„å…¬å¼ï¼Œå¦‚æœæˆ‘ä»¬ä»£å…¥på€¼ï¼Œ

è‹¥pä¸º1ï¼Œåˆ™å°±æ˜¯æˆ‘ä»¬å¸¸è¯´çš„L1-normï¼š

$||x||_1 = \displaystyle \sum^{}_{i}{|x_i|} = |x_1|+|x_2|+...+|x_i|$

è‹¥pä¸º2ï¼Œåˆ™æ˜¯æˆ‘ä»¬å¸¸è¯´çš„L2-normï¼š

$||x||_2 = \displaystyle \sqrt{(\sum^{}_{i}{|x_i|^2})} = \displaystyle \sqrt{x1^2+x2^2+...+x_i^2}$

æˆ‘ä»¬å¼•ç”¨æ–‡ç« é‡Œçš„å›¾ç‰‡ï¼ŒL2-normçš„è·ç¦»å°±æ˜¯ä¸¤ä¸ªé»‘ç‚¹ä¹‹é—´çš„ç»¿çº¿ï¼Œè€Œå¦å¤–çš„3æ¡çº¿ï¼Œéƒ½æ˜¯L1-normçš„å¤§å°ã€‚

![image-20200926210610300](./arrests/56.png)



#### âœï¸ L1 and L2æ­£åˆ™é¡¹

åœ¨ä¸Šé¢æˆ‘ä»¬æœ‰æåŠåˆ°ï¼ŒL1ã€L2èŒƒæ•°å¯ä»¥ç”¨äºæŸå¤±å‡½æ•°é‡Œçš„ä¸€ä¸ªæ­£åˆ™åŒ–é¡¹ï¼Œä½œç”¨å°±æ˜¯é™ä½æ¨¡å‹å¤æ‚åº¦ï¼Œå‡å°è¿‡æ‹Ÿåˆçš„é£é™©ã€‚è¿™é‡Œçš„æ­£åˆ™åŒ–é¡¹ï¼Œå­˜åœ¨çš„ç›®çš„å°±æ˜¯ä½œä¸ºä¸€ä¸ªâ€œæƒ©ç½šé¡¹â€ï¼Œå¯¹æŸå¤±å‡½æ•°ä¸­çš„æŸä¸€äº›å‚æ•°åšä¸€äº›é™åˆ¶ï¼Œæ˜¯ç»“æ„é£é™©æœ€å°åŒ–ç­–ç•¥çš„ä½“ç°ï¼Œå°±æ˜¯é€‰æ‹©ç»éªŒé£é™©ï¼ˆå¹³å‡æŸå¤±å‡½æ•°ï¼‰å’Œæ¨¡å‹å¤æ‚åº¦åŒæ—¶è¾ƒå°çš„æ¨¡å‹ã€‚

é’ˆå¯¹çº¿æ€§å›å½’æ¨¡å‹ï¼Œå‡è®¾å¯¹å…¶ä»£ä»·å‡½æ•°é‡ŒåŠ å…¥æ­£åˆ™åŒ–é¡¹ï¼Œå…¶ä¸­L1å’ŒL2æ­£åˆ™åŒ–é¡¹çš„è¡¨ç¤ºåˆ†åˆ«å¦‚ä¸‹æ‰€ç¤ºï¼Œå…¶ä¸­`Î» >= 0`ï¼Œæ˜¯ç”¨æ¥å¹³è¡¡æ­£åˆ™åŒ–é¡¹å’Œç»éªŒé£é™©çš„ç³»æ•°ã€‚

ï¼ˆ1ï¼‰ä½¿ç”¨L1èŒƒæ•°æ­£åˆ™åŒ–ï¼Œå…¶æ¨¡å‹ä¹Ÿè¢«å«ä½œLassoå›å½’ï¼ˆLeast Absolute Shrinkage and Selection Operatorï¼Œæœ€å°ç»å¯¹æ”¶ç¼©é€‰æ‹©ç®—å­ï¼‰ã€‚

ï¼ˆ2ï¼‰ä½¿ç”¨L2èŒƒæ•°æ­£åˆ™åŒ–ï¼Œå…¶æ¨¡å‹è¢«å«åšRidgeå›å½’ï¼Œä¸­æ–‡ä¸ºå²­å›å½’ã€‚

![image-20200926212526709](./arrests/57.png)



#### ğŸš™ æœºå™¨å­¦ä¹ ä¸­ä¸€èˆ¬æ€ä¹ˆé€‰æ‹©æ­£åˆ™é¡¹

ä¸Šé¢ä»‹ç»çš„L1å’ŒL2èŒƒæ•°æ­£åˆ™åŒ–éƒ½æœ‰ç€é™ä½è¿‡æ‹Ÿåˆé£é™©çš„åŠŸèƒ½ï¼Œä½†å®ƒä»¬æœ‰ä»€ä¹ˆä¸åŒï¼Ÿæˆ‘ä»¬åˆ°åº•åº”è¯¥é€‰æ‹©å“ªä¸€ä¸ªå‘¢ï¼Œä¸¤è€…ä¹‹é—´å„æœ‰ä»€ä¹ˆä¼˜åŠ¿å’Œé€‚ç”¨åœºæ™¯ï¼Ÿåˆ«æ€¥ï¼Œæˆ‘ä»¬ä¸€ä¸€æ¥å±•å¼€è®²è®²ã€‚

##### Q1ï¼šL1å’ŒL2æ­£åˆ™åŒ–é¡¹çš„åŒºåˆ«ï¼Ÿ

é¦–å…ˆï¼Œæˆ‘ä»¬ä»ä¸Šé¢é‚£å¼ äºŒç»´çš„å›¾å¯ä»¥çœ‹å‡ºï¼Œå¯¹äºL2-normï¼Œå…¶è§£æ˜¯å”¯ä¸€çš„ï¼Œä¹Ÿå°±æ˜¯ç»¿è‰²çš„é‚£æ¡ï¼›è€Œå¯¹äºL1-normï¼Œå…¶è§£ä¸å”¯ä¸€ï¼Œå› æ­¤L1æ­£åˆ™åŒ–é¡¹ï¼Œå…¶è®¡ç®—éš¾åº¦é€šå¸¸ä¼šé«˜äºL2çš„ã€‚

å…¶æ¬¡ï¼Œ**L1é€šå¸¸æ˜¯æ¯”L2æ›´å®¹æ˜“å¾—åˆ°ç¨€ç–è¾“å‡ºçš„**ï¼Œä¼šæŠŠä¸€äº›ä¸é‡è¦çš„ç‰¹å¾ç›´æ¥ç½®é›¶ï¼Œè‡³äºä¸ºä»€ä¹ˆL1æ­£åˆ™åŒ–ä¸ºä»€ä¹ˆæ›´å®¹æ˜“å¾—åˆ°ç¨€ç–è§£ï¼Œå¯ä»¥çœ‹ä¸‹å›¾ï¼š

![image-20200926215608638](./arrests/58.png)

ä¸Šå›¾ä»£è¡¨çš„æ„æ€å°±æ˜¯ç›®æ ‡å‡½æ•°-å¹³æ–¹è¯¯å·®é¡¹çš„ç­‰å€¼çº¿å’ŒL1ã€L2èŒƒæ•°ç­‰å€¼çº¿ï¼ˆå·¦è¾¹æ˜¯L1ï¼‰ï¼Œæˆ‘ä»¬æ­£åˆ™åŒ–åçš„ä»£ä»·å‡½æ•°éœ€è¦æ±‚è§£çš„ç›®æ ‡å°±æ˜¯åœ¨ç»éªŒé£é™©å’Œæ¨¡å‹å¤æ‚åº¦ä¹‹é—´çš„å¹³è¡¡å–èˆï¼Œåœ¨å›¾ä¸­å½¢è±¡åœ°è¡¨ç¤ºå°±æ˜¯é»‘è‰²çº¿ä¸å½©è‰²çº¿çš„äº¤å‰ç‚¹ã€‚

å¯¹äºL1èŒƒæ•°ï¼Œå…¶å›¾å½¢ä¸ºè±å½¢ï¼ŒäºŒç»´å±æ€§çš„ç­‰å€¼çº¿æœ‰4ä¸ªè§’ï¼ˆé«˜ç»´çš„ä¼šæœ‰æ›´å¤šï¼‰ï¼Œâ€œçªå‡ºæ¥çš„è§’â€æ›´å®¹æ˜“ä¸å¹³æ–¹è¯¯å·®é¡¹è¿›è¡Œäº¤å‰ï¼Œè€Œè¿™äº›â€œçªå‡ºæ¥çš„è§’â€éƒ½æ˜¯åœ¨åæ ‡è½´ä¸Šï¼Œå³W1æˆ–åˆ™W2ä¸º0ï¼›

è€Œå¯¹äºL2èŒƒæ•°ï¼Œäº¤å‰ç‚¹ä¸€èˆ¬éƒ½æ˜¯åœ¨æŸä¸ªè±¡é™ä¸­ï¼Œå¾ˆå°‘æœ‰ç›´æ¥åœ¨åæ ‡è½´ä¸Šäº¤å‰çš„ã€‚

å› æ­¤L1èŒƒæ•°æ­£åˆ™åŒ–é¡¹æ¯”L2çš„æ›´å®¹æ˜“å¾—åˆ°ç¨€ç–è§£ã€‚



##### Q2ï¼šå„æœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Œå¦‚ä½•ä½œé€‰æ‹©ï¼Ÿ

ç›´æ¥ä¸Šç»“è®ºï¼š

1ï¼‰å› ä¸ºL1èŒƒæ•°æ­£åˆ™åŒ–é¡¹çš„â€œç¨€ç–è§£â€ç‰¹æ€§ï¼ŒL1æ›´é€‚åˆç”¨äºç‰¹å¾é€‰æ‹©ï¼Œæ‰¾å‡ºè¾ƒä¸ºâ€œå…³é”®â€çš„ç‰¹å¾ï¼Œè€ŒæŠŠä¸€äº›ä¸é‚£ä¹ˆé‡è¦çš„ç‰¹å¾ç½®ä¸ºé›¶ã€‚

2ï¼‰L2èŒƒæ•°æ­£åˆ™åŒ–é¡¹å¯ä»¥äº§ç”Ÿå¾ˆå¤šå‚æ•°å€¼å¾ˆå°çš„æ¨¡å‹ï¼Œä¹Ÿå°±æ˜¯è¯´è¿™ç±»çš„æ¨¡å‹æŠ—å¹²æ‰°çš„èƒ½åŠ›å¾ˆå¼ºï¼Œå¯ä»¥é€‚åº”ä¸åŒçš„æ•°æ®é›†ï¼Œé€‚åº”ä¸åŒçš„â€œæç«¯æ¡ä»¶â€ã€‚



#### ğŸ¤” å¦‚ä½•ä½œä¸ºLoss Function

è®²å®Œäº†ä½œä¸ºæ­£åˆ™åŒ–é¡¹çš„å†…å®¹äº†ï¼Œé‚£ä¹ˆè®²è®²L1ã€L2èŒƒæ•°ä½œä¸ºæŸå¤±å‡½æ•°çš„æƒ…å†µã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦è¯„ä¼°æ¨¡å‹çš„æ•ˆæœï¼Œå¾ˆå¸¸è§„çš„ï¼Œæˆ‘ä»¬ä¼šç”¨â€œè·ç¦»â€æ¥è¡¡é‡è¯¯å·®ï¼

è‹¥ä½¿ç”¨L1-normæ¥è¡¡é‡è·ç¦»ï¼Œé‚£å°±æ˜¯æˆ‘ä»¬çš„LADï¼ˆLeast Absolute Deviationï¼Œæœ€å°ç»å¯¹åå·®ï¼‰ï¼Œå…¶ä¼˜åŒ–çš„ç›®æ ‡å‡½æ•°å¦‚ä¸‹ï¼š

$S = \displaystyle \sum^{n}_{i=1}{|y_i-f(x_i)|}$

å®é™…æ„ä¹‰ä¸Šçš„è§£é‡Šå°±æ˜¯é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„ç»å¯¹å€¼ã€‚

è‹¥ä½¿ç”¨L2-normï¼Œé‚£å°±æ˜¯æˆ‘ä»¬çš„LSEï¼ˆLeast Squares Errorï¼Œæœ€å°äºŒä¹˜è¯¯å·®ï¼‰ï¼Œå…¶ä¼˜åŒ–çš„ç›®æ ‡å‡½æ•°å¦‚ä¸‹ï¼š

$S = \displaystyle \sum^{n}_{i=1}{(y_i-f(x_i))^2}$

é’ˆå¯¹ä¸¤è€…çš„å·®å¼‚ï¼Œå¯ä»¥çœ‹ä¸‹è¡¨ï¼š

![image-20200926222805570](./arrests/59.png)

L1æŸå¤±å‡½æ•°çš„ç»“æœæ›´å…·é²æ£’æ€§ï¼Œä¹Ÿå°±æ˜¯è¯´å¯¹äºå¼‚å¸¸å€¼æ›´åŠ ä¸æ•æ„Ÿã€‚è€Œæ ¹æ®å…¶èŒƒæ•°â€œå¤©æ€§â€ï¼ŒL2çš„æ±‚è§£æ›´ä¸ºç®€å•ä¸â€œå”¯ä¸€â€ã€‚



#### ğŸ“– Reference

[1] Differences between L1 and L2 as Loss Function and Regularization

http://www.chioka.in/differences-between-l1-and-l2-as-loss-function-and-regularization/

[2] L1 Norms versus L2 Norms

https://www.kaggle.com/residentmario/l1-norms-versus-l2-norms


<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>


## Tip27ï¼šé‡‘èé£æ§é‡Œçš„WOEå‰çš„åˆ†ç®±ä¸€å®šè¦å•è°ƒå—

#### ğŸš— Index

* âœï¸ èƒŒæ™¯äº¤ä»£

* ğŸ¥ WOEå›é¡¾
* ğŸ¤” LRæ¨¡å‹çš„å…¥å‚ä¸€å®šè¦WOEå—ï¼Ÿ

* ğŸ¤” WOEä¸å•è°ƒå¯ä»¥è¿›LRæ¨¡å‹å—ï¼Ÿ

  * é’ˆå¯¹ä¸åŒç±»å‹çš„å˜é‡

  * ä¸ºä»€ä¹ˆéœ€è¦WOEå…·å¤‡å•è°ƒæ€§

* ğŸ† ç»“è®ºå¤ç›˜



ä»Šå¤©æˆ‘ä»¬æ¥è®²è®²ä¸€ä¸ªé‡‘èé£æ§é‡Œçš„â€œå¸¸è¯†ç‚¹â€ï¼Œå°±æ˜¯é‚£ç§æˆ‘ä»¬ä¹ ä»¥ä¸ºå¸¸ä½†è‹¥è¦è®²å‡ºä¸ªæ‰€ä»¥ç„¶æ¥æ¯”è¾ƒå›°éš¾çš„ç‚¹ï¼Œæ­£å¦‚æ ‡é¢˜æ‰€è¨€ï¼š**WOEå‰çš„åˆ†ç®±ä¸€å®šè¦å•è°ƒå—ï¼Ÿ**ğŸ¤”

#### âœï¸ èƒŒæ™¯äº¤ä»£

ç›¸ä¿¡æ¯ä¸€ä¸ªåœ¨é‡‘èé£æ§é¢†åŸŸåšè¿‡æ¨¡å‹çš„äººï¼Œåº”è¯¥å¯¹åˆ†ç®±æ»¡è¶³badrateå•è°ƒæ€§æœ‰ä¸€å®šçš„è®¤çŸ¥ï¼Œç‰¹åˆ«æ˜¯åœ¨ç”¨é€»è¾‘å›å½’åšAå¡çš„æ—¶å€™ï¼Œè€å¸æœºä»¬ä¼šç»å¸¸å¯¹æˆ‘ä»¬è¯´å˜é‡è¦æ»¡è¶³å•è°ƒæ€§ï¼Œå½“å˜é‡å•è°ƒäº†ï¼Œå†è¿›è¡ŒWOEè½¬æ¢ï¼Œç„¶åä½œä¸ºLRçš„å…¥å‚å–‚ç»™æ¨¡å‹ï¼Œç®€å•è®­ç»ƒä¸€ä¸‹å°±æ”¶å·¥ã€‚ä½†ä½œä¸ºä¸€ä¸ªåˆæ ¼çš„é£æ§å»ºæ¨¡å¤§å¸ˆï¼Œä»…ä»…çŸ¥é“è¿™äº›å¥—è·¯è¿˜æ˜¯ä¸å¤Ÿçš„ï¼Œæˆ‘ä»¬éœ€è¦è¿›ä¸€æ­¥å»æ€è€ƒä¸€ä¸‹å½“ä¸­çš„åŸç†ï¼Œæˆ–è€…è¯´æ˜¯æ›´è¿›ä¸€æ­¥å»è¿½é—®ä¸€ä¸‹è‡ªå·±ï¼š

> LRæ¨¡å‹çš„å…¥å‚ä¸€å®šè¦WOEå—ï¼Ÿ
>
> WOEè½¬åŒ–å‰çš„å˜é‡åˆ†ç®±ç»“æœçš„badrateä¸€å®šéœ€è¦æ»¡è¶³å•è°ƒæ€§å—ï¼Ÿ
>
> è¿ç»­å˜é‡éš¾é“å°±ä¸å¯ä»¥ç›´æ¥è¿›LRæ¨¡å‹å—ï¼Ÿ

å¸Œæœ›å¤§å®¶åœ¨é˜…è¯»å®Œæœ¬ç¯‡æ–‡ç« åï¼Œå¤šå¤šå°‘å°‘å¯ä»¥å¯¹ä¸Šé¢çš„é—®é¢˜æœ‰ä¸€å®šçš„äº†è§£ï½



#### ğŸ¥ WOEå›é¡¾

åœ¨æˆ‘ä»¬å¼€å§‹æ‹†è§£é—®é¢˜å‰ï¼Œæœ‰ä¸€ä¸ªçŸ¥è¯†ç‚¹éœ€è¦å›é¡¾ä¸€ä¸‹ï¼Œé‚£å°±æ˜¯WOEã€‚

> WOEæ˜¯weight of evidenceçš„ç¼©å†™ï¼Œæ˜¯ä¸€ç§ç¼–ç å½¢å¼ï¼Œé¦–å…ˆæˆ‘ä»¬è¦çŸ¥é“WOEæ˜¯é’ˆå¯¹ç±»åˆ«å˜é‡è€Œè¨€çš„ï¼Œæ‰€ä»¥è¿ç»­æ€§å˜é‡éœ€è¦æå‰åšå¥½åˆ†ç»„ï¼ˆè¿™é‡Œä¹Ÿæ˜¯ä¸€ä¸ªå¾ˆå¥½çš„è€ƒç‚¹ï¼Œä¹Ÿæœ‰ä¼šè¯´åˆ†ç®±ã€ç¦»æ•£åŒ–çš„ï¼Œå˜é‡ä¼˜åŒ–ä¹Ÿå¯ä»¥ä»è¿™ä¸ªè§’åº¦å‡ºå‘ï¼‰ã€‚

å…ˆç»™å‡ºæ•°å­¦è®¡ç®—å…¬å¼ï¼Œå¯¹äºç¬¬iç»„çš„WOEå¯ä»¥è¿™ä¹ˆè®¡ç®—ï¼š

$$WOE_i = ln(\frac{y_i/y_{all}}{n_i/n_{all}})$$

ä»å…¬å¼ä¸Šå¯ä»¥çœ‹å‡ºï¼Œç¬¬iç»„çš„WOEå€¼ç­‰äºè¿™ä¸ªç»„çš„å“åº”å®¢æˆ·å æ‰€æœ‰å“åº”å®¢æˆ·çš„æ¯”ä¾‹ä¸æœªå“åº”å®¢æˆ·å æ‰€æœ‰æœªå“åº”å®¢æˆ·çš„æ¯”ä¾‹çš„æ¯”å€¼å–å¯¹æ•°ã€‚å¯¹äºä¸Šé¢çš„å…¬å¼æˆ‘ä»¬è¿˜å¯ä»¥ ç®€å•åšä¸€ä¸‹è½¬åŒ–ï¼š

$$WOE_i = ln(\frac{y_i/y_{all}}{n_i/n_{all}}) = ln(\frac{y_i/n_i}{y_{all}/n_{all}})$$

æ‰€ä»¥ï¼ŒWOEä¸»è¦å°±æ˜¯ä½“ç°ç»„å†…çš„å¥½åå æ¯”ä¸æ•´ä½“çš„å·®å¼‚åŒ–ç¨‹åº¦å¤§å°ï¼ŒWOEè¶Šå¤§ï¼Œå·®å¼‚è¶Šå¤§ã€‚

æ›´å¤šçš„å†…å®¹å¯ä»¥æµè§ˆä¸€ä¸‹ä¹‹å‰çš„æ–‡ç« ã€Šç‰¹å¾é”¦å›Šï¼šå½»åº•äº†è§£ä¸€ä¸‹WOEå’ŒIVã€‹ã€‚



#### ğŸ¤” LRæ¨¡å‹çš„å…¥å‚ä¸€å®šè¦WOEå—ï¼Ÿ

The answer is noï¼å¹¶éæ‰€æœ‰LRçš„å…¥å‚éƒ½éœ€è¦WOEçš„ï¼Œä¹Ÿå¯ä»¥æ˜¯ç›´æ¥åŸå§‹å€¼å…¥æ¨¡å‹çš„ã€‚ä½†å­˜åœ¨å³åˆç†ï¼Œä¸ºä»€ä¹ˆå¤§å®¶éƒ½åœ¨è¯´è¦å¯¹å˜é‡è¿›è¡ŒWOEç¼–ç å‘¢ï¼Ÿæˆ‘ä»¬å¯ä»¥å¼•å‡ºä¸‹é¢ä¸¤ä¸ªé—®é¢˜ï¼š

* ä»€ä¹ˆæƒ…å†µä¸‹ç”¨WOEæ¯”è¾ƒåˆé€‚ï¼Ÿ
* ä»¥åŠç”¨WOEæœ‰ä»€ä¹ˆå¥½å¤„

æˆ‘ä»¬çŸ¥é“ï¼Œåœ¨é£æ§é¢†åŸŸçš„å˜é‡å¯ä»¥å¤§è‡´åˆ†ä¸ºä¸¤ç±»ï¼Œå°±æ˜¯æ•°å€¼å‹å˜é‡ä»¥åŠç±»åˆ«å‹å˜é‡ï¼Œå‰è€…å°±æ˜¯ç±»ä¼¼äºå¹´é¾„ã€é€¾æœŸå¤©æ•°ç­‰ï¼Œåè€…å°±æ˜¯èŒä¸šç±»åˆ«ã€è¡Œä¸šç±»åˆ«ç­‰ã€‚

é’ˆå¯¹ç±»åˆ«å‹å˜é‡ï¼Œæˆ‘ä»¬å¾ˆå®¹æ˜“å¯ä»¥æƒ³åˆ°ä½¿ç”¨one-hotç¼–ç æ¥ï¼Œä½†æ˜¯è¿™ç§ç¼–ç æ–¹å¼æœ‰ä¸€å®šçš„ç¼ºé™·ï¼Œé‚£å°±æ˜¯å¯¹äºæšä¸¾å€¼ç‰¹åˆ«å¤šçš„å˜é‡ï¼Œç‹¬çƒ­ç¼–ç ä¹‹åååˆ†ç¨€ç–ä»è€Œç‰¹å¾ç©ºé—´å¾ˆå¤§ï¼Œå¦å¤–å¦‚æœä¸¢å¼ƒä¸€éƒ¨åˆ†ç»´åº¦åˆ™ä¼šé€ æˆä¿¡æ¯ä¸¢å¤±ï¼ŒæŒ‡ä¸å®šè¿™äº›æ˜¯å…³é”®çš„ä¿¡æ¯ã€‚ä»¥ä¸Šçš„ä¿¡æ¯è¯´æ˜äº†æ”¾å…¥LRä¸­å¾ˆéš¾æœ‰å¾ˆå¥½çš„æ•ˆæœã€‚

è€Œé’ˆå¯¹æ•°å€¼å‹å˜é‡ï¼Œå¾ˆå¤šåŒå­¦åˆ™ä¼šæœ‰æ›´å¤§çš„ç–‘é—®ï¼Œé‚£å°±æ˜¯ä¸ºä»€ä¹ˆè¦åˆ†ç®±ç„¶ååˆè¿›è¡ŒWOEè½¬æ¢è¿™ä¹ˆéº»çƒ¦ï¼Œåæ­£éƒ½å¯ä»¥ç›´æ¥å…¥æ¨¡å‹çš„ï¼Œä½•å¿…å¤šæ­¤ä¸€ä¸¾ï¼Ÿ

å½“ç„¶äº†ï¼è¿™ä¸ªæƒ³æ³•ä¹Ÿæ˜¯æ²¡é”™çš„ï¼Œåœ¨æœ¬å°èŠ‚å¼€å¤´ä¹Ÿå·²ç»è¯´æ˜äº†ï¼Œå¹¶éè¦æ±‚æ‰€æœ‰çš„å˜é‡éƒ½è¦è¿›è¡ŒWOEç¼–ç ç„¶åè¿›å…¥æ¨¡å‹ã€‚**è€Œä»€ä¹ˆæƒ…å†µä¸‹ååˆ†é€‚åˆWOEè½¬æ¢å‘¢ï¼Œé‚£å°±æ˜¯å˜é‡æœ¬èº«ä¸yå€¼å¹¶éå­˜åœ¨ç›´æ¥çº¿æ€§å…³ç³»çš„æ—¶å€™ã€‚**

![image-20201018152118144](./arrests/60.png)

æˆ‘ä»¬çœ‹ä¸Šé¢çš„å›¾ï¼Œâ€œå¹´é¾„â€è¿™ä¸ªå­—æ®µç»å¸¸æ€§åœ°ä¼šå‡ºç°åœ¨æˆ‘ä»¬çš„Aå¡æ¨¡å‹é‡Œï¼Œä½œä¸ºé¢„æµ‹ä¸€ä¸ªå®¢æˆ·ä¿¡ç”¨æ°´å¹³çš„è¡¡é‡æŒ‡æ ‡ã€‚æˆ‘ä»¬å¯ä»¥æ¸…æ¥šçŸ¥é“ï¼Œageè¿™ä¸ªå˜é‡çš„badrateåˆ†å¸ƒï¼Œç»å¸¸æ€§ä¼šå‘ˆç°â€œUå‹â€ï¼Œä¸šåŠ¡è§£é‡Šå°±æ˜¯ï¼šå¹´è½»äººå’Œè€å¹´äººçš„è¿˜æ¬¾èƒ½åŠ›ä¼šæ¯”ä¸­å¹´äººçš„è¦ä½ï¼Œé£é™©ä¹Ÿå› æ­¤æ›´é«˜ã€‚ä»ç»Ÿè®¡è§’åº¦çœ‹ï¼Œå¹´é¾„ä¸è¿çº¦ç‡ï¼Œä¾¿ä¸æ˜¯ä¸€ä¸ªçº¿æ€§å…³ç³»ï¼

æˆ‘ä»¬å›å¿†ä¸€ä¸‹LRæ¨¡å‹ï¼ˆLogistic Regressionï¼‰ï¼Œä»æœ¬è´¨ä¸Šè®²ï¼ŒLRå°±æ˜¯ç»è¿‡å¯¹è®­ç»ƒé›†çš„å­¦ä¹ ï¼Œå¾—åˆ°ä¸€ç»„æƒå€¼wï¼Œå½“æœ‰æ–°çš„ä¸€ç»„æ•°æ®xè¾“å…¥æ—¶ï¼Œæ ¹æ®å…¬å¼è®¡ç®—å‡ºç»“æœï¼Œç„¶åç»è¿‡Sigmoidå‡½æ•°åˆ¤æ–­è¿™ä¸ªæ•°æ®æ‰€å±çš„ç±»åˆ«ã€‚

$$h_w(x) = w_0+w_1x_1+w_2x_2+...+w_nx_n$$

å‡å¦‚æˆ‘ä»¬çš„å¹´é¾„å°±æ˜¯ä¸Šé¢çš„x1ï¼Œå¹¶ä¸”æ¨¡å‹åªæœ‰ä¸€ä¸ªå˜é‡ï¼Œé‚£ä¹ˆéšç€x1çš„å˜å¤§ï¼Œ$h_w(x)$çš„å€¼ä¹Ÿä¼šä¸æ–­å˜å¤§ï¼Œè€Œä¸æ˜¯åƒä¸Šå›¾ä¸€æ ·å‘ˆç°â€œUå‹â€ï¼Œè¯´æ˜äº†è¿™æ˜¯ä¸€ä¸ªéçº¿æ€§çš„é—®é¢˜ï¼Œä½†å¦‚æœæˆ‘ä»¬å¯¹å¹´é¾„è¿›è¡ŒWOEè½¬æ¢ï¼Œå°±å¯ä»¥çœ‹åˆ°å¦‚å³å›¾æ‰€ç¤ºçš„é‚£æ ·ï¼Œéšç€WOEçš„å¢å¤§ï¼Œgoodrateä¹Ÿå¢å¤§è¿™ç§çº¿æ€§å…³ç³»ï¼ˆbadrate=1-goodrateï¼Œå› æ­¤å’Œbadrateä¹Ÿæ˜¯çº¿å½¢å…³ç³»ï¼‰ã€‚

ä»¥ä¸Šä¹Ÿæ˜¯ä½¿ç”¨WOEç¼–ç çš„ä¸€ä¸ªæœ€å¤§å¥½å¤„ï¼Œä¹Ÿå°±æ˜¯æŠŠbadrateå‘ˆç°éçº¿æ€§çš„å˜é‡è½¬æ¢ä¸ºçº¿å½¢ï¼Œä¾¿äºç†è§£ä¹Ÿä¾¿äºåç»­æ¨¡å‹æ±‚è§£ã€‚æ­¤å¤–ï¼ŒWOEç¼–ç è¿˜æœ‰ä¸€ä¸ªå¥½å¤„ï¼Œé‚£å°±æ˜¯å…·æœ‰â€œå®¹é”™æ€§â€ï¼Œå› ä¸ºWOEç¼–ç å…¶å®ä¹Ÿå¯ä»¥ç†è§£ä¸ºéœ€è¦é¢„å…ˆåˆ†ç®±ï¼Œé‚£ä¹ˆå¯¹äºå¼‚å¸¸å€¼æ²¡é‚£ä¹ˆæ•æ„Ÿï¼Œå¯¹äºå•ä¸ªå˜é‡çš„å¼‚å¸¸æ³¢åŠ¨ä¸ä¼šæœ‰å¤ªå¤§ååº”ã€‚



#### ğŸ¤” WOEä¸å•è°ƒå¯ä»¥è¿›LRæ¨¡å‹å—ï¼Ÿ

é‚£ä¹ˆæˆ‘ä»¬å›åˆ°æœ€åˆçš„é—®é¢˜ï¼Œé‚£å°±æ˜¯å¦‚æ ‡é¢˜æ‰€è¯´çš„ï¼šWOEå‰çš„åˆ†ç®±ä¸€å®šè¦å•è°ƒå—ï¼Ÿç»“è®ºæ˜¯ä¸ä¸€å®šéœ€è¦å•è°ƒã€‚è¦æ·±å…¥äº†è§£è¿™ç­”æ¡ˆï¼Œæˆ‘ä»¬å¯ä»¥çœ‹çœ‹ä¸‹é¢ä¸¤ä¸ªè®¨è®ºï¼š

##### 01 é’ˆå¯¹ä¸åŒç±»å‹çš„å˜é‡

1ï¼‰é’ˆå¯¹ç±»åˆ«å˜é‡ğŸ˜‹

ç±»åˆ«å˜é‡å¯ä»¥åˆ†æœ‰åºå’Œæ— åºå˜é‡ã€‚

é’ˆå¯¹æœ‰åºç±»åˆ«å˜é‡ï¼Œæ¯”å¦‚åƒå­¦å†ï¼Œæˆ‘ä»¬åˆ†ç®±çš„æ—¶å€™è¦ä¿è¯åŸå§‹é¡ºåºçš„å‰æä¸‹ï¼Œè¿›è¡Œä¸åŒåŸå§‹ç»„åˆ«çš„åˆå¹¶ï¼Œå®Œæˆåˆ†ç®±ï¼Œç„¶åéœ€è¦çœ‹åˆ†ç®±çš„badrateå•è°ƒæ€§ï¼Œæœ€åæ‰æ¥çœ‹WOEå•è°ƒæ€§æƒ…å†µã€‚

é’ˆå¯¹æ— åºç±»åˆ«å˜é‡ï¼Œæ— åºç±»åˆ«å˜é‡åˆå¯ä»¥æ ¹æ®æšä¸¾å€¼çš„å¤šå°‘æ‹†åˆ†ä¸ºä¸¤ç±»ï¼šå¤šæšä¸¾æ— åºç±»åˆ«å˜é‡å’Œå°‘æšä¸¾æ— åºç±»åˆ«å˜é‡ã€‚æ— è®ºæ˜¯å“ªä¸€ç§ï¼Œæˆ‘ä»¬éƒ½å¯ä»¥æ ¹æ®å¯¹æ¯ä¸ªæšä¸¾å€¼çš„badrateç»Ÿè®¡å¾—åˆ°å…¶é‡åŒ–æŒ‡æ ‡ï¼Œç„¶åæ ¹æ®badrateè¿›è¡Œé€‚å½“çš„ç±»åˆ«åˆå¹¶ï¼Œå®Œæˆåˆ†ç®±æ“ä½œï¼Œè¿™æ—¶å€™çš„åˆ†ç®±ç»“æœï¼Œå¤©ç„¶å•è°ƒï¼è€Œé’ˆå¯¹å°‘æšä¸¾æ— åºç±»åˆ«å˜é‡ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥æ ¹æ®ä¸šåŠ¡è®¤è¯†ï¼Œè¿›è¡Œç±»åˆ«çš„åˆå¹¶ï¼Œæ¯”å¦‚åƒä¸­å›½å¤§åŒºå­—æ®µï¼ˆåå—ã€ååŒ—ç­‰ï¼‰ï¼ŒWOEç¼–ç åï¼Œä¹Ÿä¸åšä¸¥æ ¼çš„å•è°ƒæ€§è¦æ±‚ã€‚

2ï¼‰é’ˆå¯¹æ•°å€¼å˜é‡ğŸ˜†

è¿›è¡Œåˆé€‚çš„åˆ†ç®±ç®—æ³•è¿›è¡Œåˆ†ç®±åçš„binï¼Œéœ€è¦æ»¡è¶³badrateå•è°ƒæ€§ï¼Œç„¶åæ‰è¿›è¡ŒWOEç¼–ç ã€‚ä¸è¿‡å‘¢ï¼Œè¿™ä¸ªä¹Ÿä¸æ˜¯ä¸¥æ ¼è¦æ±‚çš„ã€‚

##### 02 ä¸ºä»€ä¹ˆéœ€è¦WOEå…·å¤‡å•è°ƒæ€§

WOEä¸ä¸€å®šéƒ½éœ€è¦æ˜¯å•è°ƒçš„ï¼Œåªè¦ä»ä¸šåŠ¡è§’åº¦å¯ä»¥è§£é‡Šå¾—é€šï¼Œé‚£å°±æ²¡æœ‰é—®é¢˜ï¼å°±å¥½åƒä¸Šé¢çš„é‚£ä¸ªæ —å­ï¼Œå¹´é¾„å­—æ®µï¼ŒWOEå°±ä¸æ˜¯å•è°ƒçš„ï¼Œä½†ä»ä¸šåŠ¡ä¸Šå¯ä»¥è§£é‡Šå¾—é€šï¼Œé‚£å°±æ²¡æœ‰é—®é¢˜ï¼

å¦‚æœä»ä¸šåŠ¡ä¸Šè§£é‡Šæ˜¯éœ€è¦å•è°ƒæ€§ï¼Œä½†åˆ†ç»„åçš„WOEå¹¶æ²¡æœ‰å•è°ƒï¼Œé‚£ä¹ˆè¿™æ—¶å€™æœ‰ä¸¤æ¡è·¯å¯ä»¥é€‰æ‹©ï¼Œä¸€æ˜¯é‡æ–°åˆ†ç»„ç„¶åé‡æ–°è®¡ç®—WOEï¼ŒäºŒæ˜¯æ”¾å¼ƒè¿™ä¸ªå˜é‡ã€‚

æœ€åæä¸€ä¸‹ï¼Œå¦‚æœä¸å•è°ƒçš„å˜é‡ä¸è¿›è¡ŒWOEç¼–ç ç›´æ¥è¿›å…¥LRæ¨¡å‹ï¼Œä¸€èˆ¬éƒ½æ˜¯å¾ˆéš¾æ±‚è§£çš„ï¼Œå› ä¸ºå¾ˆéš¾æ‰¾åˆ°ä¸€ä¸ªçº¿æ€§å…¬å¼æ¥æè¿°å…³ç³»ã€‚



#### ğŸ† ç»“è®ºå¤ç›˜

1ï¼‰LRæ¨¡å‹çš„å…¥å‚ä¸ä¸€å®šéƒ½è¦WOEè½¬æ¢ï¼Œç›´æ¥è¿›è¡Œæ¨¡å‹ä¹Ÿæ˜¯å¯ä»¥çš„ï¼Œåªæ˜¯é‡ä¸Šä¸å•è°ƒçš„å˜é‡ä¼šæ¯”è¾ƒéš¾æ±‚è§£ç½¢äº†ï¼Œå¯é€‰æ‹©ä¸¢å¼ƒã€‚

2ï¼‰ä½¿ç”¨WOEç¼–ç çš„ä¸€ä¸ªæœ€å¤§å¥½å¤„æ˜¯æŠŠbadrateå‘ˆç°éçº¿æ€§çš„å˜é‡è½¬æ¢ä¸ºçº¿å½¢ï¼Œä¾¿äºç†è§£ä¹Ÿä¾¿äºåç»­æ¨¡å‹æ±‚è§£ï¼Œè¿›è¡Œäº†WOEç¼–ç çš„æ¨¡å‹å¯¹äºå¼‚å¸¸å€¼æ²¡é‚£ä¹ˆæ•æ„Ÿï¼Œå•ä¸ªå˜é‡çš„å¼‚å¸¸æ³¢åŠ¨ä¸ä¼šå¯¹æ¨¡å‹é€ æˆå¾ˆå¤§ååº”ã€‚

3ï¼‰WOEå¹¶ä¸ä¸€å®šéƒ½éœ€è¦æ˜¯å•è°ƒçš„ï¼Œåªè¦ä»ä¸šåŠ¡è§’åº¦å¯ä»¥è§£é‡Šå¾—é€šå³å¯ã€‚



<a href="#ç›®å½•Keep-updating">ğŸ˜‹ ç‚¹æˆ‘å¯ä»¥å›åˆ°ç›®å½•å“¦ ğŸš—</a>

## Tip28ï¼šå¦‚ä½•åœ¨Pythonä¸­å¤„ç†ä¸å¹³è¡¡æ•°æ®

#### ğŸš™ Index

1ã€åˆ°åº•ä»€ä¹ˆæ˜¯ä¸å¹³è¡¡æ•°æ®

2ã€å¤„ç†ä¸å¹³è¡¡æ•°æ®çš„ç†è®ºæ–¹æ³•

3ã€Pythoné‡Œæœ‰ä»€ä¹ˆåŒ…å¯ä»¥å¤„ç†ä¸å¹³è¡¡æ ·æœ¬

4ã€Pythonä¸­å…·ä½“å¦‚ä½•å¤„ç†å¤±è¡¡æ ·æœ¬



å°è±¡ä¸­å¾ˆä¹…ä¹‹å‰æœ‰ä½æœ‹å‹è¯´è¦æˆ‘å†™ä¸€ç¯‡å¦‚ä½•å¤„ç†ä¸å¹³è¡¡æ•°æ®çš„æ–‡ç« ï¼Œæ•´ç†ç›¸å…³çš„ç†è®ºä¸å®è·µçŸ¥è¯†ï¼ˆå¯æƒœæœ¬äººå¤ªæ‡’äº†ï¼Œç°åœ¨æ‰å¼€å§‹å†™ï¼‰ï¼Œäºæ˜¯ä¹æœ‰äº†ä»Šå¤©çš„æ–‡ç« ã€‚å¤±è¡¡æ ·æœ¬åœ¨æˆ‘ä»¬çœŸå®ä¸–ç•Œä¸­æ˜¯ååˆ†å¸¸è§çš„ï¼Œé‚£ä¹ˆæˆ‘ä»¬åœ¨æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ä¸­ä½¿ç”¨è¿™äº›å¤±è¡¡æ ·æœ¬æ•°æ®ä¼šå‡ºç°ä»€ä¹ˆé—®é¢˜å‘¢ï¼Ÿå¦‚ä½•å¤„ç†è¿™äº›å¤±è¡¡æ ·æœ¬å‘¢ï¼Ÿä»¥ä¸‹çš„å†…å®¹å¸Œæœ›å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼

#### ğŸ¤” åˆ°åº•ä»€ä¹ˆæ˜¯ä¸å¹³è¡¡æ•°æ®

å¤±è¡¡æ•°æ®å‘ç”Ÿåœ¨åˆ†ç±»åº”ç”¨åœºæ™¯ä¸­ï¼Œåœ¨åˆ†ç±»é—®é¢˜ä¸­ï¼Œç±»åˆ«ä¹‹é—´çš„åˆ†å¸ƒä¸å‡åŒ€å°±æ˜¯å¤±è¡¡çš„æ ¹æœ¬ï¼Œå‡è®¾æœ‰ä¸ªäºŒåˆ†ç±»é—®é¢˜ï¼Œtargetä¸ºyï¼Œé‚£ä¹ˆyçš„å–å€¼èŒƒå›´ä¸º0å’Œ1ï¼Œå½“å…¶ä¸­ä¸€æ–¹ï¼ˆæ¯”å¦‚y=1ï¼‰çš„å æ¯”è¿œå°äºå¦ä¸€æ–¹ï¼ˆy=0ï¼‰çš„æ—¶å€™ï¼Œå°±æ˜¯å¤±è¡¡æ ·æœ¬äº†ã€‚

é‚£ä¹ˆåˆ°åº•æ˜¯éœ€è¦å·®å¼‚å¤šå°‘ï¼Œæ‰ç®—æ˜¯å¤±è¡¡å‘¢ï¼Œæ ¹æœ¬Google Developerçš„è¯´æ³•ï¼Œæˆ‘ä»¬ä¸€èˆ¬å¯ä»¥æŠŠå¤±è¡¡åˆ†ä¸º3ä¸ªç¨‹åº¦ï¼š

* è½»åº¦ï¼š20-40%
* ä¸­åº¦ï¼š1-20%
* æåº¦ï¼š<1%

ä¸€èˆ¬æ¥è¯´ï¼Œå¤±è¡¡æ ·æœ¬åœ¨æˆ‘ä»¬æ„å»ºæ¨¡å‹çš„æ—¶å€™çœ‹ä¸å‡ºä»€ä¹ˆé—®é¢˜ï¼Œè€Œä¸”å¾€å¾€æˆ‘ä»¬è¿˜å¯ä»¥å¾—åˆ°å¾ˆé«˜çš„accuracyï¼Œä¸ºä»€ä¹ˆå‘¢ï¼Ÿå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªæåº¦å¤±è¡¡çš„æ ·æœ¬ï¼Œy=1çš„å æ¯”ä¸º1%ï¼Œé‚£ä¹ˆï¼Œæˆ‘ä»¬è®­ç»ƒçš„æ¨¡å‹ï¼Œä¼šåå‘äºæŠŠæµ‹è¯•é›†é¢„æµ‹ä¸º0ï¼Œè¿™æ ·å­æ¨¡å‹æ•´ä½“çš„é¢„æµ‹å‡†ç¡®æ€§å°±ä¼šæœ‰ä¸€ä¸ªå¾ˆå¥½çœ‹çš„æ•°å­—ï¼Œå¦‚æœæˆ‘ä»¬åªæ˜¯å…³æ³¨è¿™ä¸ªæŒ‡æ ‡çš„è¯ï¼Œå¯èƒ½å°±ä¼šè¢«éª—äº†ã€‚



#### ğŸ“– å¤„ç†ä¸å¹³è¡¡æ•°æ®çš„ç†è®ºæ–¹æ³•

åœ¨æˆ‘ä»¬å¼€å§‹ç”¨Pythonå¤„ç†å¤±è¡¡æ ·æœ¬ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ¥äº†è§£ä¸€æ³¢å…³äºå¤„ç†å¤±è¡¡æ ·æœ¬çš„ä¸€äº›ç†è®ºçŸ¥è¯†ï¼Œå‰è¾ˆä»¬å…³äºè¿™ç±»é—®é¢˜çš„è§£å†³æ–¹æ¡ˆï¼Œä¸»è¦åŒ…æ‹¬ä»¥ä¸‹ï¼š

* ä»æ•°æ®è§’åº¦ï¼šé€šè¿‡åº”ç”¨ä¸€äº›æ¬ é‡‡æ ·orè¿‡é‡‡æ ·æŠ€æœ¯æ¥å¤„ç†å¤±è¡¡æ ·æœ¬ã€‚æ¬ é‡‡æ ·å°±æ˜¯å¯¹å¤šæ•°ç±»è¿›è¡ŒæŠ½æ ·ï¼Œä¿ç•™å°‘æ•°ç±»çš„å…¨é‡ï¼Œä½¿å¾—ä¸¤ç±»çš„æ•°é‡ç›¸å½“ï¼Œè¿‡é‡‡æ ·å°±æ˜¯å¯¹å°‘æ•°ç±»è¿›è¡Œå¤šæ¬¡é‡å¤é‡‡æ ·ï¼Œä¿ç•™å¤šæ•°ç±»çš„å…¨é‡ï¼Œä½¿å¾—ä¸¤ç±»çš„æ•°é‡ç›¸å½“ã€‚ä½†æ˜¯ï¼Œè¿™ç±»åšæ³•ä¹Ÿæœ‰å¼Šç«¯ï¼Œæ¬ é‡‡æ ·ä¼šå¯¼è‡´æˆ‘ä»¬ä¸¢å¤±ä¸€éƒ¨åˆ†çš„ä¿¡æ¯ï¼Œå¯èƒ½åŒ…å«äº†ä¸€äº›é‡è¦çš„ä¿¡æ¯ï¼Œè¿‡é‡‡æ ·åˆ™ä¼šå¯¼è‡´åˆ†ç±»å™¨å®¹æ˜“è¿‡æ‹Ÿåˆã€‚å½“ç„¶ï¼Œä¹Ÿå¯ä»¥æ˜¯ä¸¤ç§æŠ€æœ¯çš„ç›¸äº’ç»“åˆã€‚
* ä»ç®—æ³•è§’åº¦ï¼šç®—æ³•è§’åº¦çš„è§£å†³æ–¹æ¡ˆå°±æ˜¯å¯ä»¥é€šè¿‡å¯¹æ¯ç±»çš„è®­ç»ƒå®ä¾‹ç»™äºˆä¸€å®šæƒå€¼çš„è°ƒæ•´ã€‚æ¯”å¦‚åƒåœ¨SVMè¿™æ ·å­çš„æœ‰å‚åˆ†ç±»å™¨ä¸­ï¼Œå¯ä»¥åº”ç”¨grid searchï¼ˆç½‘æ ¼æœç´¢ï¼‰ä»¥åŠäº¤å‰éªŒè¯ï¼ˆcross validationï¼‰æ¥ä¼˜åŒ–Cä»¥åŠgammaå€¼ã€‚è€Œå¯¹äºå†³ç­–æ ‘è¿™ç±»çš„éå‚æ•°æ¨¡å‹ï¼Œå¯ä»¥é€šè¿‡è°ƒæ•´æ ‘å¶èŠ‚ç‚¹ä¸Šçš„æ¦‚ç‡ä¼°è®¡ä»è€Œå®ç°æ•ˆæœä¼˜åŒ–ã€‚

æ­¤å¤–ï¼Œä¹Ÿæœ‰ç ”ç©¶å‘˜ä»æ•°æ®ä»¥åŠç®—æ³•çš„ç»“åˆè§’åº¦æ¥çœ‹å¾…è¿™ç±»é—®é¢˜ï¼Œæå‡ºäº†ä¸¤è€…ç»“åˆä½“çš„AdaOUBoostï¼ˆadaptive over-sampling and undersampling boostï¼‰ç®—æ³•ï¼Œè¿™ä¸ªç®—æ³•çš„æ–°é¢–ä¹‹å¤„åœ¨äºè‡ªé€‚åº”åœ°å¯¹å°‘æ•°ç±»æ ·æœ¬è¿›è¡Œè¿‡é‡‡æ ·ï¼Œç„¶åå¯¹å¤šæ•°ç±»æ ·æœ¬è¿›è¡Œæ¬ é‡‡æ ·ï¼Œä»¥å½¢æˆä¸åŒçš„åˆ†ç±»å™¨ï¼Œå¹¶æ ¹æ®å…¶å‡†ç¡®åº¦å°†è¿™äº›å­åˆ†ç±»å™¨ç»„åˆåœ¨ä¸€èµ·ä»è€Œå½¢æˆå¼ºå¤§çš„åˆ†ç±»å™¨ï¼Œæ›´å¤šçš„è¯·å‚è€ƒï¼š

> AdaOUBoostï¼šhttps://dl.acm.org/doi/10.1145/1743384.1743408



#### ğŸš€ Pythoné‡Œæœ‰ä»€ä¹ˆåŒ…å¯ä»¥å¤„ç†ä¸å¹³è¡¡æ ·æœ¬

è¿™é‡Œä»‹ç»ä¸€ä¸ªå¾ˆä¸é”™çš„åŒ…ï¼Œå« **imbalanced-learn**ï¼Œå¤§å®¶å¯ä»¥åœ¨ç”µè„‘ä¸Šå®‰è£…ä¸€ä¸‹ä½¿ç”¨ã€‚

> å®˜æ–¹æ–‡æ¡£ï¼šhttps://imbalanced-learn.readthedocs.io/en/stable/index.html

```shell
pip install -U imbalanced-learn

```

![image-20201114201826826](./arrests/61.png)

ä½¿ç”¨ä¸Šé¢çš„åŒ…ï¼Œæˆ‘ä»¬å°±å¯ä»¥å®ç°æ ·æœ¬çš„æ¬ é‡‡æ ·ã€è¿‡é‡‡æ ·ï¼Œå¹¶ä¸”å¯ä»¥åˆ©ç”¨pipelineçš„æ–¹å¼æ¥å®ç°ä¸¤è€…çš„ç»“åˆï¼Œååˆ†æ–¹ä¾¿ï¼Œæˆ‘ä»¬ä¸‹ä¸€èŠ‚æ¥ç®€å•ä½¿ç”¨ä¸€ä¸‹å§ï¼



#### ğŸ¦ˆ Pythonä¸­å…·ä½“å¦‚ä½•å¤„ç†å¤±è¡¡æ ·æœ¬

ä¸ºäº†æ›´å¥½æ»´ç†è§£ï¼Œæˆ‘ä»¬å¼•å…¥ä¸€ä¸ªæ•°æ®é›†ï¼Œæ¥è‡ªäºUCIæœºå™¨å­¦ä¹ å­˜å‚¨åº“çš„è¥é”€æ´»åŠ¨æ•°æ®é›†ã€‚(æ•°æ®é›†å¤§å®¶å¯ä»¥è‡ªå·±å»å®˜ç½‘ä¸‹è½½ï¼šhttps://archive.ics.uci.edu/ml/machine-learning-databases/00222/  ä¸‹è½½bank-additional.zip æˆ–è€…åˆ°å…¬ä¼—å·åå°å›å¤å…³é”®å­—â€œbankâ€æ¥è·å–å§ã€‚)

æˆ‘ä»¬åœ¨å®Œæˆimblearnåº“çš„å®‰è£…ä¹‹åï¼Œå°±å¯ä»¥å¼€å§‹ç®€å•çš„æ“ä½œäº†ï¼ˆå…¶ä½™æ›´åŠ å¤æ‚çš„æ“ä½œå¯ä»¥ç›´æ¥çœ‹å®˜æ–¹æ–‡æ¡£ï¼‰ï¼Œä»¥ä¸‹æˆ‘ä¼šä»4æ–¹é¢æ¥æ¼”ç¤ºå¦‚ä½•ç”¨Pythonå¤„ç†å¤±è¡¡æ ·æœ¬ï¼Œåˆ†åˆ«æ˜¯ï¼š

ğŸŒˆ1ã€éšæœºæ¬ é‡‡æ ·çš„å®ç°

ğŸŒˆ2ã€ä½¿ç”¨SMOTEè¿›è¡Œè¿‡é‡‡æ ·

ğŸŒˆ3ã€æ¬ é‡‡æ ·å’Œè¿‡é‡‡æ ·çš„ç»“åˆï¼ˆä½¿ç”¨pipelineï¼‰

ğŸŒˆ4ã€å¦‚ä½•è·å–æœ€ä½³çš„é‡‡æ ·ç‡ï¼Ÿ



##### ğŸš—ğŸš—ğŸš— é‚£æˆ‘ä»¬å¼€å§‹å§ï¼

```python
# å¯¼å…¥ç›¸å…³çš„åº“ï¼ˆä¸»è¦å°±æ˜¯imblearnåº“ï¼‰
from collections import Counter
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
import pandas as pd
import numpy as np
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

from sklearn.svm import SVC
from sklearn.metrics import classification_report, roc_auc_score
from numpy import mean

# å¯¼å…¥æ•°æ®
df = pd.read_csv(r'./data/bank-additional/bank-additional-full.csv', ';') # '';'' ä¸ºåˆ†éš”ç¬¦
df.head()

```

![image-20201114203736871](./arrests/62.png)



æ•°æ®é›†æ˜¯è‘¡è„ç‰™é“¶è¡Œçš„æŸæ¬¡è¥é”€æ´»åŠ¨çš„æ•°æ®ï¼Œå…¶è¥é”€ç›®æ ‡å°±æ˜¯è®©å®¢æˆ·è®¢é˜…ä»–ä»¬çš„äº§å“ï¼Œç„¶åä»–ä»¬é€šè¿‡ä¸å®¢æˆ·çš„ç”µè¯æ²Ÿé€šä»¥åŠå…¶ä»–æ¸ é“è·å–åˆ°çš„å®¢æˆ·ä¿¡æ¯ï¼Œç»„æˆäº†è¿™ä¸ªæ•°æ®é›†ã€‚

å…³äºå­—æ®µé‡Šä¹‰ï¼Œå¯ä»¥çœ‹ä¸‹é¢çš„æˆªå›¾ï¼š

![image-20201114203827825](./arrests/63.png)

æˆ‘ä»¬å¯ä»¥å¤§è‡´çœ‹çœ‹æ•°æ®é›†æ˜¯ä¸æ˜¯å¤±è¡¡æ ·æœ¬ï¼š

```python
df['y'].value_counts()/len(df)

#no     0.887346
#yes    0.112654
#Name: y, dtype: float64

```

å¯ä»¥çœ‹å‡ºå°‘æ•°ç±»çš„å æ¯”ä¸º11.2%ï¼Œå±äº**ä¸­åº¦å¤±è¡¡æ ·æœ¬**ã€‚

```python
# åªä¿ç•™æ•°å€¼å‹å˜é‡ï¼ˆç®€å•æ“ä½œï¼‰
df = df.loc[:,
['age', 'duration', 'campaign', 'pdays',
       'previous', 'emp.var.rate', 'cons.price.idx',
       'cons.conf.idx', 'euribor3m', 'nr.employed','y']]
# targetç”± yes/no è½¬ä¸º 0/1
df['y'] = df['y'].apply(lambda x: 1 if x=='yes' else 0)
df['y'].value_counts()

#0    36548
#1     4640
#Name: y, dtype: int64

```



##### ğŸŒˆ1ã€éšæœºæ¬ é‡‡æ ·çš„å®ç°

æ¬ é‡‡æ ·åœ¨imblearnåº“ä¸­ä¹Ÿæ˜¯æœ‰æ–¹æ³•å¯ä»¥ç”¨çš„ï¼Œé‚£å°±æ˜¯ `under_sampling.RandomUnderSampler`ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æŠŠæ–¹æ³•å¼•å…¥ï¼Œç„¶åè°ƒç”¨å®ƒã€‚å¯è§ï¼ŒåŸå…ˆ0çš„æ ·æœ¬æœ‰21942ï¼Œæ¬ é‡‡æ ·ä¹‹åå°±å˜æˆäº†ä¸1ä¸€æ ·çš„æ•°é‡äº†ï¼ˆå³2770ï¼‰ï¼Œå®ç°äº†50%/50%çš„ç±»åˆ«åˆ†å¸ƒã€‚

```python
# 1ã€éšæœºæ¬ é‡‡æ ·çš„å®ç°
# å¯¼å…¥ç›¸å…³çš„æ–¹æ³•
from imblearn.under_sampling import RandomUnderSampler

# åˆ’åˆ†å› å˜é‡å’Œè‡ªå˜é‡
X = df.iloc[:,:-1]
y = df.iloc[:,-1]

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.40)

# ç»Ÿè®¡å½“å‰çš„ç±»åˆ«å æ¯”æƒ…å†µ
print("Before undersampling: ", Counter(y_train))

# è°ƒç”¨æ–¹æ³•è¿›è¡Œæ¬ é‡‡æ ·
undersample = RandomUnderSampler(sampling_strategy='majority')

# è·å¾—æ¬ é‡‡æ ·åçš„æ ·æœ¬
X_train_under, y_train_under = undersample.fit_resample(X_train, y_train)

# ç»Ÿè®¡æ¬ é‡‡æ ·åçš„ç±»åˆ«å æ¯”æƒ…å†µ
print("After undersampling: ", Counter(y_train_under))

# è°ƒç”¨æ”¯æŒå‘é‡æœºç®—æ³• SVC
model=SVC()

clf = model.fit(X_train, y_train)
pred = clf.predict(X_test)
print("ROC AUC score for original data: ", roc_auc_score(y_test, pred))

clf_under = model.fit(X_train_under, y_train_under)
pred_under = clf_under.predict(X_test)
print("ROC AUC score for undersampled data: ", roc_auc_score(y_test, pred_under))

# Outputï¼š
#Before undersampling:  Counter({0: 21942, 1: 2770})
#After undersampling:  Counter({0: 2770, 1: 2770})
#ROC AUC score for original data:  0.603521152028
#ROC AUC score for undersampled data:  0.829234085179
```



ğŸŒˆ2ã€ä½¿ç”¨SMOTEè¿›è¡Œè¿‡é‡‡æ ·

è¿‡é‡‡æ ·æŠ€æœ¯ä¸­ï¼ŒSMOTEè¢«è®¤ä¸ºæ˜¯æœ€ä¸ºæµè¡Œçš„æ•°æ®é‡‡æ ·ç®—æ³•ä¹‹ä¸€ï¼Œå®ƒæ˜¯åŸºäºéšæœºè¿‡é‡‡æ ·ç®—æ³•çš„ä¸€ç§æ”¹è‰¯ç‰ˆæœ¬ï¼Œç”±äºéšæœºè¿‡é‡‡æ ·åªæ˜¯é‡‡å–äº†ç®€å•å¤åˆ¶æ ·æœ¬çš„ç­–ç•¥æ¥è¿›è¡Œæ ·æœ¬çš„æ‰©å¢ï¼Œè¿™æ ·å­ä¼šå¯¼è‡´ä¸€ä¸ªæ¯”è¾ƒç›´æ¥çš„é—®é¢˜å°±æ˜¯è¿‡æ‹Ÿåˆã€‚å› æ­¤ï¼ŒSMOTEçš„åŸºæœ¬æ€æƒ³å°±æ˜¯å¯¹å°‘æ•°ç±»æ ·æœ¬è¿›è¡Œåˆ†æå¹¶åˆæˆæ–°æ ·æœ¬æ·»åŠ åˆ°æ•°æ®é›†ä¸­ã€‚

> ç®—æ³•æµç¨‹å¦‚ä¸‹ï¼š
>
> (1)å¯¹äºå°‘æ•°ç±»ä¸­æ¯ä¸€ä¸ªæ ·æœ¬xï¼Œä»¥æ¬§æ°è·ç¦»ä¸ºæ ‡å‡†è®¡ç®—å®ƒåˆ°å°‘æ•°ç±»æ ·æœ¬é›†ä¸­æ‰€æœ‰æ ·æœ¬çš„è·ç¦»ï¼Œå¾—åˆ°å…¶kè¿‘é‚»ã€‚
>
> (2)æ ¹æ®æ ·æœ¬ä¸å¹³è¡¡æ¯”ä¾‹è®¾ç½®ä¸€ä¸ªé‡‡æ ·æ¯”ä¾‹ä»¥ç¡®å®šé‡‡æ ·å€ç‡Nï¼Œå¯¹äºæ¯ä¸€ä¸ªå°‘æ•°ç±»æ ·æœ¬xï¼Œä»å…¶kè¿‘é‚»ä¸­éšæœºé€‰æ‹©è‹¥å¹²ä¸ªæ ·æœ¬ï¼Œå‡è®¾é€‰æ‹©çš„è¿‘é‚»ä¸ºxnã€‚
>
> (3)å¯¹äºæ¯ä¸€ä¸ªéšæœºé€‰å‡ºçš„è¿‘é‚»xnï¼Œåˆ†åˆ«ä¸åŸæ ·æœ¬æŒ‰ç…§å¦‚ä¸‹çš„å…¬å¼æ„å»ºæ–°çš„æ ·æœ¬ã€‚

![image-20201114230817992](./arrests/64.png)

```python
# 2ã€ä½¿ç”¨SMOTEè¿›è¡Œè¿‡é‡‡æ ·
# å¯¼å…¥ç›¸å…³çš„æ–¹æ³•
from imblearn.over_sampling import SMOTE

# åˆ’åˆ†å› å˜é‡å’Œè‡ªå˜é‡
X = df.iloc[:,:-1]
y = df.iloc[:,-1]

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.40)

# ç»Ÿè®¡å½“å‰çš„ç±»åˆ«å æ¯”æƒ…å†µ
print("Before oversampling: ", Counter(y_train))

# è°ƒç”¨æ–¹æ³•è¿›è¡Œè¿‡é‡‡æ ·
SMOTE = SMOTE()

# è·å¾—è¿‡é‡‡æ ·åçš„æ ·æœ¬
X_train_SMOTE, y_train_SMOTE = SMOTE.fit_resample(X_train, y_train)

# ç»Ÿè®¡è¿‡é‡‡æ ·åçš„ç±»åˆ«å æ¯”æƒ…å†µ
print("After oversampling: ",Counter(y_train_SMOTE))

# è°ƒç”¨æ”¯æŒå‘é‡æœºç®—æ³• SVC
model=SVC()

clf = model.fit(X_train, y_train)
pred = clf.predict(X_test)
print("ROC AUC score for original data: ", roc_auc_score(y_test, pred))

clf_SMOTE= model.fit(X_train_SMOTE, y_train_SMOTE)
pred_SMOTE = clf_SMOTE.predict(X_test)
print("ROC AUC score for oversampling data: ", roc_auc_score(y_test, pred_SMOTE))

# Outputï¼š
#Before oversampling:  Counter({0: 21980, 1: 2732})
#After oversampling:  Counter({0: 21980, 1: 21980})
#ROC AUC score for original data:  0.602555700614
#ROC AUC score for oversampling data:  0.844305732561
```



ğŸŒˆ3ã€æ¬ é‡‡æ ·å’Œè¿‡é‡‡æ ·çš„ç»“åˆï¼ˆä½¿ç”¨pipelineï¼‰

é‚£å¦‚æœæˆ‘ä»¬éœ€è¦åŒæ—¶ä½¿ç”¨è¿‡é‡‡æ ·ä»¥åŠæ¬ é‡‡æ ·ï¼Œé‚£è¯¥æ€ä¹ˆåšå‘¢ï¼Ÿå…¶å®å¾ˆç®€å•ï¼Œå°±æ˜¯ä½¿ç”¨ `pipeline`æ¥å®ç°ã€‚

```python
#  3ã€æ¬ é‡‡æ ·å’Œè¿‡é‡‡æ ·çš„ç»“åˆï¼ˆä½¿ç”¨pipelineï¼‰
# å¯¼å…¥ç›¸å…³çš„æ–¹æ³•
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline

# åˆ’åˆ†å› å˜é‡å’Œè‡ªå˜é‡
X = df.iloc[:,:-1]
y = df.iloc[:,-1]

#  å®šä¹‰ç®¡é“
model = SVC()
over = SMOTE(sampling_strategy=0.4)
under = RandomUnderSampler(sampling_strategy=0.5)
steps = [('o', over), ('u', under), ('model', model)]
pipeline = Pipeline(steps=steps)

# è¯„ä¼°æ•ˆæœ
scores = cross_val_score(pipeline, X, y, scoring='roc_auc', cv=5, n_jobs=-1)
score = mean(scores)
print('ROC AUC score for the combined sampling method: %.3f' % score)

# Outputï¼š
#ROC AUC score for the combined sampling method: 0.937
```



ğŸŒˆ4ã€å¦‚ä½•è·å–æœ€ä½³çš„é‡‡æ ·ç‡ï¼Ÿ

åœ¨ä¸Šé¢çš„æ —å­ä¸­ï¼Œæˆ‘ä»¬éƒ½æ˜¯é»˜è®¤ç»è¿‡é‡‡æ ·å˜æˆ50ï¼š50ï¼Œä½†æ˜¯è¿™æ ·å­çš„é‡‡æ ·æ¯”ä¾‹å¹¶éæœ€ä¼˜é€‰æ‹©ï¼Œå› æ­¤æˆ‘ä»¬å¼•å…¥ä¸€ä¸ªå« `æœ€ä½³é‡‡æ ·ç‡`çš„æ¦‚å¿µï¼Œç„¶åæˆ‘ä»¬é€šè¿‡è®¾ç½®é‡‡æ ·çš„æ¯”ä¾‹ï¼Œé‡‡æ ·ç½‘æ ¼æœç´¢çš„æ–¹æ³•å»æ‰¾åˆ°è¿™ä¸ªæœ€ä¼˜ç‚¹ã€‚

```python
# 4ã€å¦‚ä½•è·å–æœ€ä½³çš„é‡‡æ ·ç‡ï¼Ÿ
# å¯¼å…¥ç›¸å…³çš„æ–¹æ³•
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline

# åˆ’åˆ†å› å˜é‡å’Œè‡ªå˜é‡
X = df.iloc[:,:-1]
y = df.iloc[:,-1]

# values to evaluate
over_values = [0.3,0.4,0.5]
under_values = [0.7,0.6,0.5]
for o in over_values:
  for u in under_values:
    # define pipeline
    model = SVC()
    over = SMOTE(sampling_strategy=o)
    under = RandomUnderSampler(sampling_strategy=u)
    steps = [('over', over), ('under', under), ('model', model)]
    pipeline = Pipeline(steps=steps)
    # evaluate pipeline
    scores = cross_val_score(pipeline, X, y, scoring='roc_auc', cv=5, n_jobs=-1)
    score = mean(scores)
    print('SMOTE oversampling rate:%.1f, Random undersampling rate:%.1f , Mean ROC AUC: %.3f' % (o, u, score))
    

# Outputï¼š    
#SMOTE oversampling rate:0.3, Random undersampling rate:0.7 , Mean ROC AUC: 0.938
#SMOTE oversampling rate:0.3, Random undersampling rate:0.6 , Mean ROC AUC: 0.936
#SMOTE oversampling rate:0.3, Random undersampling rate:0.5 , Mean ROC AUC: 0.937
#SMOTE oversampling rate:0.4, Random undersampling rate:0.7 , Mean ROC AUC: 0.938
#SMOTE oversampling rate:0.4, Random undersampling rate:0.6 , Mean ROC AUC: 0.937
#SMOTE oversampling rate:0.4, Random undersampling rate:0.5 , Mean ROC AUC: 0.938
#SMOTE oversampling rate:0.5, Random undersampling rate:0.7 , Mean ROC AUC: 0.939
#SMOTE oversampling rate:0.5, Random undersampling rate:0.6 , Mean ROC AUC: 0.938
#SMOTE oversampling rate:0.5, Random undersampling rate:0.5 , Mean ROC AUC: 0.938
```

ä»ç»“æœæ—¥å¿—æ¥çœ‹ï¼Œæœ€ä¼˜çš„é‡‡æ ·ç‡å°±æ˜¯è¿‡é‡‡æ ·0.5ï¼Œæ¬ é‡‡æ ·0.7ã€‚



æœ€åï¼Œæƒ³å’Œå¤§å®¶è¯´çš„æ˜¯æ²¡æœ‰ç»å¯¹çš„å¥—è·¯ï¼Œåªæœ‰åˆé€‚çš„å¥—è·¯ï¼Œæ— è®ºæ˜¯æ¬ é‡‡æ ·è¿˜æ˜¯è¿‡é‡‡æ ·ï¼Œåªæœ‰åˆé€‚æ‰æœ€é‡è¦ã€‚è¿˜æœ‰ï¼Œæ¬ é‡‡æ ·çš„ç¡®ä¼šæ¯”è¿‡é‡‡æ ·â€œçœé’±â€å“ˆï¼ˆä»è®­ç»ƒæ—¶é—´ä¸Šå¾ˆç›´è§‚å¯ä»¥æ„Ÿå—åˆ°ï¼‰ã€‚



#### ğŸ“– References

[1] SMOTEç®—æ³• https://www.jianshu.com/p/13fc0f7f5565

[2] How to deal with imbalanced data in Python


![image](./arrests/åº•å›¾2.0.png)

æœ€æ–°çš„å‘å¸ƒå†…å®¹è¯·å…³æ³¨ä¸ªäººå¾®ä¿¡å…¬ä¼—å·å“ˆ~

