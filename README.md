# Tips-of-Feature-engineering

A feature engineering kit for each issue, to give you a deeper and deeper understanding of the work of feature engineering!

> æ¯ä¸€æœŸéƒ½ä¼šåˆ†äº«ä¸€äº›å¾ˆå®ç”¨çš„ç‰¹å¾å·¥ç¨‹æŠ€å·§ï¼Œç›®å‰è¿™é‡Œå­˜æ”¾äº†å†å²çš„æ‰€æœ‰æœŸæ•°ï¼Œæœ€æ–°çš„æœŸæ•°æ¬¢è¿å…³æ³¨å¾®ä¿¡å…¬ä¼—å·å“¦ï¼ˆSAMshareï¼‰ï¼

![image](./arrests/image.png)

éšç€æˆ‘ä»¬åœ¨æœºå™¨å­¦ä¹ ã€æ•°æ®å»ºæ¨¡ã€æ•°æ®æŒ–æ˜åˆ†æè¿™æ¡å‘å±•è·¯ä¸Šè¶Šèµ°è¶Šè¿œï¼Œå…¶å®è¶Šä¼šæ„Ÿè§‰åˆ°ç‰¹å¾å·¥ç¨‹çš„é‡è¦æ€§ï¼Œå¹³æ—¶æˆ‘ä»¬åœ¨å¾ˆå¤šåœ°æ–¹éƒ½ä¼šçœ‹åˆ°ä¸€äº›å¾ˆå¥½çš„ç‰¹å¾å·¥ç¨‹æŠ€å·§ï¼Œæœ¬é¡¹ç›®çš„ç›®çš„å°±æ˜¯æŠŠè¿™äº›å°æŠ€å·§æ‰“åŒ…æˆä¸€ä¸ªåˆä¸€ä¸ªçš„å°é”¦å›Šï¼Œä¾›å¤§å®¶å»é˜…è¯»ã€‚

é¦–å…ˆæ˜¯å½“å‰æ›´æ–°åˆ°çš„ç›®å½•ï¼Œæ–¹ä¾¿å¤§å®¶å»æŸ¥æ‰¾å†…å®¹ï¼


## ğŸš— æŒç»­æ›´æ–°

- [Tip1ï¼šç‰¹å¾æ— é‡çº²åŒ–çš„å¸¸è§æ“ä½œæ–¹æ³•](#Tip1ï¼šç‰¹å¾æ— é‡çº²åŒ–çš„å¸¸è§æ“ä½œæ–¹æ³•)
* [Tip2ï¼šæ€ä¹ˆè¿›è¡Œå¤šé¡¹å¼orå¯¹æ•°çš„æ•°æ®å˜æ¢](#Tip2ï¼šæ€ä¹ˆè¿›è¡Œå¤šé¡¹å¼orå¯¹æ•°çš„æ•°æ®å˜æ¢)
* [Tip3ï¼šå¸¸ç”¨çš„ç»Ÿè®¡å›¾åœ¨Pythoné‡Œæ€ä¹ˆç”»?](#Tip3ï¼šå¸¸ç”¨çš„ç»Ÿè®¡å›¾åœ¨Pythoné‡Œæ€ä¹ˆç”»?)
* [Tip4ï¼šæ€ä¹ˆå»é™¤DataFrameé‡Œçš„ç¼ºå¤±å€¼ï¼Ÿ](#Tip4ï¼šæ€ä¹ˆå»é™¤DataFrameé‡Œçš„ç¼ºå¤±å€¼ï¼Ÿ)
* [Tip5ï¼šæ€ä¹ˆæŠŠè¢«é”™è¯¯å¡«å……çš„ç¼ºå¤±å€¼è¿˜åŸï¼Ÿ](#Tip5ï¼šæ€ä¹ˆæŠŠè¢«é”™è¯¯å¡«å……çš„ç¼ºå¤±å€¼è¿˜åŸï¼Ÿ)
* [Tip6ï¼šæ€ä¹ˆå®šä¹‰ä¸€ä¸ªæ–¹æ³•å»å¡«å……åˆ†ç±»å˜é‡çš„ç©ºå€¼ï¼Ÿ](#Tip6ï¼šæ€ä¹ˆå®šä¹‰ä¸€ä¸ªæ–¹æ³•å»å¡«å……åˆ†ç±»å˜é‡çš„ç©ºå€¼ï¼Ÿ)
* [Tip7ï¼šæ€ä¹ˆå®šä¹‰ä¸€ä¸ªæ–¹æ³•å»å¡«å……æ•°å€¼å˜é‡çš„ç©ºå€¼ï¼Ÿ](#Tip7ï¼šæ€ä¹ˆå®šä¹‰ä¸€ä¸ªæ–¹æ³•å»å¡«å……æ•°å€¼å˜é‡çš„ç©ºå€¼ï¼Ÿ)
* [Tip8ï¼šæ€ä¹ˆæŠŠå‡ ä¸ªå›¾è¡¨ä¸€èµ·åœ¨åŒä¸€å¼ å›¾ä¸Šæ˜¾ç¤ºï¼Ÿ](#Tip8ï¼šæ€ä¹ˆæŠŠå‡ ä¸ªå›¾è¡¨ä¸€èµ·åœ¨åŒä¸€å¼ å›¾ä¸Šæ˜¾ç¤ºï¼Ÿ)
* [Tip9ï¼šæ€ä¹ˆæŠŠç”»å‡ºå †ç§¯å›¾æ¥çœ‹å æ¯”å…³ç³»ï¼Ÿ](#Tip9ï¼šæ€ä¹ˆæŠŠç”»å‡ºå †ç§¯å›¾æ¥çœ‹å æ¯”å…³ç³»ï¼Ÿ)
* [Tip10ï¼šæ€ä¹ˆå¯¹æ»¡è¶³æŸç§æ¡ä»¶çš„å˜é‡ä¿®æ”¹å…¶å˜é‡å€¼ï¼Ÿ](#Tip10ï¼šæ€ä¹ˆå¯¹æ»¡è¶³æŸç§æ¡ä»¶çš„å˜é‡ä¿®æ”¹å…¶å˜é‡å€¼ï¼Ÿ)
* [Tip11ï¼šæ€ä¹ˆé€šè¿‡æ­£åˆ™æå–å­—ç¬¦ä¸²é‡Œçš„æŒ‡å®šå†…å®¹?](#Tip11ï¼šæ€ä¹ˆé€šè¿‡æ­£åˆ™æå–å­—ç¬¦ä¸²é‡Œçš„æŒ‡å®šå†…å®¹?)
* [Tip12ï¼šå¦‚ä½•åˆ©ç”¨å­—å…¸æ‰¹é‡ä¿®æ”¹å˜é‡å€¼ï¼Ÿ](#Tip12ï¼šå¦‚ä½•åˆ©ç”¨å­—å…¸æ‰¹é‡ä¿®æ”¹å˜é‡å€¼ï¼Ÿ)
* [Tip13ï¼šå¦‚ä½•å¯¹ç±»åˆ«å˜é‡è¿›è¡Œç‹¬çƒ­ç¼–ç ï¼Ÿ](#Tip13ï¼šå¦‚ä½•å¯¹ç±»åˆ«å˜é‡è¿›è¡Œç‹¬çƒ­ç¼–ç ï¼Ÿ)
* [Tip14ï¼šå¦‚ä½•æŠŠâ€œå¹´é¾„â€å­—æ®µæŒ‰ç…§æˆ‘ä»¬çš„é˜ˆå€¼åˆ†æ®µï¼Ÿ](#Tip14ï¼šå¦‚ä½•æŠŠ"å¹´é¾„"å­—æ®µæŒ‰ç…§æˆ‘ä»¬çš„é˜ˆå€¼åˆ†æ®µï¼Ÿ)
* [Tip15ï¼šå¦‚ä½•ä½¿ç”¨sklearnçš„å¤šé¡¹å¼æ¥è¡ç”Ÿæ›´å¤šçš„å˜é‡ï¼Ÿ](#Tip15ï¼šå¦‚ä½•ä½¿ç”¨sklearnçš„å¤šé¡¹å¼æ¥è¡ç”Ÿæ›´å¤šçš„å˜é‡ï¼Ÿ)
* [Tip16ï¼šå¦‚ä½•æ ¹æ®å˜é‡ç›¸å…³æ€§ç”»å‡ºçƒ­åŠ›å›¾ï¼Ÿ](#Tip16ï¼šå¦‚ä½•æ ¹æ®å˜é‡ç›¸å…³æ€§ç”»å‡ºçƒ­åŠ›å›¾ï¼Ÿ)
* [Tip17ï¼šå¦‚ä½•æŠŠåˆ†å¸ƒä¿®æ­£ä¸ºç±»æ­£æ€åˆ†å¸ƒï¼Ÿ](#Tip17ï¼šå¦‚ä½•æŠŠåˆ†å¸ƒä¿®æ­£ä¸ºç±»æ­£æ€åˆ†å¸ƒï¼Ÿ)
* [Tip18ï¼šæ€ä¹ˆæ‰¾å‡ºæ•°æ®é›†ä¸­æœ‰æ•°æ®å€¾æ–œçš„ç‰¹å¾ï¼Ÿ](#tip18ï¼šæ€ä¹ˆæ‰¾å‡ºæ•°æ®é›†ä¸­æœ‰æ•°æ®å€¾æ–œçš„ç‰¹å¾ï¼Ÿ)
- [Tip19ï¼šæ€ä¹ˆå°½å¯èƒ½åœ°ä¿®æ­£æ•°æ®å€¾æ–œçš„ç‰¹å¾ï¼Ÿ](#tip19ï¼šæ€ä¹ˆå°½å¯èƒ½åœ°ä¿®æ­£æ•°æ®å€¾æ–œçš„ç‰¹å¾ï¼Ÿ)





## Tip1ï¼šç‰¹å¾æ— é‡çº²åŒ–çš„å¸¸è§æ“ä½œæ–¹æ³•

ç¬¬ä¸€æ‹›ï¼Œä»ç®€å•çš„ç‰¹å¾é‡çº²å¤„ç†å¼€å§‹ï¼Œè¿™é‡Œä»‹ç»äº†3ç§æ— é‡çº²åŒ–æ“ä½œçš„æ–¹æ³•ï¼ŒåŒæ—¶ä¹Ÿé™„ä¸Šç›¸å…³çš„åŒ…ä»¥åŠè°ƒç”¨æ–¹æ³•ï¼Œæ¬¢è¿è¡¥å……ï¼

> æ— é‡çº²åŒ–ï¼šå³nondimensionalize æˆ–è€…dimensionlessï¼Œæ˜¯æŒ‡é€šè¿‡ä¸€ä¸ªåˆé€‚çš„å˜é‡æ›¿ä»£ï¼Œå°†ä¸€ä¸ªæ¶‰åŠç‰©ç†é‡çš„æ–¹ç¨‹çš„éƒ¨åˆ†æˆ–å…¨éƒ¨çš„å•ä½ç§»é™¤ï¼Œä»¥æ±‚ç®€åŒ–å®éªŒæˆ–è€…è®¡ç®—çš„ç›®çš„ã€‚â€”â€”ç™¾åº¦ç™¾ç§‘



è¿›è¡Œè¿›ä¸€æ­¥è§£é‡Šï¼Œæ¯”å¦‚æœ‰ä¸¤ä¸ªå­—æ®µï¼Œä¸€ä¸ªæ˜¯è½¦è¡Œèµ°çš„å…¬é‡Œæ•°ï¼Œå¦ä¸€ä¸ªæ˜¯äººè·‘æ­¥çš„è·ç¦»ï¼Œä»–ä»¬ä¹‹é—´çš„å•ä½å…¶å®å·®å¼‚è¿˜æ˜¯æŒºå¤§çš„ï¼Œå…¶å®ä¸¤è€…ä¹‹é—´æ— æ³•è¿›è¡Œæ¯”è¾ƒçš„ï¼Œä½†æ˜¯æˆ‘ä»¬å¯ä»¥è¿›è¡Œå»é‡çº²ï¼ŒæŠŠä»–ä»¬çš„å˜é‡å€¼è¿›è¡Œç¼©æ”¾ï¼Œéƒ½ç»Ÿä¸€åˆ°æŸä¸€ä¸ªåŒºé—´å†…ï¼Œæ¯”å¦‚0-1ï¼Œä¾¿äºä¸åŒå•ä½æˆ–è€…é‡çº§ä¹‹é—´çš„æŒ‡æ ‡å¯ä»¥è¿›è¡Œæ¯”è¾ƒoråŠ æƒï¼

ä¸‹é¢çš„æ˜¯sklearné‡Œçš„ä¸€äº›æ— é‡çº²åŒ–çš„å¸¸è§æ“ä½œæ–¹æ³•ã€‚

```python
from sklearn.datasets import load_iris  
#å¯¼å…¥IRISæ•°æ®é›†  
iris = load_iris()

#æ ‡å‡†åŒ–ï¼Œè¿”å›å€¼ä¸ºæ ‡å‡†åŒ–åçš„æ•°æ®  
from sklearn.preprocessing import StandardScaler  
StandardScaler().fit_transform(iris.data)  

#åŒºé—´ç¼©æ”¾ï¼Œè¿”å›å€¼ä¸ºç¼©æ”¾åˆ°[0, 1]åŒºé—´çš„æ•°æ®  
from sklearn.preprocessing import MinMaxScaler  
MinMaxScaler().fit_transform(iris.data)  

#å½’ä¸€åŒ–ï¼Œè¿”å›å€¼ä¸ºå½’ä¸€åŒ–åçš„æ•°æ®
from sklearn.preprocessing import Normalizer  
Normalizer().fit_transform(iris.data)
```





## Tip2ï¼šæ€ä¹ˆè¿›è¡Œå¤šé¡¹å¼orå¯¹æ•°çš„æ•°æ®å˜æ¢?

æ•°æ®å˜æ¢ï¼Œè¿™ä¸ªæ“ä½œåœ¨ç‰¹å¾å·¥ç¨‹ä¸­ç”¨å¾—è¿˜æ˜¯è›®å¤šçš„ï¼Œä¸€ä¸ªç‰¹å¾åœ¨å½“å‰çš„åˆ†å¸ƒä¸‹æ— æ³•æœ‰æ˜æ˜¾çš„åŒºåˆ†åº¦ï¼Œä½†ä¸€ä¸ªå°å°çš„å˜æ¢åˆ™å¯ä»¥å¸¦æ¥æ„æƒ³ä¸åˆ°çš„æ•ˆæœï¼Œè€Œè¿™ä¸ªå°å°çš„å˜æ¢ï¼Œä¹Ÿå°±æ˜¯ä»Šå¤©ç»™å¤§å®¶åˆ†äº«çš„å°é”¦å›Šã€‚

#### å¤šé¡¹å¼å˜æ¢

æŒ‰ç…§æŒ‡å®šçš„degreeï¼Œè¿›è¡Œå¤šé¡¹å¼æ“ä½œä»è€Œè¡ç”Ÿå‡ºæ–°å˜é‡(å½“ç„¶è¿™æ˜¯é’ˆå¯¹æ¯ä¸€åˆ—ç‰¹å¾å†…çš„æ“ä½œ)ã€‚

ä¸¾ä¸ªæ —å­ï¼š

```python
from sklearn.datasets import load_iris  
#å¯¼å…¥IRISæ•°æ®é›†  
iris = load_iris()
iris.data[0]

# Output: array([ 5.1,  3.5,  1.4,  0.2])
```

```python
tt = PolynomialFeatures().fit_transform(iris.data)  
tt[0]

# Output: array([  1.  ,   5.1 ,   3.5 ,   1.4 ,   0.2 ,  26.01,  17.85,   7.14, 1.02,  12.25,   4.9 ,   0.7 ,   1.96,   0.28,   0.04])
```

å› ä¸ºPolynomialFeatures()æ–¹æ³•é»˜è®¤degreeæ˜¯2ï¼Œæ‰€ä»¥åªä¼šè¿›è¡ŒäºŒé¡¹å¼çš„è¡ç”Ÿã€‚

ä¸€èˆ¬æ¥è¯´ï¼Œå¤šé¡¹å¼å˜æ¢éƒ½æ˜¯æŒ‰ç…§ä¸‹é¢çš„æ–¹å¼æ¥çš„ï¼š

f = kx + b   ä¸€æ¬¡å‡½æ•°ï¼ˆdegreeä¸º1ï¼‰

f = ax^2 + b*x + w  äºŒæ¬¡å‡½æ•°ï¼ˆdegreeä¸º2ï¼‰

f = a*x^3 + b*x^2 + c*x + w  ä¸‰æ¬¡å‡½æ•°ï¼ˆdegreeä¸º3ï¼‰



è¿™ç±»çš„è½¬æ¢å¯ä»¥é€‚å½“åœ°æå‡æ¨¡å‹çš„æ‹Ÿåˆèƒ½åŠ›ï¼Œå¯¹äºåœ¨çº¿æ€§å›å½’æ¨¡å‹ä¸Šçš„åº”ç”¨è¾ƒä¸ºå¹¿æ³›ã€‚



#### å¯¹æ•°å˜æ¢

è¿™ä¸ªæ“ä½œå°±æ˜¯ç›´æ¥è¿›è¡Œä¸€ä¸ªå¯¹æ•°è½¬æ¢ï¼Œæ”¹å˜åŸå…ˆçš„æ•°æ®åˆ†å¸ƒï¼Œè€Œå¯ä»¥è¾¾åˆ°çš„ä½œç”¨ä¸»è¦æœ‰:

1ï¼‰å–å®Œå¯¹æ•°ä¹‹åå¯ä»¥ç¼©å°æ•°æ®çš„ç»å¯¹æ•°å€¼ï¼Œæ–¹ä¾¿è®¡ç®—ï¼›

2ï¼‰å–å®Œå¯¹æ•°ä¹‹åå¯ä»¥æŠŠä¹˜æ³•è®¡ç®—è½¬æ¢ä¸ºåŠ æ³•è®¡ç®—ï¼›

3ï¼‰è¿˜æœ‰å°±æ˜¯åˆ†å¸ƒæ”¹å˜å¸¦æ¥çš„æ„æƒ³ä¸åˆ°çš„æ•ˆæœã€‚



numpyåº“é‡Œå°±æœ‰å¥½å‡ ç±»å¯¹æ•°è½¬æ¢çš„æ–¹æ³•ï¼Œå¯ä»¥é€šè¿‡from numpy import xxx è¿›è¡Œå¯¼å…¥ä½¿ç”¨ã€‚

logï¼šè®¡ç®—è‡ªç„¶å¯¹æ•°

log10ï¼šåº•ä¸º10çš„log

log2ï¼šåº•ä¸º2çš„log

log1pï¼šåº•ä¸ºeçš„log



#### ä»£ç é›†åˆ

```python
from sklearn.datasets import load_iris  
#å¯¼å…¥IRISæ•°æ®é›†  
iris = load_iris()

#å¤šé¡¹å¼è½¬æ¢  
#å‚æ•°degreeä¸ºåº¦ï¼Œé»˜è®¤å€¼ä¸º2 
from sklearn.preprocessing import PolynomialFeatures  
PolynomialFeatures().fit_transform(iris.data)  

#å¯¹æ•°å˜æ¢
from numpy import log1p  
from sklearn.preprocessing import FunctionTransformer  
#è‡ªå®šä¹‰è½¬æ¢å‡½æ•°ä¸ºå¯¹æ•°å‡½æ•°çš„æ•°æ®å˜æ¢  
#ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯å•å˜å…ƒå‡½æ•°  
FunctionTransformer(log1p).fit_transform(iris.data)  
```




## Tip3ï¼šå¸¸ç”¨çš„ç»Ÿè®¡å›¾åœ¨Pythoné‡Œæ€ä¹ˆç”»?

è¿™é‡Œçš„è¯æˆ‘ä»¬ä»‹ç»å‡ ç§å¾ˆç®€å•ä½†ä¹Ÿå¾ˆå®ç”¨çš„ç»Ÿè®¡å›¾ç»˜åˆ¶æ–¹æ³•ï¼Œåˆ†åˆ«æœ‰æ¡å½¢å›¾ã€é¥¼å›¾ã€ç®±ä½“å›¾ã€ç›´æ–¹å›¾ä»¥åŠæ•£ç‚¹å›¾ï¼Œå…³äºè¿™å‡ ç§å›¾å½¢çš„å«ä¹‰è¿™è¾¹å°±ä¸å¤šåšè§£é‡Šäº†ã€‚

ä»Šå¤©ç”¨åˆ°ä¸¤ä¸ªæ•°æ®é›†ï¼Œæ•°æ®é›†å¤§å®¶å¯ä»¥åœ¨å…¬ä¼—å·å›å¤"ç‰¹å¾å·¥ç¨‹"æ¥è·å–ï¼Œåˆ†åˆ«æ˜¯**Salary_Ranges_by_Job_Classificationå’ŒGlobalLandTemperaturesByCity**ã€‚

#### æ•ˆæœå›¾ï¼š

![image-20191227230928468](./arrests/1.png)

![image-20191227230949512](./arrests/2.png)

![image-20191227231000989](./arrests/3.png)

![image-20191227231016574](./arrests/4.png)

![image-20191227231027274](./arrests/5.png)



#### ä»£ç é›†åˆ

```python
# å¯¼å…¥ä¸€äº›å¸¸ç”¨åŒ…
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

%matplotlib inline
plt.style.use('fivethirtyeight')

#è§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜ï¼ŒMac
%matplotlib inline
from matplotlib.font_manager import FontProperties


# å¼•å…¥ç¬¬ 1 ä¸ªæ•°æ®é›† Salary_Ranges_by_Job_Classification
salary_ranges = pd.read_csv('./data/Salary_Ranges_by_Job_Classification.csv')

# å¼•å…¥ç¬¬ 2 ä¸ªæ•°æ®é›† GlobalLandTemperaturesByCity
climate = pd.read_csv('./data/GlobalLandTemperaturesByCity.csv')
# ç§»é™¤ç¼ºå¤±å€¼
climate.dropna(axis=0, inplace=True)
# åªçœ‹ä¸­å›½
# æ—¥æœŸè½¬æ¢, å°†dt è½¬æ¢ä¸ºæ—¥æœŸï¼Œå–å¹´ä»½, æ³¨æ„mapçš„ç”¨æ³•
climate['dt'] = pd.to_datetime(climate['dt'])
climate['year'] = climate['dt'].map(lambda value: value.year)
climate_sub_china = climate.loc[climate['Country'] == 'China']
climate_sub_china['Century'] = climate_sub_china['year'].map(lambda x:int(x/100 +1))

# è®¾ç½®æ˜¾ç¤ºçš„å°ºå¯¸
plt.rcParams['figure.figsize'] = (4.0, 4.0) # è®¾ç½®figure_sizeå°ºå¯¸
plt.rcParams['image.interpolation'] = 'nearest' # è®¾ç½® interpolation style
plt.rcParams['image.cmap'] = 'gray' # è®¾ç½® é¢œè‰² style
plt.rcParams['savefig.dpi'] = 100 #å›¾ç‰‡åƒç´ 
plt.rcParams['figure.dpi'] = 100 #åˆ†è¾¨ç‡
plt.rcParams['font.family'] = ['Arial Unicode MS'] #æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡

# ç»˜åˆ¶æ¡å½¢å›¾
salary_ranges['Grade'].value_counts().sort_values(ascending=False).head(10).plot(kind='bar')
# ç»˜åˆ¶é¥¼å›¾
salary_ranges['Grade'].value_counts().sort_values(ascending=False).head(5).plot(kind='pie')
# ç»˜åˆ¶ç®±ä½“å›¾
salary_ranges['Union Code'].value_counts().sort_values(ascending=False).head(5).plot(kind='box')
# ç»˜åˆ¶ç›´æ–¹å›¾
climate['AverageTemperature'].hist()
# ç»˜åˆ¶æ•£ç‚¹å›¾
x = climate_sub_china['year']
y = climate_sub_china['AverageTemperature']
fig, ax = plt.subplots(figsize=(10,5))
ax.scatter(x, y)
plt.show()
```



## Tip4ï¼šæ€ä¹ˆå»é™¤DataFrameé‡Œçš„ç¼ºå¤±å€¼ï¼Ÿ

è¿™ä¸ªæˆ‘ä»¬ç»å¸¸ä¼šç”¨ï¼Œå½“æˆ‘ä»¬å‘ç°æŸä¸ªå˜é‡çš„ç¼ºå¤±ç‡å¤ªé«˜çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¼šç›´æ¥å¯¹å…¶è¿›è¡Œåˆ é™¤æ“ä½œï¼Œåˆæˆ–è€…è¯´æŸä¸€è¡Œæˆ‘ä¸æƒ³è¦äº†ï¼Œæƒ³å•ç‹¬åˆ é™¤è¿™ä¸€è¡Œæ•°æ®ï¼Œè¿™ä¸ªæˆ‘ä»¬è¯¥æ€ä¹ˆå¤„ç†å‘¢ï¼Ÿè¿™é‡Œä»‹ç»ä¸€ä¸ªæ–¹æ³•ï¼ŒDataFrame.dropna()ï¼Œå…·ä½“å¯ä»¥çœ‹ä¸‹å›¾ï¼š

![image-20191228074829720](./arrests/6.png)

ä»æ–¹æ³•ä»‹ç»å¯ä»¥çœ‹å‡ºï¼Œæˆ‘ä»¬å¯ä»¥æŒ‡å®š `axis` çš„å€¼ï¼Œå¦‚æœæ˜¯0ï¼Œé‚£å°±æ˜¯æŒ‰ç…§è¡Œå»è¿›è¡Œç©ºå€¼åˆ é™¤ï¼Œå¦‚æœæ˜¯1åˆ™æ˜¯æŒ‰ç…§åˆ—å»è¿›è¡Œæ“ä½œï¼Œé»˜è®¤æ˜¯0ã€‚

åŒæ—¶ï¼Œè¿˜æœ‰ä¸€ä¸ªå‚æ•°æ˜¯`how` ,å°±æ˜¯é€‰æ‹©åˆ é™¤çš„æ¡ä»¶ï¼Œå¦‚æœæ˜¯ `any`åˆ™æ˜¯å¦‚æœå­˜åœ¨ä¸€ä¸ªç©ºå€¼ï¼Œåˆ™è¿™è¡Œ(åˆ—)çš„æ•°æ®éƒ½ä¼šè¢«åˆ é™¤ï¼Œå¦‚æœæ˜¯ `all`çš„è¯ï¼Œåªæœ‰å½“è¿™è¡Œ(åˆ—)å…¨éƒ¨çš„å˜é‡å€¼ä¸ºç©ºæ‰ä¼šè¢«åˆ é™¤ï¼Œé»˜è®¤çš„è¯éƒ½æ˜¯`any` ã€‚

å¥½äº†ï¼Œä¸¾å‡ ä¸ªæ —å­ï¼Œæˆ‘ä»¬è¿˜æ˜¯ç”¨climateæ•°æ®é›†ï¼š

```python
# å¼•å…¥æ•°æ®é›†
import pandas as pd
climate = pd.read_csv('./data/GlobalLandTemperaturesByCity.csv')
# ä¿ç•™ä¸€éƒ¨åˆ†åˆ—
data = climate.loc[:,['dt','AverageTemperature','AverageTemperatureUncertainty','City']]
data.head()
```

#### ç»Ÿè®¡æœ‰å¤šå°‘ç¼ºå¤±å€¼

```python
# æŸ¥çœ‹æœ‰å¤šå°‘ç¼ºå¤±å€¼
print(data.isnull().sum())
print('\n')
# æŸ¥çœ‹ç¼ºå¤±å€¼å æ¯”
print(data.isnull().sum()/len(data))
```

![image-20191228081417965](./arrests/7.png)

#### åˆ é™¤æ“ä½œ

```python
# åŸå§‹æ¨¡æ ·
print(data.head())
print('\n')

# é»˜è®¤å‚æ•°axis=0ï¼Œæ ¹æ®ç´¢å¼•(index)åˆ é™¤æŒ‡å®šçš„è¡Œï¼Œåˆ é™¤ç¬¬0è¡Œæ•°æ®
print(data.drop(0).head())
print('\n')

# axis=1,æ ¹æ®åˆ—å(columns)åˆ é™¤æŒ‡å®šçš„åˆ—ï¼Œåˆ é™¤'dt'åˆ—
print(data.drop('dt',axis=1).head())
print('\n')

# ç§»é™¤å«æœ‰ç¼ºå¤±å€¼çš„è¡Œï¼Œç›´æ¥ç»“æœä½œä¸ºæ–°df
data.dropna(axis=0, inplace=True)
```

![image-20191228081435160](./arrests/8.png)





## Tip5ï¼šæ€ä¹ˆæŠŠè¢«é”™è¯¯å¡«å……çš„ç¼ºå¤±å€¼è¿˜åŸï¼Ÿ

ä¸Šä¸ªå°é”¦å›Šè®²åˆ°æˆ‘ä»¬å¯ä»¥å¯¹ç¼ºå¤±å€¼è¿›è¡Œä¸¢å¼ƒå¤„ç†ï¼Œä½†æ˜¯è¿™ç§æ“ä½œå¾€å¾€ä¼šä¸¢å¤±äº†å¾ˆå¤šä¿¡æ¯çš„ï¼Œå¾ˆå¤šæ—¶å€™æˆ‘ä»¬éƒ½éœ€è¦å…ˆçœ‹çœ‹ç¼ºå¤±çš„åŸå› ï¼Œå¦‚æœæœ‰äº›ç¼ºå¤±æ˜¯æ­£å¸¸å­˜åœ¨çš„ï¼Œæˆ‘ä»¬å°±ä¸éœ€è¦è¿›è¡Œä¸¢å¼ƒï¼Œä¿ç•™ç€å¯¹æˆ‘ä»¬çš„æ¨¡å‹å…¶å®å¸®åŠ©ä¼šæ›´å¤§çš„ã€‚

æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€ç§æƒ…å†µå°±æ˜¯æˆ‘ä»¬ç›´æ¥è¿›è¡Œç»Ÿè®¡ï¼Œå®ƒæ˜¯æ²¡æœ‰ç¼ºå¤±çš„ï¼Œä½†æ˜¯å®é™…ä¸Šæ˜¯ç¼ºå¤±çš„ï¼Œä»€ä¹ˆæ„æ€ï¼Ÿå°±æ˜¯è¯´ç¼ºå¤±è¢«äººä¸ºï¼ˆç³»ç»Ÿï¼‰åœ°è¿›è¡Œäº†å¡«å……ï¼Œæ¯”å¦‚æˆ‘ä»¬å¸¸è§çš„ç”¨0ã€-9ã€-999ã€blankç­‰æ¥è¿›è¡Œå¡«å……ç¼ºå¤±ï¼Œè‹¥çœŸé‡è§è¿™ç§æƒ…å†µï¼Œæˆ‘ä»¬å¯ä»¥è¿™ä¹ˆå¤„ç†å‘¢ï¼Ÿ

å¾ˆç®€å•ï¼Œé‚£å°±æ˜¯**è¿˜åŸç¼ºå¤±ï¼**

#### å•ä¸ªæ“ä½œ

```python
# å¼•å…¥æ•°æ®é›†(çš®é©¬å°ç¬¬å®‰äººç³–å°¿ç—…é¢„æµ‹æ•°æ®é›†)
pima_columns = ['times_pregment','plasma_glucose_concentration','diastolic_blood_pressure','triceps_thickness',
                'serum_insulin','bmi','pedigree_function','age','onset_disbetes']

pima = pd.read_csv('./data/pima.data', names=pima_columns)


# å¤„ç†è¢«é”™è¯¯å¡«å……çš„ç¼ºå¤±å€¼0ï¼Œè¿˜åŸä¸º ç©º(å•ç‹¬å¤„ç†)
pima['serum_insulin'] = pima['serum_insulin'].map(lambda x:x if x !=0 else None)
# æ£€æŸ¥å˜é‡ç¼ºå¤±æƒ…å†µ
pima['serum_insulin'].isnull().sum()

# Outputï¼š374
```



#### æ‰¹é‡æ“ä½œ

```python
# æ‰¹é‡æ“ä½œ è¿˜åŸç¼ºå¤±å€¼
columns = ['serum_insulin','bmi','plasma_glucose_concentration','diastolic_blood_pressure','triceps_thickness']

for col in columns:
    pima[col].replace([0], [None], inplace=True)

# æ£€æŸ¥å˜é‡ç¼ºå¤±æƒ…å†µ
pima.isnull().sum()
```

![image-20191228083228056](./arrests/9.png)





## Tip6ï¼šæ€ä¹ˆå®šä¹‰ä¸€ä¸ªæ–¹æ³•å»å¡«å……åˆ†ç±»å˜é‡çš„ç©ºå€¼ï¼Ÿ

ä¹‹å‰æˆ‘ä»¬è¯´è¿‡å¦‚ä½•åˆ é™¤æ‰ç¼ºå¤±çš„è¡Œï¼Œä½†æ˜¯å¦‚ä½•æˆ‘ä»¬éœ€è¦çš„æ˜¯å¡«å……å‘¢ï¼Ÿæ¯”å¦‚è¯´ç”¨ä¼—æ•°æ¥å¡«å……ç¼ºå¤±ï¼Œæˆ–è€…ç”¨æŸä¸ªç‰¹å®šå€¼æ¥å¡«å……ç¼ºå¤±å€¼ï¼Ÿè¿™ä¸ªä¹Ÿæ˜¯æˆ‘ä»¬éœ€è¦æŒæ¡çš„ç‰¹å¾å·¥ç¨‹çš„æ–¹æ³•ä¹‹ä¸€ï¼Œå¯¹äºç”¨ç‰¹å®šå€¼å¡«å……ç¼ºå¤±ï¼Œå…¶å®æ¯”è¾ƒç®€å•äº†ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥ç”¨`fillna()` æ–¹æ³•å°±å¯ä»¥ï¼Œä¸‹é¢æˆ‘æ¥è®²ä¸€ä¸ªé€šç”¨çš„åŠæ³•ï¼Œé™¤äº†ç”¨ç‰¹å®šå€¼å¡«å……ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥è‡ªå®šä¹‰ï¼Œæ¯”å¦‚è¯´ç”¨â€ä¼—æ•°â€œæ¥å¡«å……ç­‰ç­‰ã€‚

è¿™é‡Œæˆ‘ä»¬ç”¨åˆ°äº†`TransformerMixin`æ–¹æ³•ï¼Œç„¶åè‡ªå®šä¹‰ä¸€ä¸ªå¡«å……å™¨æ¥è¿›è¡Œç¼ºå¤±å€¼çš„å¡«å……ã€‚

è¿™é‡Œæˆ‘ä»¬é€ ä¸€ä¸ªæ•°æ®é›†æ¥æµ‹è¯•æˆ‘ä»¬çš„ä»£ç ï¼š

```python
# æœ¬æ¬¡æ¡ˆä¾‹ä½¿ç”¨çš„æ•°æ®é›†
import pandas as pd
X = pd.DataFrame({'city':['tokyo',None,'london','seattle','san fancisco','tokyo'],
                  'boolean':['y','n',None,'n','n','y'],
                  'ordinal_column':['somewhat like','like','somewhat like','like','somewhat like','dislike'],
                  'quantitative_column':[1,11,-.5,10,None,20]})
X
```

![image-20191231230535024](./arrests/10.png)



å¯ä»¥çœ‹å‡ºï¼Œè¿™ä¸ªæ•°æ®é›†æœ‰ä¸‰ä¸ªåˆ†ç±»å˜é‡ï¼Œåˆ†åˆ«æ˜¯booleanã€cityå’Œordinal_columnï¼Œè€Œè¿™é‡Œé¢æœ‰ä¸¤ä¸ªå­—æ®µå­˜åœ¨ç©ºå€¼ã€‚



```python
# å¡«å……åˆ†ç±»å˜é‡ï¼ˆåŸºäºTransformerMixinçš„è‡ªå®šä¹‰å¡«å……å™¨ï¼Œç”¨ä¼—æ•°å¡«å……ï¼‰
from sklearn.base import TransformerMixin
class CustomCategoryzImputer(TransformerMixin):
    def __init__(self, cols=None):
        self.cols = cols
        
    def transform(self, df):
        X = df.copy()
        for col in self.cols:
            X[col].fillna(X[col].value_counts().index[0], inplace=True)
        return X
    
    def fit(self, *_):
        return self   
    
# è°ƒç”¨è‡ªå®šä¹‰çš„å¡«å……å™¨
cci = CustomCategoryzImputer(cols=['city','boolean'])
cci.fit_transform(X)
```

![image-20191231230946764](./arrests/11.png)




## Tip7ï¼šæ€ä¹ˆå®šä¹‰ä¸€ä¸ªæ–¹æ³•å»å¡«å……æ•°å€¼å˜é‡çš„ç©ºå€¼ï¼Ÿ

è¿™ä¸ªé”¦å›Šå’Œä¸Šä¸€ä¸ªå·®ä¸å¤šäº†ï¼Œä¸è¿‡è¿™ä¸ªæ¢ä¸€ä¸ªæ–¹æ³• `Imputer` ã€‚

åŒæ ·çš„ï¼Œæˆ‘ä»¬è¿˜æ˜¯é€ ä¸€ä¸ªæ•°æ®é›†ï¼š

```python
# æœ¬æ¬¡æ¡ˆä¾‹ä½¿ç”¨çš„æ•°æ®é›†
import pandas as pd
X = pd.DataFrame({'city':['tokyo',None,'london','seattle','san fancisco','tokyo'],
                  'boolean':['y','n',None,'n','n','y'],
                  'ordinal_column':['somewhat like','like','somewhat like','like','somewhat like','dislike'],
                  'quantitative_column':[1,11,-.5,10,None,20]})
X
```

![image-20191231230535024](./arrests/10.png)



å¯ä»¥çœ‹å‡ºï¼Œè¿™ä¸ªæ•°æ®é›†æœ‰ä¸€ä¸ªæ•°å€¼å˜é‡`quantitative_columns`ï¼Œå­˜åœ¨ä¸€è¡Œç¼ºå¤±å€¼ï¼Œæˆ‘ä»¬ç›´æ¥è°ƒç”¨`sklearn`çš„`preprocessing`æ–¹æ³•é‡Œçš„`Imputer`ã€‚

```python
# å¡«å……æ•°å€¼å˜é‡ï¼ˆåŸºäºImputerçš„è‡ªå®šä¹‰å¡«å……å™¨ï¼Œç”¨ä¼—æ•°å¡«å……ï¼‰
from sklearn.preprocessing import Imputer
class CustomQuantitativeImputer(TransformerMixin):
    def __init__(self, cols=None, strategy='mean'):
        self.cols = cols
        self.strategy = strategy
        
    def transform(self, df):
        X = df.copy()
        impute = Imputer(strategy=self.strategy)
        for col in self.cols:
            X[col] = impute.fit_transform(X[[col]])
        return X
    
    def fit(self, *_):
        return self
    
# è°ƒç”¨è‡ªå®šä¹‰çš„å¡«å……å™¨
cqi = CustomQuantitativeImputer(cols = ['quantitative_column'], strategy='mean')
cqi.fit_transform(X)
```

![image-20191231231355341](./arrests/12.png)




## Tip8ï¼šæ€ä¹ˆæŠŠå‡ ä¸ªå›¾è¡¨ä¸€èµ·åœ¨åŒä¸€å¼ å›¾ä¸Šæ˜¾ç¤ºï¼Ÿ

æœªæ¥å‡ ä¸ªç‰¹å¾é”¦å›Šçš„å†…å®¹ä¼šä½¿ç”¨æ³°å¦å°¼å…‹å·çš„æ•°æ®é›†ï¼Œå¤§å®¶å¯ä»¥åœ¨ä¸‹é¢çš„é“¾æ¥å»ä¸‹è½½æ•°æ®å“ˆã€‚

Titanicæ•°æ®é›†ä¸‹è½½ï¼šhttps://www.kaggle.com/c/titanic/data



é¦–å…ˆæˆ‘ä»¬è¦çŸ¥é“ï¼Œåšç‰¹å¾å·¥ç¨‹ä¹‹å‰çŸ¥é“æ•°æ®çš„åˆ†å¸ƒå’Œå…³è”æƒ…å†µæ˜¯æä¸ºé‡è¦çš„ï¼Œå› æ­¤æŠŠè¿™äº›ä¿¡æ¯åšä¸€äº›å¯è§†åŒ–çš„æ“ä½œæ˜¯å¾ˆé‡è¦çš„æ“ä½œå’ŒæŠ€èƒ½ï¼Œä»Šå¤©æˆ‘ä»¬å°±æ¥å­¦ä¹ ä¸‹æ€ä¹ˆç”»å¾ˆå¤šå¼ å›¾ï¼Œç„¶åå¯ä»¥ä¸€å¹¶æ˜¾ç¤ºåœ¨åŒä¸€å¼ ä¸Šå§ï¼Œä¸“ä¸šæ¥è¯´å°±æ˜¯ç”»å­å›¾ã€‚

#### å¯¼å…¥æ•°æ®é›†

```python
# å¯¼å…¥ç›¸å…³åº“
import pandas as pd 
import numpy as np 
from pandas import Series,DataFrame

# å¯¼å…¥æ³°å¦å°¼çš„æ•°æ®é›†
data_train = pd.read_csv("./data/titanic/Train.csv")
data_train.head()
```

![image-20200104150617226](./arrests/13.png)



#### ä»£ç æ±‡é›†

```python
import matplotlib.pyplot as plt

# è®¾ç½®figure_sizeå°ºå¯¸
plt.rcParams['figure.figsize'] = (8.0, 6.0) 

fig = plt.figure()

# è®¾å®šå›¾è¡¨é¢œè‰²
fig.set(alpha=0.2)  

# ç¬¬ä¸€å¼ å°å›¾
plt.subplot2grid((2,3),(0,0))           
data_train['Survived'].value_counts().plot(kind='bar')
plt.ylabel(u"äººæ•°")  
plt.title(u"èˆ¹å‘˜è·æ•‘æƒ…å†µ (1ä¸ºè·æ•‘)")

# ç¬¬äºŒå¼ å°å›¾
plt.subplot2grid((2,3),(0,1))
data_train['Pclass'].value_counts().plot(kind="bar")
plt.ylabel(u"äººæ•°")
plt.title(u"ä¹˜å®¢ç­‰çº§åˆ†å¸ƒ")

# ç¬¬ä¸‰å¼ å°å›¾
plt.subplot2grid((2,3),(0,2))
plt.scatter(data_train['Survived'], data_train['Age'])
plt.ylabel(u"å¹´é¾„") 
plt.grid(b=True, which='major', axis='y') 
plt.title(u"æŒ‰å¹´é¾„çœ‹è·æ•‘åˆ†å¸ƒ (1ä¸ºè·æ•‘)")

# ç¬¬å››å¼ å°å›¾ï¼Œåˆ†å¸ƒå›¾
plt.subplot2grid((2,3),(1,0), colspan=2)
data_train.Age[data_train.Pclass == 1].plot(kind='kde')   
data_train.Age[data_train.Pclass == 2].plot(kind='kde')
data_train.Age[data_train.Pclass == 3].plot(kind='kde')
plt.xlabel(u"å¹´é¾„")
plt.ylabel(u"å¯†åº¦") 
plt.title(u"å„ç­‰çº§çš„ä¹˜å®¢å¹´é¾„åˆ†å¸ƒ")
plt.legend((u'å¤´ç­‰èˆ±', u'2ç­‰èˆ±',u'3ç­‰èˆ±'),loc='best')

# ç¬¬äº”å¼ å°å›¾
plt.subplot2grid((2,3),(1,2))
data_train.Embarked.value_counts().plot(kind='bar')
plt.title(u"å„ç™»èˆ¹å£å²¸ä¸Šèˆ¹äººæ•°")
plt.ylabel(u"äººæ•°")  
plt.show()
```

![image-20200104150744024](./arrests/14.png)

æˆ‘ä»¬ä»ä¸Šé¢çš„å¯è§†åŒ–æ“ä½œç»“æœå¯ä»¥çœ‹å‡ºï¼Œå…¶å®å¯ä»¥çœ‹å‡ºä¸€äº›è§„å¾‹ï¼Œæ¯”å¦‚è¯´ç”Ÿè¿˜çš„å‡ ç‡æ¯”æ­»äº¡çš„è¦å¤§ï¼Œç„¶åè·æ•‘çš„äººåœ¨å¹´é¾„ä¸ŠåŒºåˆ«ä¸å¤§ï¼Œç„¶åå°±æ˜¯æœ‰é’±äººï¼ˆåå¤´ç­‰èˆ±çš„ï¼‰çš„å¹´é¾„ä¼šåå¤§ç­‰ã€‚





## Tip9ï¼šæ€ä¹ˆæŠŠç”»å‡ºå †ç§¯å›¾æ¥çœ‹å æ¯”å…³ç³»ï¼Ÿ

æœªæ¥å‡ ä¸ªç‰¹å¾é”¦å›Šçš„å†…å®¹ä¼šä½¿ç”¨æ³°å¦å°¼å…‹å·çš„æ•°æ®é›†ï¼Œå¤§å®¶å¯ä»¥åœ¨ä¸‹é¢çš„é“¾æ¥å»ä¸‹è½½æ•°æ®å“ˆã€‚

Titanicæ•°æ®é›†ä¸‹è½½ï¼šhttps://www.kaggle.com/c/titanic/data



ä¸Šæ¬¡çš„é”¦å›Šæˆ‘çŸ¥é“äº†æ€ä¹ˆæŠŠå‡ å¼ å›¾æ”¾åœ¨ä¸€å¼ å›¾ä¸Šå»æ˜¾ç¤ºï¼Œä½†æ˜¯è¿™ä¸ªåªæ˜¯ä¸€ç§æ’ç‰ˆæ–¹å¼çš„æ“ä½œï¼Œä»Šå¤©åˆ†äº«ä¸€ä¸ªç”»å †ç§¯å›¾çš„æ–¹æ³•ï¼Œå¯ä»¥ç”¨æ¥çœ‹ç±»åˆ«å æ¯”å…³ç³»ï¼Œæœ‰åŠ©äºæˆ‘ä»¬å»äº†è§£æ•°æ®ï¼Œå‘ç°æ•°æ®é‡Œçš„è§„å¾‹ã€‚

#### å¯¼å…¥æ•°æ®é›†

```python
# å¯¼å…¥ç›¸å…³åº“
import pandas as pd 
import numpy as np 
from pandas import Series,DataFrame

# å¯¼å…¥æ³°å¦å°¼çš„æ•°æ®é›†
data_train = pd.read_csv("./data/titanic/Train.csv")
data_train.head()
```

![image-20200104150617226](./arrests/13.png)



#### ä»£ç æ±‡é›†

```python
# è®¾ç½®figure_sizeå°ºå¯¸
plt.rcParams['figure.figsize'] = (5.0, 4.0) 

#çœ‹çœ‹å„ä¹˜å®¢ç­‰çº§çš„è·æ•‘æƒ…å†µ
fig = plt.figure()
fig.set(alpha=0.8)

Survived_0 = data_train.Pclass[data_train.Survived == 0].value_counts()
Survived_1 = data_train.Pclass[data_train.Survived == 1].value_counts()
df=pd.DataFrame({u'è·æ•‘':Survived_1, u'æœªè·æ•‘':Survived_0})
df.plot(kind='bar', stacked=True)
plt.title(u"å„ä¹˜å®¢ç­‰çº§çš„è·æ•‘æƒ…å†µ")
plt.xlabel(u"ä¹˜å®¢ç­‰çº§") 
plt.ylabel(u"äººæ•°") 
plt.show()
```

![image-20200105094525846](./arrests/15.png)





## Tip10ï¼šæ€ä¹ˆå¯¹æ»¡è¶³æŸç§æ¡ä»¶çš„å˜é‡ä¿®æ”¹å…¶å˜é‡å€¼ï¼Ÿ

æœªæ¥å‡ ä¸ªç‰¹å¾é”¦å›Šçš„å†…å®¹ä¼šä½¿ç”¨æ³°å¦å°¼å…‹å·çš„æ•°æ®é›†ï¼Œå¤§å®¶å¯ä»¥åœ¨ä¸‹é¢çš„é“¾æ¥å»ä¸‹è½½æ•°æ®å“ˆã€‚

Titanicæ•°æ®é›†ä¸‹è½½ï¼š

https://www.kaggle.com/c/titanic/data



è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨`loc`å‡½æ•°ï¼Œè¿™ä¸ªæ–¹å¼å®åœ¨æ˜¯å¤ªå¥½ç”¨äº†ï¼

é¦–å…ˆæˆ‘ä»¬å…ˆç†è§£ä¸€ä¸‹è¿™ä¸ª`loc`åº”è¯¥æ€ä¹ˆç”¨å§ï¼Œç„¶åå†ä¸¾å‡ ä¸ªå®æˆ˜ä¾‹å­æ¥ç†è§£ä¸€ä¸‹ã€‚

æˆ‘ä»¬è¦çŸ¥é“locå‡½æ•°çš„æ„æ€å°±æ˜¯é€šè¿‡è¡Œæ ‡ç­¾ç´¢å¼•è¡Œæ•°æ®ï¼Œæœ€ç›´æ¥çš„å°±æ˜¯çœ‹çœ‹æ–‡æ¡£ï¼Œå¼•ç”¨æ–‡æ¡£é‡Œçš„æ•°æ®é›†ï¼š

```python
df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],index=['cobra', 'viper', 'sidewinder'],columns=['max_speed', 'shield'])
df
```

![image-20200105200816439](./arrests/16.png)

ä¸‹é¢çš„å°ä¾‹å­å°±æ˜¯ä»æ–‡æ¡£é‡Œæ‹¿è¿‡æ¥çš„ï¼Œå¾ˆå…¨é¢çš„ç¤ºä¾‹äº†ä¸€äº›åº”ç”¨æ“ä½œã€‚

![image-20200105200936822](./arrests/17.png)

![image-20200105201004990](./arrests/18.png)

é‚£ä¹ˆé€šè¿‡ä¸Šé¢çš„å­¦ä¹ ï¼Œä½ å¤§æ¦‚ä¹ŸçŸ¥é“äº†`loc`çš„ç®€å•ç”¨æ³•äº†ï¼Œä¸‹é¢å°±ä»‹ç»ä¸‹åœ¨ç‰¹å¾å·¥ç¨‹é‡Œæˆ‘ä»¬æ¸…æ´—æŸäº›æ•°æ®æ—¶å€™ï¼Œå¯ä»¥é€šè¿‡è¿™å‡½æ•°æ¥ä¿®æ”¹å˜é‡å€¼ï¼Œä»è€Œè¾¾åˆ°æˆ‘ä»¬çš„æŸäº›ç›®çš„ã€‚



ä¸‹é¢æˆ‘ä»¬è¿˜æ˜¯ç”¨æ³°å¦å°¼å·çš„æ•°æ®é›†ï¼š

```python
# å¯¼å…¥ç›¸å…³åº“
import pandas as pd 
import numpy as np 
from pandas import Series,DataFrame

# å¯¼å…¥æ³°å¦å°¼çš„æ•°æ®é›†
data_train = pd.read_csv("./data/titanic/Train.csv")
data_train['Age'].value_counts().sort_index()
```

![image-20200105201448795](./arrests/19.png)

æˆ‘ä»¬å¯ä»¥çœ‹å‡ºæœ‰äº›å¹´é¾„æœ‰å°äº1å²çš„ï¼Œæ¯”å¦‚0.42ã€0.67ä¹‹ç±»çš„ï¼Œæˆ‘ä»¬è¿™é‡Œå°±ä½¿ç”¨ä¸€ä¸‹`loc`æ¥æŠŠè¿™äº›å°äº1å²çš„ä¿®æ”¹ä¸º1å²å§ï¼Œå¦‚æœæ²¡æœ‰æ„å¤–ï¼Œåº”è¯¥å²æ•°ä¸º1çš„ç»Ÿè®¡æ•°ä¼šå˜ä¸º14ä¸ªã€‚

```python
data_train.loc[(data_train.Age<=1),'Age'] = 1
data_train['Age'].value_counts().sort_index()
```

![image-20200105201854156](./arrests/20.png)



## Tip11ï¼šæ€ä¹ˆé€šè¿‡æ­£åˆ™æå–å­—ç¬¦ä¸²é‡Œçš„æŒ‡å®šå†…å®¹?

è¿™ä¸ªæ­£åˆ™è¡¨è¾¾å¼åœ¨æˆ‘ä»¬åšå­—ç¬¦æå–ä¸­æ˜¯ååˆ†å¸¸ç”¨çš„ï¼Œå…ˆå‰æœ‰ä¸€ç¯‡æ–‡ç« æœ‰ä»‹ç»åˆ°æ€ä¹ˆå»ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¥å®ç°æˆ‘ä»¬çš„ç›®çš„ï¼Œå¤§å®¶å¯ä»¥å…ˆå›é¡¾ä¸‹è¿™ç¯‡æ–‡ç« ã€‚

[å›¾æ–‡å¹¶èŒ‚åœ°å¸¦ä½ å…¥é—¨æ­£åˆ™è¡¨è¾¾å¼](https://mp.weixin.qq.com/s/F63qWLEWZY6vHGUK3pjnfA)



æˆ‘ä»¬è¿˜æ˜¯ç”¨ä¸€ä¸‹æ³°å¦å°¼å…‹å·çš„æ•°æ®é›†ï¼Œå¤§å®¶å¯ä»¥åœ¨ä¸‹é¢çš„é“¾æ¥å»ä¸‹è½½æ•°æ®å“ˆã€‚

Titanicæ•°æ®é›†ä¸‹è½½ï¼š

https://www.kaggle.com/c/titanic/data

```python
# å¯¼å…¥ç›¸å…³åº“
import pandas as pd 
import numpy as np 
from pandas import Series,DataFrame
import re

# å¯¼å…¥æ³°å¦å°¼çš„æ•°æ®é›†
data_train = pd.read_csv("./data/titanic/Train.csv")
data_train.head()
```

![image-20200106224916692](./arrests/21.png)

æˆ‘ä»¬ç°åœ¨å¯ä»¥æå–ä¸‹è¿™`name`é‡Œçš„ç§°è°“ï¼Œæ¯”å¦‚Mrã€Missä¹‹ç±»çš„ï¼Œä½œä¸ºä¸€ä¸ªæ–°åˆ—ï¼Œä»£ç å¦‚ä¸‹:

```python
data['Title'] = data['Name'].map(lambda x: re.compile(", (.*?)\.").findall(x)[0])
data.head()
```

![image-20200106225032595](./arrests/22.png)



æˆ‘ä»¬ä¹‹å‰çœ‹è¿™ä»£ç å…¶å®æœ‰ç‚¹æ‡µçš„ï¼Œä¸è¿‡è¿™æ˜¯å› ä¸ºå¤§å®¶å¯èƒ½å¯¹æ­£åˆ™è¡¨è¾¾å¼çš„è§„åˆ™ä¸å¤ªç†Ÿæ‚‰ï¼Œæ‰€ä»¥ä¸‹é¢æœ‰å‡ ä¸ªç›¸å…³çš„å¯ä»¥å‚è€ƒä¸‹ã€‚

```python
import re
str = 'xxdaxxabxxacabxxcdabddbxxssbdffbggxx'
# ä¸€ä¸ª'.'å°±æ˜¯åŒ¹é…\n(æ¢è¡Œç¬¦)ä»¥å¤–çš„ä»»ä½•å­—ç¬¦
print(re.findall(r'a.b',str))

# ä¸€ä¸ª'*'å‰é¢çš„å­—ç¬¦å‡ºç°0æ¬¡æˆ–ä»¥ä¸Š
print(re.findall(r'a*b',str))

# åŒ¹é…ä».*å‰é¢çš„å­—ç¬¦ä¸ºèµ·ç‚¹ï¼Œåˆ°åé¢å­—ç¬¦ä¸ºç»ˆç‚¹çš„æ‰€æœ‰å†…å®¹ï¼Œç›´åˆ°è¿”å›æ‰€æœ‰
print(re.findall(r'xx.*xx',str))

# éè´ªå©ªï¼Œå’Œä¸Šé¢çš„ä¸€æ ·ï¼Œä¸è¿‡æ˜¯ç”¨è¿‡ä¸€æ¬¡å°±ä¸ä¼šå†ç”¨,ï¼Œä»¥åˆ—è¡¨çš„å½¢å¼è¿”å›
print(re.findall(r'xx.*?xx',str))

# éè´ªå©ªï¼Œä¸ä¸Šé¢æ˜¯ä¸€æ ·çš„ï¼Œåªæ˜¯ä¸ä¸Šé¢ç›¸æ¯”ï¼Œå¤šäº†ä¸€ä¸ªæ‹¬å·ï¼Œåªä¿ç•™æ‹¬å·ä¸­çš„å†…å®¹
print(re.findall(r'xx(.*?)xx',str))

# ä¿ç•™a,bä¸­é—´çš„å†…å®¹
print(re.findall(r'xx(.+?)xx',str))
print(re.findall(r'xx(.+?)xx',str)[0])
```

![image-20200106225154826](./arrests/23.png)



æ‰€ä»¥ï¼Œçœ‹äº†è¿™äº›åï¼Œåº”è¯¥å°±å¯ä»¥ç†è§£ä¸Šé¢çš„patternçš„å«ä¹‰äº†ï¼





## Tip12ï¼šå¦‚ä½•åˆ©ç”¨å­—å…¸æ‰¹é‡ä¿®æ”¹å˜é‡å€¼ï¼Ÿ

è¿™é‡Œæˆ‘ä»¬å‡è®¾æœ‰è¿™ä¹ˆä¸€ç§æƒ…å†µï¼Œä¸€ä¸ªå­—æ®µé‡Œçš„å˜é‡å€¼ï¼Œéœ€è¦æŠŠæŸå‡ ä¸ªå˜é‡å€¼ä¿®æ”¹ä¸ºåŒä¸€ä¸ªå€¼ï¼Œç„¶åå…¶ä»–å‡ ä¸ªå˜é‡å€¼ä¿®æ”¹ä¸ºå¦å¤–ä¸€ä¸ªï¼Œé‚£ä¹ˆæˆ‘ä»¬æœ‰ä»€ä¹ˆç®€å•çš„åŠæ³•å¯ä»¥å®Œæˆå‘¢ï¼Ÿè¿™è¾¹ï¼Œæˆ‘æ¨èä¸€ä¸ª**å­—å…¸æ˜ å°„**çš„åŠæ³•ï¼

æˆ‘ä»¬è¿˜æ˜¯ç”¨ä¸€ä¸‹æ³°å¦å°¼å…‹å·çš„æ•°æ®é›†ï¼Œå¤§å®¶å¯ä»¥åœ¨ä¸‹é¢çš„é“¾æ¥å»ä¸‹è½½æ•°æ®å“ˆã€‚

Titanicæ•°æ®é›†ä¸‹è½½ï¼š

https://www.kaggle.com/c/titanic/data

```python
# å¯¼å…¥ç›¸å…³åº“
import pandas as pd 
import numpy as np 
from pandas import Series,DataFrame
import re

# å¯¼å…¥æ³°å¦å°¼çš„æ•°æ®é›†
data_train = pd.read_csv("./data/titanic/Train.csv")
# æå–å…¶ä¸­å‡ åˆ—
data = data_train.loc[:,['PassengerId','Name']]

# æå–ç§°è°“
data['Title'] = data['Name'].map(lambda x: re.compile(", (.*?)\.").findall(x)[0])
data.Title.value_counts()
```

![image-20200108082956766](./arrests/24.png)

å°±å¥½åƒæˆ‘åˆšåˆšæ‰€è¯´çš„ï¼Œéœ€è¦æŠŠé»„è‰²æ¡†æ¡†é‡Œçš„å˜é‡å€¼ä¿®æ”¹æ‰ï¼Œè€Œä¸”æ˜¯æŒ‰ç…§æˆ‘ä»¬çš„æƒ³æ³•ï¼Œæ¯”å¦‚`capt`å’Œ`Dr`åˆä¸ºä¸€ä½“ï¼Œç»Ÿä¸€å«`officer`ã€‚

```python
# å®šä¹‰ä¸€ä¸ªç©ºå­—å…¸æ¥æ”¶é›†æ˜ å°„å…³ç³»
title_Dict = {}
title_Dict.update(dict.fromkeys(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer'))
title_Dict.update(dict.fromkeys(['Don', 'Sir', 'the Countess', 'Dona', 'Lady'], 'Royalty'))
title_Dict.update(dict.fromkeys(['Mme', 'Ms', 'Mrs'], 'Mrs'))
title_Dict.update(dict.fromkeys(['Mlle', 'Miss'], 'Miss'))
title_Dict.update(dict.fromkeys(['Mr'], 'Mr'))
title_Dict.update(dict.fromkeys(['Master','Jonkheer'], 'Master'))
title_Dict
```

![image-20200108083243631](./arrests/25.png)

æˆ‘ä»¬æŠŠæ˜ å°„å…³ç³»ç”¨å­—å…¸æ¥å­˜å‚¨ï¼Œåˆ°æ—¶å€™ç›´æ¥å¯ä»¥æ‹¿æ¥ç”¨ã€‚

```python
data['Title'] = data['Title'].map(title_Dict)
data.Title.value_counts()
```

![image-20200108083335530](./arrests/26.png)





## Tip13ï¼šå¦‚ä½•å¯¹ç±»åˆ«å˜é‡è¿›è¡Œç‹¬çƒ­ç¼–ç ï¼Ÿ

å¾ˆå¤šæ—¶å€™æˆ‘ä»¬éœ€è¦å¯¹ç±»åˆ«å˜é‡è¿›è¡Œç‹¬çƒ­ç¼–ç ï¼Œç„¶åæ‰å¯ä»¥ä½œä¸ºå…¥å‚ç»™æ¨¡å‹ä½¿ç”¨ï¼Œç‹¬çƒ­çš„æ–¹å¼æœ‰å¾ˆå¤šç§ï¼Œè¿™é‡Œä»‹ç»ä¸€ä¸ªå¸¸ç”¨çš„æ–¹æ³• `get_dummies`å§ï¼Œè¿™ä¸ªæ–¹æ³•å¯ä»¥è®©ç±»åˆ«å˜é‡æŒ‰ç…§æšä¸¾å€¼ç”ŸæˆNä¸ªï¼ˆNä¸ºæšä¸¾å€¼æ•°é‡ï¼‰æ–°å­—æ®µï¼Œéƒ½æ˜¯0-1çš„å˜é‡å€¼ã€‚

æˆ‘ä»¬è¿˜æ˜¯ç”¨åˆ°æˆ‘ä»¬çš„æ³°å¦å°¼å…‹å·çš„æ•°æ®é›†ï¼ŒåŒæ—¶ä½¿ç”¨æˆ‘ä»¬ä¸Šæ¬¡é”¦å›Šåˆ†äº«çš„çŸ¥è¯†ï¼Œå¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†æ“ä½œï¼Œè§ä¸‹ï¼š

```python
# å¯¼å…¥ç›¸å…³åº“
import pandas as pd 
import numpy as np 
from pandas import Series,DataFrame
import re

# å¯¼å…¥æ³°å¦å°¼çš„æ•°æ®é›†
data_train = pd.read_csv("./data/titanic/Train.csv")
# æå–å…¶ä¸­å‡ åˆ—
data = data_train.loc[:,['PassengerId','Name']]

# æå–ç§°è°“
data['Title'] = data['Name'].map(lambda x: re.compile(", (.*?)\.").findall(x)[0])

# å®šä¹‰ä¸€ä¸ªç©ºå­—å…¸æ¥æ”¶é›†æ˜ å°„å…³ç³»
title_Dict = {}
title_Dict.update(dict.fromkeys(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer'))
title_Dict.update(dict.fromkeys(['Don', 'Sir', 'the Countess', 'Dona', 'Lady'], 'Royalty'))
title_Dict.update(dict.fromkeys(['Mme', 'Ms', 'Mrs'], 'Mrs'))
title_Dict.update(dict.fromkeys(['Mlle', 'Miss'], 'Miss'))
title_Dict.update(dict.fromkeys(['Mr'], 'Mr'))
title_Dict.update(dict.fromkeys(['Master','Jonkheer'], 'Master'))
data['Title'] = data['Title'].map(title_Dict)
data.Title.value_counts()
```

![image-20200109203916978](./arrests/27.png)

é‚£ä¹ˆæ¥ä¸‹æ¥æˆ‘ä»¬å¯¹å­—æ®µTitleè¿›è¡Œç‹¬çƒ­ç¼–ç ï¼Œè¿™é‡Œä½¿ç”¨get_dummiesï¼Œç”ŸæˆNä¸ª0-1æ–°å­—æ®µï¼š

```python
# æˆ‘ä»¬å¯¹å­—æ®µTitleè¿›è¡Œç‹¬çƒ­ç¼–ç ï¼Œè¿™é‡Œä½¿ç”¨get_dummiesï¼Œç”ŸæˆNä¸ª0-1æ–°å­—æ®µ
dummies_title = pd.get_dummies(data['Title'], prefix="Title")
data = pd.concat([data,dummies_title], axis=1)
data.head()
```

![image-20200109204023084](./arrests/28.png)

å¯¹äº†ï¼Œè¿™é‡Œæœ‰äº›åŒå­¦å¯èƒ½ä¼šé—®ï¼Œè¿˜æœ‰ä¸€ç§ç‹¬çƒ­ç¼–ç å‡ºæ¥çš„æ˜¯N-1ä¸ªå­—æ®µçš„åˆæ˜¯ä»€ä¹ˆï¼Ÿå¦å¤–è¿™ç§çš„è¯ï¼Œæˆ‘ä»¬æ˜¯ç§°ä¸º`dummy encoding`çš„ï¼Œä¹Ÿå°±æ˜¯å“‘å˜é‡ç¼–ç ï¼Œå®ƒæŠŠä»»æ„ä¸€ä¸ªçŠ¶æ€ä½å»é™¤ï¼Œä¹Ÿå°±æ˜¯è¯´å…¶ä¸­æœ‰ä¸€ç±»å˜é‡å€¼çš„å“‘å˜é‡è¡¨ç¤ºä¸ºå…¨0ã€‚æ›´å¤šçš„å†…å®¹å»ºè®®å¯ä»¥ç™¾åº¦æ·±å…¥äº†è§£å“ˆã€‚




## Tip14ï¼šå¦‚ä½•æŠŠâ€œå¹´é¾„â€å­—æ®µæŒ‰ç…§æˆ‘ä»¬çš„é˜ˆå€¼åˆ†æ®µï¼Ÿ

æˆ‘ä»¬åœ¨è¿›è¡Œç‰¹å¾å¤„ç†çš„æ—¶å€™ï¼Œä¹Ÿæœ‰çš„æ—¶å€™ä¼šé‡åˆ°ä¸€äº›å˜é‡ï¼Œæ¯”å¦‚è¯´å¹´é¾„ï¼Œç„¶åæˆ‘ä»¬æƒ³è¦æŒ‰ç…§æˆ‘ä»¬æƒ³è¦çš„é˜ˆå€¼è¿›è¡Œåˆ†ç±»ï¼Œæ¯”å¦‚è¯´ä½äº18å²çš„ä½œä¸ºä¸€ç±»ï¼Œ18-30å²çš„ä½œä¸ºä¸€ç±»ï¼Œé‚£ä¹ˆæ€ä¹ˆç”¨Pythonå®ç°çš„å‘¢ï¼Ÿ

æ˜¯çš„ï¼Œæˆ‘ä»¬è¿˜æ˜¯ç”¨åˆ°æˆ‘ä»¬çš„æ³°å¦å°¼å…‹å·çš„æ•°æ®é›†ï¼Œå¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†æ“ä½œï¼Œè§ä¸‹ï¼š

```python
# å¯¼å…¥ç›¸å…³åº“
import pandas as pd 
import numpy as np 
from pandas import Series,DataFrame

# å¯¼å…¥æ³°å¦å°¼çš„æ•°æ®é›†
data_train = pd.read_csv("./data/titanic/Train.csv")
# ä¿®å¤éƒ¨åˆ†ageçš„å€¼
data_train.loc[(data_train.Age<=1),'Age'] = 1
# åªä¿ç•™éƒ¨åˆ†å€¼
data = data_train.loc[:,['PassengerId','Age']]
data.head()
```

![image-20200109204627086](./arrests/29.png)

ç„¶åï¼Œæˆ‘ä»¬ç¼–è¾‘ä»£ç ï¼ŒæŒ‰ç…§æˆ‘ä»¬çš„é¢„æœŸè¿›è¡Œåˆ†ç»„:

```python
# ç¡®å®šé˜ˆå€¼ï¼Œå†™å…¥åˆ—è¡¨
bins = [0, 12, 18, 30, 50, 70, 100]
data['Age_group'] = pd.cut(data['Age'], bins)

dummies_Age = pd.get_dummies(data['Age_group'], prefix= 'Age')
data = pd.concat([data, dummies_Age], axis=1)

data.head()
```

![image-20200109204718102](./arrests/30.png)



è¿™æ ·å­å°±å¾ˆç¥å¥‡äº†å§ï¼ŒæŠŠå¹´é¾„æŒ‰ç…§æˆ‘ä»¬çš„éœ€æ±‚è¿›è¡Œåˆ†ç»„ï¼Œé¡ºä¾¿ä½¿ç”¨ç‹¬çƒ­ç¼–ç ç”Ÿæˆäº†æ–°çš„å­—æ®µã€‚






## Tip15ï¼šå¦‚ä½•ä½¿ç”¨sklearnçš„å¤šé¡¹å¼æ¥è¡ç”Ÿæ›´å¤šçš„å˜é‡ï¼Ÿ

å…³äºè¿™ç§è¡ç”Ÿå˜é‡çš„æ–¹å¼ï¼Œç†è®ºå…¶å®å¤§å®¶åº”è¯¥å¾ˆæ—©ä¹Ÿéƒ½å¬è¯´è¿‡äº†ï¼Œä½†æ˜¯å¦‚ä½•åœ¨Pythoné‡Œå®ç°ï¼Œä¹Ÿå°±æ˜¯ä»Šå¤©åœ¨è¿™é‡Œåˆ†äº«ç»™å¤§å®¶ï¼Œå…¶å®ä¹Ÿå¾ˆç®€å•ï¼Œå°±æ˜¯è°ƒç”¨`sklearn`çš„`PolynomialFeatures`æ–¹æ³•ï¼Œå…·ä½“å¤§å®¶å¯ä»¥çœ‹çœ‹ä¸‹é¢çš„demoã€‚



è¿™é‡Œä½¿ç”¨ä¸€ä¸ªäººä½“åŠ é€Ÿåº¦æ•°æ®é›†ï¼Œä¹Ÿå°±æ˜¯è®°å½•ä¸€ä¸ªäººåœ¨åšä¸åŒåŠ¨ä½œæ—¶å€™ï¼Œåœ¨ä¸åŒæ–¹å‘ä¸Šçš„åŠ é€Ÿåº¦ï¼Œåˆ†åˆ«æœ‰3ä¸ªæ–¹å‘ï¼Œå‘½åä¸ºxã€yã€zã€‚

```python
# äººä½“èƒ¸éƒ¨åŠ é€Ÿåº¦æ•°æ®é›†,æ ‡ç­¾activityçš„æ•°å€¼ä¸º1-7
'''
1-åœ¨ç”µè„‘å‰å·¥ä½œ
2-ç«™ç«‹ã€èµ°è·¯å’Œä¸Šä¸‹æ¥¼æ¢¯
3-ç«™ç«‹
4-èµ°è·¯
5-ä¸Šä¸‹æ¥¼æ¢¯
6-ä¸äººè¾¹èµ°è¾¹èŠ
7-ç«™ç«‹ç€è¯´è¯

'''
import pandas as pd
df = pd.read_csv('./data/activity_recognizer/1.csv', header=None)
df.columns = ['index','x','y','z','activity']
df.head()

```

![image-20200111200231817](./arrests/31.png)

é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥ç›´æ¥è°ƒç”¨åˆšåˆšè¯´çš„åŠæ³•ï¼Œç„¶åå¯¹äºæ•°å€¼å‹å˜é‡å¤šé¡¹å¼çš„å˜é‡æ‰©å±•ï¼Œä»£ç å¦‚ä¸‹:

```python
# æ‰©å±•æ•°å€¼ç‰¹å¾
from sklearn.preprocessing import PolynomialFeatures

x = df[['x','y','z']]
y = df['activity']

poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)

x_poly = poly.fit_transform(x)
pd.DataFrame(x_poly, columns=poly.get_feature_names()).head()
```

![image-20200111200347306](./arrests/32.png)




## Tip16ï¼šå¦‚ä½•æ ¹æ®å˜é‡ç›¸å…³æ€§ç”»å‡ºçƒ­åŠ›å›¾ï¼Ÿ

ä¸Šæ¬¡çš„é”¦å›Šæœ‰æåŠåˆ°å¦‚ä½•ä½¿ç”¨`sklearn`æ¥å®ç°å¤šé¡¹å¼çš„æ‰©å±•æ¥è¡ç”Ÿæ›´å¤šçš„å˜é‡ï¼Œä½†æ˜¯æˆ‘ä»¬ä¹ŸçŸ¥é“å…¶å®è¿™æ ·å­å‡ºæ¥çš„å˜é‡ä¹‹é—´çš„ç›¸å…³æ€§æ˜¯å¾ˆå¼ºçš„ï¼Œæˆ‘ä»¬æ€ä¹ˆå¯ä»¥å¯è§†åŒ–ä¸€ä¸‹å‘¢ï¼Ÿè¿™é‡Œä»‹ç»ä¸€ä¸ªçƒ­åŠ›å›¾çš„æ–¹å¼ï¼Œè°ƒç”¨`corr`æ¥å®ç°å˜é‡ç›¸å…³æ€§çš„è®¡ç®—ï¼ŒåŒæ—¶çƒ­åŠ›å›¾ï¼Œé¢œè‰²è¶Šæ·±çš„è¯ï¼Œä»£è¡¨ç›¸å…³æ€§è¶Šå¼ºï¼

```python
# äººä½“èƒ¸éƒ¨åŠ é€Ÿåº¦æ•°æ®é›†,æ ‡ç­¾activityçš„æ•°å€¼ä¸º1-7
'''
1-åœ¨ç”µè„‘å‰å·¥ä½œ
2-ç«™ç«‹ã€èµ°è·¯å’Œä¸Šä¸‹æ¥¼æ¢¯
3-ç«™ç«‹
4-èµ°è·¯
5-ä¸Šä¸‹æ¥¼æ¢¯
6-ä¸äººè¾¹èµ°è¾¹èŠ
7-ç«™ç«‹ç€è¯´è¯

'''
import pandas as pd
from sklearn.preprocessing import PolynomialFeatures

df = pd.read_csv('./data/activity_recognizer/1.csv', header=None)
df.columns = ['index','x','y','z','activity']

x = df[['x','y','z']]
y = df['activity']

# å¤šé¡¹å¼æ‰©å……æ•°å€¼å˜é‡
poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)

x_poly = poly.fit_transform(x)
pd.DataFrame(x_poly, columns=poly.get_feature_names()).head()

# æŸ¥çœ‹çƒ­åŠ›å›¾(é¢œè‰²è¶Šæ·±ä»£è¡¨ç›¸å…³æ€§è¶Šå¼º)
%matplotlib inline
import seaborn as sns

sns.heatmap(pd.DataFrame(x_poly, columns=poly.get_feature_names()).corr())
```

![image-20200111201003846](./arrests/33.png)




## Tip17ï¼šå¦‚ä½•æŠŠåˆ†å¸ƒä¿®æ­£ä¸ºç±»æ­£æ€åˆ†å¸ƒï¼Ÿ

ä»Šå¤©æˆ‘ä»¬ç”¨çš„æ˜¯ä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼Œä¹Ÿæ˜¯åœ¨kaggleä¸Šçš„ä¸€ä¸ªæ¯”èµ›ï¼Œå¤§å®¶å¯ä»¥å…ˆå»ä¸‹è½½ä¸€ä¸‹ï¼š

![image-20200113205105743](./arrests/34.png)

ä¸‹è½½åœ°å€ï¼šhttps://www.kaggle.com/c/house-prices-advanced-regression-techniques/data

```python
import pandas as pd
import numpy as np
# Plots
import seaborn as sns
import matplotlib.pyplot as plt

# è¯»å–æ•°æ®é›†
train = pd.read_csv('./data/house-prices-advanced-regression-techniques/train.csv')
train.head()

```

![image-20200113210816071](./arrests/35.png)



é¦–å…ˆè¿™ä¸ªæ˜¯ä¸€ä¸ªä»·æ ¼é¢„æµ‹çš„é¢˜ç›®ï¼Œåœ¨å¼€å§‹å‰æˆ‘ä»¬éœ€è¦çœ‹çœ‹åˆ†å¸ƒæƒ…å†µï¼Œå¯ä»¥è°ƒç”¨ä»¥ä¸‹çš„æ–¹æ³•æ¥è¿›è¡Œç»˜åˆ¶ï¼š

```python
sns.set_style("white")
sns.set_color_codes(palette='deep')
f, ax = plt.subplots(figsize=(8, 7))
#Check the new distribution 
sns.distplot(train['SalePrice'], color="b");
ax.xaxis.grid(False)
ax.set(ylabel="Frequency")
ax.set(xlabel="SalePrice")
ax.set(title="SalePrice distribution")
sns.despine(trim=True, left=True)
plt.show()

```

![image-20200113210907623](./arrests/36.png)



æˆ‘ä»¬ä»ç»“æœå¯ä»¥çœ‹å‡ºï¼Œé”€å”®ä»·æ ¼æ˜¯å³åï¼Œè€Œå¤§å¤šæ•°æœºå™¨å­¦ä¹ æ¨¡å‹éƒ½ä¸èƒ½å¾ˆå¥½åœ°å¤„ç†éæ­£æ€åˆ†å¸ƒæ•°æ®ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥åº”ç”¨log(1+x)è½¬æ¢æ¥è¿›è¡Œä¿®æ­£ã€‚é‚£ä¹ˆå…·ä½“æˆ‘ä»¬å¯ä»¥æ€ä¹ˆç”¨Pythonä»£ç å®ç°å‘¢ï¼Ÿ

```python
# log(1+x) è½¬æ¢
train["SalePrice_log"] = np.log1p(train["SalePrice"])

sns.set_style("white")
sns.set_color_codes(palette='deep')
f, ax = plt.subplots(figsize=(8, 7))

sns.distplot(train['SalePrice_log'] , fit=norm, color="b");

# å¾—åˆ°æ­£æ€åˆ†å¸ƒçš„å‚æ•°
(mu, sigma) = norm.fit(train['SalePrice_log'])

plt.legend(['Normal dist. ($\mu=$ {:.2f} and $\sigma=$ {:.2f} )'.format(mu, sigma)],
            loc='best')
ax.xaxis.grid(False)
ax.set(ylabel="Frequency")
ax.set(xlabel="SalePrice")
ax.set(title="SalePrice distribution")
sns.despine(trim=True, left=True)

plt.show()
```

![image-20200113211509700](./arrests/37.png)




## Tip18ï¼šæ€ä¹ˆæ‰¾å‡ºæ•°æ®é›†ä¸­æœ‰æ•°æ®å€¾æ–œçš„ç‰¹å¾ï¼Ÿ

ä»Šå¤©æˆ‘ä»¬ç”¨çš„æ˜¯ä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼Œä¹Ÿæ˜¯åœ¨kaggleä¸Šçš„ä¸€ä¸ªæ¯”èµ›ï¼Œå¤§å®¶å¯ä»¥å…ˆå»ä¸‹è½½ä¸€ä¸‹ï¼š

![image-20200113205105743](./arrests/34.png)

ä¸‹è½½åœ°å€ï¼šhttps://www.kaggle.com/c/house-prices-advanced-regression-techniques/data

```python
import pandas as pd
import numpy as np
# Plots
import seaborn as sns
import matplotlib.pyplot as plt

# è¯»å–æ•°æ®é›†
train = pd.read_csv('./data/house-prices-advanced-regression-techniques/train.csv')
train.head()
```

![image-20200113210816071](./arrests/35.png)



æˆ‘ä»¬å¯¹æ•°æ®é›†è¿›è¡Œåˆ†æï¼Œé¦–å…ˆæˆ‘ä»¬å¯ä»¥å…ˆçœ‹çœ‹ç‰¹å¾çš„åˆ†å¸ƒæƒ…å†µï¼Œçœ‹ä¸‹å“ªäº›ç‰¹å¾æ˜æ˜¾å°±æ˜¯æœ‰æ•°æ®å€¾æ–œçš„ï¼Œç„¶åå¯ä»¥æ‰¾åŠæ³•è§£å†³ï¼Œå› æ­¤ï¼Œç¬¬ä¸€æ­¥å°±æ˜¯è¦æœ‰åŠæ³•æ‰¾åˆ°è¿™äº›ç‰¹å¾ã€‚

é¦–å…ˆå¯ä»¥é€šè¿‡å¯è§†åŒ–çš„æ–¹å¼ï¼Œç”»ç®±ä½“å›¾ï¼Œç„¶åè§‚å¯Ÿç®±ä½“æƒ…å†µï¼Œç†è®ºçŸ¥è¯†æ˜¯ï¼š

> åœ¨ç®±çº¿å›¾ä¸­ï¼Œç®±å­çš„ä¸­é—´æœ‰ä¸€æ¡çº¿ï¼Œä»£è¡¨äº†æ•°æ®çš„ä¸­ä½æ•°ã€‚ç®±å­çš„ä¸Šä¸‹åº•ï¼Œåˆ†åˆ«æ˜¯æ•°æ®çš„ä¸Šå››åˆ†ä½æ•°ï¼ˆQ3ï¼‰å’Œä¸‹å››åˆ†ä½æ•°ï¼ˆQ1ï¼‰ï¼Œè¿™æ„å‘³ç€ç®±ä½“åŒ…å«äº†50%çš„æ•°æ®ã€‚å› æ­¤ï¼Œ**ç®±å­çš„é«˜åº¦åœ¨ä¸€å®šç¨‹åº¦ä¸Šåæ˜ äº†æ•°æ®çš„æ³¢åŠ¨ç¨‹åº¦**ã€‚ä¸Šä¸‹è¾¹ç¼˜åˆ™ä»£è¡¨äº†è¯¥ç»„æ•°æ®çš„æœ€å¤§å€¼å’Œæœ€å°å€¼ã€‚æœ‰æ—¶å€™ç®±å­å¤–éƒ¨ä¼šæœ‰ä¸€äº›ç‚¹ï¼Œå¯ä»¥ç†è§£ä¸ºæ•°æ®ä¸­çš„â€œ**å¼‚å¸¸å€¼**â€ã€‚è€Œå¯¹äºæ•°æ®å€¾æ–œçš„ï¼Œæˆ‘ä»¬å«åšâ€œåæ€â€ï¼Œä¸æ­£æ€åˆ†å¸ƒç›¸å¯¹ï¼ŒæŒ‡çš„æ˜¯éå¯¹ç§°åˆ†å¸ƒçš„åæ–œçŠ¶æ€ã€‚åœ¨ç»Ÿè®¡å­¦ä¸Šï¼Œä¼—æ•°å’Œå¹³å‡æ•°ä¹‹å·®å¯ä½œä¸ºåˆ†é…åæ€çš„æŒ‡æ ‡ä¹‹ä¸€ï¼šå¦‚å¹³å‡æ•°å¤§äºä¼—æ•°ï¼Œç§°ä¸ºæ­£åæ€ï¼ˆæˆ–å³åæ€ï¼‰ï¼›ç›¸åï¼Œåˆ™ç§°ä¸ºè´Ÿåæ€ï¼ˆæˆ–å·¦åæ€ï¼‰ã€‚



```python
# ä¸¢å¼ƒyå€¼
all_features = train.drop(['SalePrice'], axis=1)

# æ‰¾å‡ºæ‰€æœ‰çš„æ•°å€¼å‹å˜é‡
numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
numeric = []
for i in all_features.columns:
    if all_features[i].dtype in numeric_dtypes:
        numeric.append(i)
        
# å¯¹æ‰€æœ‰çš„æ•°å€¼å‹å˜é‡ç»˜åˆ¶ç®±ä½“å›¾
sns.set_style("white")
f, ax = plt.subplots(figsize=(8, 7))
ax.set_xscale("log")
ax = sns.boxplot(data=all_features[numeric] , orient="h", palette="Set1")
ax.xaxis.grid(False)
ax.set(ylabel="Feature names")
ax.set(xlabel="Numeric values")
ax.set(title="Numeric Distribution of Features")
sns.despine(trim=True, left=True)
```

![image-20200114215939603](./arrests/38.png)

å¯ä»¥çœ‹å‡ºæœ‰ä¸€äº›ç‰¹å¾ï¼Œæœ‰ä¸€äº›æ•°æ®ä¼šåç¦»ç®±ä½“å¤–ï¼Œå› æ­¤å±äºæ•°æ®å€¾æ–œã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬ä»ä¸Šé¢çš„å¯è§†åŒ–ä¸­è™½ç„¶çœ‹å‡ºæ¥äº†ï¼Œä½†æ˜¯æƒ³è¦é€‰å‡ºæ¥è¿˜æ˜¯æ¯”è¾ƒéº»çƒ¦ï¼Œæ‰€ä»¥è¿™é‡Œå¼•å…¥ä¸€ä¸ªåæ€çš„æ¦‚å¿µï¼Œç›¸å¯¹åº”çš„æœ‰ä¸€ä¸ªæŒ‡æ ‡`skew`ï¼Œè¿™ä¸ªå°±æ˜¯ä»£è¡¨åæ€çš„ç³»æ•°ã€‚

> Skewnessï¼šæè¿°æ•°æ®åˆ†å¸ƒå½¢æ€çš„ç»Ÿè®¡é‡ï¼Œå…¶æè¿°çš„æ˜¯æŸæ€»ä½“å–å€¼åˆ†å¸ƒçš„**å¯¹ç§°æ€§**ï¼Œç®€å•æ¥è¯´å°±æ˜¯æ•°æ®çš„ä¸å¯¹ç§°ç¨‹åº¦ã€‚
>
> ååº¦æ˜¯ä¸‰é˜¶ä¸­å¿ƒè·è®¡ç®—å‡ºæ¥çš„ã€‚
>
> ï¼ˆ1ï¼‰Skewness = 0 ï¼Œåˆ†å¸ƒå½¢æ€ä¸æ­£æ€åˆ†å¸ƒååº¦ç›¸åŒã€‚
>
> ï¼ˆ2ï¼‰Skewness > 0 ï¼Œæ­£åå·®æ•°å€¼è¾ƒå¤§ï¼Œä¸ºæ­£åæˆ–å³åã€‚é•¿å°¾å·´æ‹–åœ¨å³è¾¹ï¼Œæ•°æ®å³ç«¯æœ‰è¾ƒå¤šçš„æç«¯å€¼ã€‚
>
> ï¼ˆ3ï¼‰Skewness < 0 ï¼Œè´Ÿåå·®æ•°å€¼è¾ƒå¤§ï¼Œä¸ºè´Ÿåæˆ–å·¦åã€‚é•¿å°¾å·´æ‹–åœ¨å·¦è¾¹ï¼Œæ•°æ®å·¦ç«¯æœ‰è¾ƒå¤šçš„æç«¯å€¼ã€‚
>
> ï¼ˆ4ï¼‰æ•°å€¼çš„ç»å¯¹å€¼è¶Šå¤§ï¼Œè¡¨æ˜æ•°æ®åˆ†å¸ƒè¶Šä¸å¯¹ç§°ï¼Œåæ–œç¨‹åº¦å¤§ã€‚

é‚£ä¹ˆåœ¨Pythoné‡Œå¯ä»¥æ€ä¹ˆå®ç°å‘¢ï¼Ÿ

```python
# æ‰¾å‡ºæ˜æ˜¾åæ€çš„æ•°å€¼å‹å˜é‡
skew_features = all_features[numeric].apply(lambda x: skew(x)).sort_values(ascending=False)

high_skew = skew_features[skew_features > 0.5]
skew_index = high_skew.index

print("æœ¬æ•°æ®é›†ä¸­æœ‰ {} ä¸ªæ•°å€¼å‹å˜é‡çš„ Skew > 0.5 :".format(high_skew.shape[0]))
skewness = pd.DataFrame({'Skew' :high_skew})
skew_features.head(10)
```

![image-20200114220316028](./arrests/39.png)




## Tip19ï¼šæ€ä¹ˆå°½å¯èƒ½åœ°ä¿®æ­£æ•°æ®å€¾æ–œçš„ç‰¹å¾ï¼Ÿ

ä¸Šä¸€ä¸ªé”¦å›Šï¼Œåˆ†äº«äº†ç»™å¤§å®¶é€šè¿‡`skew`çš„æ–¹æ³•æ¥æ‰¾åˆ°æ•°æ®é›†ä¸­æœ‰æ•°æ®å€¾æ–œçš„ç‰¹å¾ï¼ˆç‰¹å¾é”¦å›Šï¼šæ€ä¹ˆæ‰¾å‡ºæ•°æ®é›†ä¸­æœ‰æ•°æ®å€¾æ–œçš„ç‰¹å¾ï¼Ÿï¼‰ï¼Œé‚£ä¹ˆæ€ä¹ˆå»ä¿®æ­£å®ƒå‘¢ï¼Ÿæ­£æ˜¯ä»Šå¤©è¦åˆ†äº«ç»™å¤§å®¶çš„é”¦å›Šï¼



è¿˜æ˜¯ç”¨åˆ°æˆ¿ä»·é¢„æµ‹çš„æ•°æ®é›†ï¼š

![image-20200113205105743](./arrests/34.png)

ä¸‹è½½åœ°å€ï¼šhttps://www.kaggle.com/c/house-prices-advanced-regression-techniques/data

```python
import pandas as pd
import numpy as np
# Plots
import seaborn as sns
import matplotlib.pyplot as plt

# è¯»å–æ•°æ®é›†
train = pd.read_csv('./data/house-prices-advanced-regression-techniques/train.csv')
train.head()
```

![image-20200113210816071](./arrests/35.png)



æˆ‘ä»¬é€šè¿‡ä¸Šæ¬¡çš„çŸ¥è¯†ï¼ŒçŸ¥é“äº†å¯ä»¥é€šè¿‡`skewness`æ¥è¿›è¡Œå€¾æ–œç‰¹å¾çš„è¾¨åˆ«ï¼Œé‚£ä¹ˆå¯¹äºä¿®æ­£å®ƒçš„åŠæ³•ï¼Œè¿™é‡Œä¹Ÿå…ˆåˆ†äº«ä¸€ä¸ªç†è®ºçŸ¥è¯† â€”â€” **box-coxè½¬æ¢**ã€‚

> çº¿æ€§å›å½’æ¨¡å‹æ»¡è¶³çº¿æ€§æ€§ã€ç‹¬ç«‹æ€§ã€æ–¹å·®é½æ€§ä»¥åŠæ­£æ€æ€§çš„åŒæ—¶ï¼Œåˆä¸ä¸¢å¤±ä¿¡æ¯ï¼Œæ­¤ç§å˜æ¢ç§°ä¹‹ä¸ºBoxâ€”Coxå˜æ¢ã€‚
>
> Box-Coxå˜æ¢æ˜¯Boxå’ŒCoxåœ¨1964å¹´æå‡ºçš„ä¸€ç§å¹¿ä¹‰å¹‚å˜æ¢æ–¹æ³•ï¼Œæ˜¯ç»Ÿè®¡å»ºæ¨¡ä¸­å¸¸ç”¨çš„ä¸€ç§[æ•°æ®](https://baike.baidu.com/item/æ•°æ®/33305)å˜æ¢ï¼Œç”¨äºè¿ç»­çš„å“åº”å˜é‡ä¸æ»¡è¶³æ­£æ€åˆ†å¸ƒçš„æƒ…å†µã€‚Box-Coxå˜æ¢ä¹‹åï¼Œå¯ä»¥ä¸€å®šç¨‹åº¦ä¸Šå‡å°ä¸å¯è§‚æµ‹çš„è¯¯å·®å’Œé¢„æµ‹å˜é‡çš„ç›¸å…³æ€§ã€‚Box-Coxå˜æ¢çš„ä¸»è¦ç‰¹ç‚¹æ˜¯å¼•å…¥ä¸€ä¸ªå‚æ•°ï¼Œé€šè¿‡æ•°æ®æœ¬èº«ä¼°è®¡è¯¥å‚æ•°è¿›è€Œç¡®å®šåº”é‡‡å–çš„æ•°æ®å˜æ¢å½¢å¼ï¼ŒBox-Coxå˜æ¢å¯ä»¥æ˜æ˜¾åœ°æ”¹å–„æ•°æ®çš„æ­£æ€æ€§ã€å¯¹ç§°æ€§å’Œæ–¹å·®ç›¸ç­‰æ€§ï¼Œå¯¹è®¸å¤šå®é™…æ•°æ®éƒ½æ˜¯è¡Œä¹‹æœ‰æ•ˆçš„ã€‚â€”â€” ç™¾åº¦ç™¾ç§‘



åœ¨ä½¿ç”¨å‰ï¼Œæˆ‘ä»¬å…ˆçœ‹çœ‹åŸå…ˆå€¾æ–œçš„ç‰¹å¾æœ‰å¤šå°‘ä¸ªã€‚



```python
# ä¸¢å¼ƒyå€¼
all_features = train.drop(['SalePrice'], axis=1)

# æ‰¾å‡ºæ‰€æœ‰çš„æ•°å€¼å‹å˜é‡
numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
numeric = []
for i in all_features.columns:
    if all_features[i].dtype in numeric_dtypes:
        numeric.append(i)
        
# æ‰¾å‡ºæ˜æ˜¾åæ€çš„æ•°å€¼å‹å˜é‡
skew_features = all_features[numeric].apply(lambda x: skew(x)).sort_values(ascending=False)

high_skew = skew_features[skew_features > 0.5]
skew_index = high_skew.index

print("æœ¬æ•°æ®é›†ä¸­æœ‰ {} ä¸ªæ•°å€¼å‹å˜é‡çš„ Skew > 0.5 :".format(high_skew.shape[0]))
skewness = pd.DataFrame({'Skew' :high_skew})
skew_features
```

> æœ¬æ•°æ®é›†ä¸­æœ‰ 24 ä¸ªæ•°å€¼å‹å˜é‡çš„ Skew > 0.5 :



åœ¨Pythonä¸­æ€ä¹ˆä½¿ç”¨Box-Cox è½¬æ¢å‘¢ï¼Ÿå¾ˆç®€å•ã€‚

```python
# é€šè¿‡ Box-Cox è½¬æ¢ï¼Œä»è€ŒæŠŠå€¾æ–œçš„æ•°æ®è¿›è¡Œä¿®æ­£
for i in skew_index:
    all_features[i] = boxcox1p(all_features[i], boxcox_normmax(all_features[i] + 1))
```



ç„¶åæˆ‘ä»¬å†çœ‹çœ‹è¿˜æœ‰å¤šå°‘ä¸ªæ•°æ®å€¾æ–œçš„ç‰¹å¾å§ï¼

```python
# æ‰¾å‡ºæ˜æ˜¾åæ€çš„æ•°å€¼å‹å˜é‡
skew_features = all_features[numeric].apply(lambda x: skew(x)).sort_values(ascending=False)

high_skew = skew_features[skew_features > 0.5]
skew_index = high_skew.index
print("æœ¬æ•°æ®é›†ä¸­æœ‰ {} ä¸ªæ•°å€¼å‹å˜é‡çš„ Skew > 0.5 :".format(high_skew.shape[0]))
skewness = pd.DataFrame({'Skew' :high_skew})
```

> æœ¬æ•°æ®é›†ä¸­æœ‰ 15 ä¸ªæ•°å€¼å‹å˜é‡çš„ Skew > 0.5 :



å˜å°‘äº†å¾ˆå¤šï¼Œè€Œä¸”å¦‚æœçœ‹ä»–ä»¬çš„skewå€¼ï¼Œä¹Ÿä¼šå‘ç°å˜å°äº†å¾ˆå¤šã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥çœ‹çœ‹è½¬æ¢åçš„ç®±ä½“å›¾æƒ…å†µã€‚

```python
# Let's make sure we handled all the skewed values
sns.set_style("white")
f, ax = plt.subplots(figsize=(8, 7))
ax.set_xscale("log")
ax = sns.boxplot(data=all_features[skew_index] , orient="h", palette="Set1")
ax.xaxis.grid(False)
ax.set(ylabel="Feature names")
ax.set(xlabel="Numeric values")
ax.set(title="Numeric Distribution of Features")
sns.despine(trim=True, left=True)
```

![image-20200117212535708](./arrests/40.png)


![image](./arrests/åº•å›¾2.0.png)
æœ€æ–°çš„å‘å¸ƒå†…å®¹è¯·å…³æ³¨ä¸ªäººå¾®ä¿¡å…¬ä¼—å·å“ˆ~

